%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%% TROISIEME PARTIE %%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\part{Rendre la recherche réutilisable et interopérable: \textit{KatAPI}, une API pour échanger des données structurées}

La problématique de cette partie est la suivante: comment rendre la recherche en humanités numériques réutilisable et encourager le partage de données entre projets de recherche? La réponse à cette question, au sein du projet \mssktb{}, prend la forme d'une \api{}. Celle-ci diffuse les données catalographiques à la source du projet, mais aussi des informations issues de la recherche et du traitement computationnel de celles-ci dans deux formats structurés: le \json{} et le \xmltei{}.

En guise d'introduction, il me semble important ici de faire un bref rappel des principes fondamentaux du développement applicatif et de l'architecture du Web. Certains de ces principes ont déjà été présentés (voir le graphique \ref{fig:api} dans la partie précédente), mais ce rappel permettra de rendre la suite de ce chapitre plus claire.

Le Web est une architecture de type client-serveur qui permet l'interaction de machines dans un réseau décentralisé. Cette architecture définit deux fonctions possibles pour une machine: client (qui envoie et récupère des données distantes) et serveur (qui contient une application permettant l'interaction avec le client, ainsi qu'une base de données). Dans le Web, l'architecture client-serveur repose sur un protocole technique qui pose les principes de l'interaction entre des machines: le \gls{http}. Selon ce principe, l'accès d'un client à une ressource stockée sur un serveur (une page Web, par exemple) se fait au travers d'un \gls{url}. Celui-ci sert à localiser la ressource. L'interaction est définie par des requêtes (du client au serveur) et par des réponses (du serveur au client). Six types de requêtes sont possibles, qui correspondent à autant d'actions: demander des données à un serveur, en supprimer, les mettre à jour... Requêtes et réponses ont la même structure: elles sont composées d'un en-tête \gls{http} (qui contient des métadonnées sur la requête ou la réponse) et d'un corps (qui contient la requête ou la réponse en elle-même; celui-ci peut être vide). Parmi les métadonnées contenues dans l'en-tête, deux sont importantes dans notre contexte (surtout pour les réponses du client au serveur): le statut et le type MIME. Un statut est un code à trois chiffres qui caractérise la réponse et le déroulement de l'interaction client-serveur. \enquote{200} indique que tout va bien, \enquote{404} que la ressource demandée n'existe pas (c'est-à-dire, que l'\gls{url} de la requête ne pointe pas vers une ressource existante). Le type MIME est une manière standardisée de définir le format d'une réponse: \enquote{\texttt{application/json}} lorsque la réponse est au format \json{}, \enquote{\texttt{application/xml}} lorsque du \xml{} est renvoyé.

Une \api{} est une application, c'est-à-dire un ensemble de fonctions rassemblées pour permettre l'interaction entre un client et un serveur. Souvent, et c'est le cas pour les applications du projet \mssktb{}, une application permet l'interaction avec une base de données, elle-aussi stockée sur le serveur. Par exemple, lorsque l'on accède à une page \textit{Wikipedia}, l'application reçoit une requête de la part d'un client; elle va chercher dans la base les données pertinentes, les structure sous la forme d'une page HTML et les renvoie à l'utilisateur.ice, qui verra la page s'afficher sur son écran. La principale différence entre une \api{} Web et une application (comme \textit{Wikipedia}) est que l'\api{} est \enquote{un site Web pour machines}. Elle ne contient pas d'interface graphique et les réponses renvoyées par l'\api{} sont des données dites \enquote{brutes}; celles-ci ont l'avantage d'être lisibles et manipulables par une machine. L'interaction avec une \api{} se fait en envoyant une requête à l'application avec un \gls{url} qui contient les paramètres de la requête et des valeurs associées à ces paramètres (quelles données demander, quel format de réponse utiliser...) et éventuellement un corps de requête qui contienne des données (ce qui n'est pas le cas lorsque la requête correspond à une demande de données). L'\gls{url} contient donc la sémantique de la requête, il correspond à une question posée à un serveur de façon structurée. L'intérêt d'une telle \api{} est que, pour peu que l'on sache interagir avec elle, il est possible de récupérer automatiquement des données structurées, prêtes à être utilisées. Pour télécharger un jeu de données, il n'y a pas besoin, par exemple, d'aller sur la bonne page Web, de cliquer sur un bouton \enquote{Télécharger} et d'enregistrer le fichier au bon endroit. Toutes ces opérations peuvent être faites automatiquement, comme cela a été fait pour plus de 80000 requêtes lors de l'interaction avec \wkd{} décrite précédemment. Cette perspective est particulièrement intéressante pour un projet de recherche, puisqu'elle peut permettre de récupérer automatiquement les jeux de données produits par un autre projet, ce qui encourage la réutilisation des données de la recherche. Pour des ingénieur.e.s des données, les \api{} facilitent grandement le travail de récupération automatisée d'informations: elles permettent de \enquote{se concentrer sur le quoi, et non sur le comment}\footnote{\textit{focus on the what, and not on the how}. Citation issue de \cite[p. 2]{murdock_inpho_2011}.}.

Souvent, un site Web peut être composé d'une version accessible pour des utilisateur.ice.s humain.e.s ainsi que d'une version pour machines; c'est le cas dans le projet \ktb{}. L'application pour humain.e.s a déjà été développée; c'est la version pour les machines, son fonctionnement et son utilité pour permettre la réutilisation des données du projet dans un contexte de science ouverte qui sont donc présentés dans cette partie.

\chapter{Standards de design et statut des API dans pour les humanités numériques centrées sur le texte}
\chaptermark{Standards de design et statut}
Il n'existe aucune norme communément acceptée pour la conception d'une \api{}: dans l'absolu, tant que celle-ci fonctionne, elle peut être considérée comme une \api{}. Cependant, des standards se sont développés afin de regrouper les différentes méthodes et de développer des bonnes pratiques de design. Deux types de standards sont ici présentés: les standards d'architecture et les standards d'interopérabilité. Un standard d'architecture ou de design, comme le \gls{rest}, définit comment concevoir l'interaction client-serveur dans une \api{} et propose une manière de structurer les réponses du serveur. Il ne définit cependant pas quels paramètres de recherches sont autorisés, ni comment le corps d'une réponse doit être organisé. Il ne définit pas non plus précisément comment organiser une requête, c'est-à-dire quel \gls{url} construire pour accéder aux données. C'est le rôle des standards d'interopérabilité (\gls{oaipmh}, \gls{cts}, \gls{dts}). Ceux-ci définissent la sémantique des requêtes (c'est-à-dire les paramètres autorisés) et la manière de construire un \gls{url} pour accéder à certaines données. Ils permettent donc l'interopérabilité, puisqu'une même syntaxe peut être utilisée pour requêter différentes \api{}. Ni le \gls{rest}, ni les standards d'interopérabilité ne définissent l'implémentation d'une \api{}: les deux types de standards s'intéressent à l'interaction du client avec l'\api{}, ils ne définissent pas l'application en elle-même. Une application qui se conforme à un standard garantit simplement un certain type d'interaction client-serveur. En plus de ces deux standards qui sont ici présentés, les principes \gls{fair}: ceux-ci ne définissent ni implémentation, ni sémantique, mais sont simplement des principes généraux pour la manière dont des données doivent être partagées dans un contexte de science ouverte et réutilisable.

\section{Que faire du FAIR? Le partage des données de la recherche}
Les principes \gls{fair}\footcite{boeckhout_fair_2018} sont essentiels aux problématiques de la science ouverte. Celle-ci encourage non seulement la diffusion de la recherche dans des formats traditionnels (articles, conférences...), mais aussi la diffusion de données brutes issues de la recherche scientifique. L'objectif, dans la diffusion de ces données brutes, est de rendre les données réutilisables, mais aussi de permettre la reproductibilité de la recherche, et donc la vérification des résultats obtenus. 

La problématique de la diffusion de données de recherche brutes se retrouve bien sûr en humanités numériques. Dans le domaine de la reconnaissance optique de caractères, par exemple, se développe le partage de vérité de terrain, comme cela a été évoqué en première partie de ce mémoire. La reconnaissance de caractères est permise par l'entrainement d'un algorithme d'apprentissage machine sur des textes qui ont été transcrits manuellement; c'est ce couple texte numérisé/transcription qui constitue la vérité de terrain. Or la production de ces données demande beaucoup de temps ainsi que des compétences spécifiques pour des graphies difficiles à lire et des langues rares\footnote{Un exemple de ces corpus \enquote{difficiles} est le développement de la reconnaissance optique de caractères pour le Cham, langue parlée par une minorité originaire du Sud-Est de l'Asie. Celle-ci comprend environ 30000 locuteurs. Le projet travaille également à la reconnaissance du Cham ancien, qui est extrêmement méconnu (\cite{schweyer_analyse_2022}).}. Pour faciliter le développement de méthodes de reconnaissance optique de caractères se développent donc des initiatives pour faciliter le partage de vérités de terrains. Parmi ces initiatives se trouve le projet \textit{HTR United}\footcite{chague_sharing_2022}, qui offre un portail pour l'accès à et le dépôt de vérités de terrains. Celles-ci sont partagées avec des métadonnées précisant par exemple leur contexte de production, le domaine auquel appartient au corpus.

La diffusion de données de recherche est cependant une opération plus complexe qu'il ne pourrait y paraître; c'est pourquoi les principes \gls{fair} ont été édités en 2014\footcite[p. 931]{boeckhout_fair_2018}. Ils forment une base minimale de recommandations sur la manière de partager des données de recherche. Cette base minimale est composée de quatre principes\footcite[p. 932-933]{boeckhout_fair_2018}: 

\begin{itemize}
	\item \textit{Findability}: les jeux de données doivent être diffusés sur des dépôts publics; ils doivent être décrits avec suffisamment de métadonnées pour que leur périmètre et la manière dont ils ont été constitués soient clairement identifiables.
	\item \textit{Accessible}: les jeux de données doivent être accessibles librement et idéalement de façon manuelle aussi bien qu'automatique.
	\item \textit{Reusable}: les jeux de données doivent être réutilisables. Cela implique de définir un périmètre pour la réutilisation des données, notamment au travers de licences.
	\item \textit{Interoperable}: les jeux de données doivent être diffusés dans des formats structurés, compréhensibles par des humain.e.s et, idéalement, manipulables par des machines.
\end{itemize}

Qu'en est-il de la relation entre ces principes et la conception d'\api{}? La diffusion automatisée par le biais d'applications semble aller main dans la main avec les principes \gls{fair}. Une \api{} permet de diffuser automatiquement des données brutes et structurées dans des formats interopérables. Cependant, une telle application n'adhère pas par défaut aux principes \gls{fair}. Elle garantit l'accessibilité des données; pour qu'elles soient réutilisables, la conception d'\api{} doit être considérablement étoffée. Il faut en effet définir le contexte de production des données, ainsi que la licence dans laquelle elles sont diffusées. Il est donc nécessaire d'ajouter des métadonnées aux réponses de l'\api{} ou de trouver un moyen de documenter les conditions de réutilisation des données. La notion de \enquote{dépôt public} requis par les principes \gls{fair} pour partager des données change également de sens. L'\api{} sert pas à partager les données sur un autre dépôt qui agrège des jeux de données, elle sert à les diffuser à des utilisateur.ice.s. Une \api{} pour la recherche forme donc sa propre plateforme de diffusion des données. Enfin, il faut garantir que les données soient compréhensibles. Cet aspect des principes \gls{fair} n'est pas anodin dans la conception d'une \api{}. Non seulement celle-ci doit renvoyer des réponses structurées et valides; la sémantique des réponses doit également être explicitée. Cela veut dire que, soit dans l'\api{}, soit dans la documentation, le sens de chaque élément doit être précisé. La documentation est ici importante; mais l'utilisation de la \tei{} est également intéressante en vue de ce besoin de produire des données compréhensibles. Ce standard, en plus d'être très pratiqué dans les humanités numériques, est défini dans les \textit{TEI Guidelines}\footcite{tei_consortium_p5_2022} et dispose donc d'une documentation officielle. Au delà de ces principes abstraits, de véritables standards techniques peuvent servir d'inspiration dans le développement d'\api{} pour diffuser des données de recherche.

\section{Le REST: un modèle pour le design d'API}
Ici est présenté le standard REST, défini par Roy Fielding\footcite{fielding_architectural_2000}; ce standard architectural est considéré comme l'idéal à atteindre en matière de design d'\api{}. Il n'a cependant pas été entièrement suivi ici, en partie parce qu'il est mieux adapté à un projet de plus grande échelle, et en partie car il repose sur un contrôle avancé de l'architecture client serveur, ce qui n'est pas le cas ici. Le \gls{rest} a donc été implémenté de façon réfléchie lorsque cela était pertinent pour le projet.

Le standard \gls{rest} (\enquote{État de transfert représentatif}) est un standard et un style pour la conception d'\api{} dans une architecture client-serveur. Il est aujourd'hui un standard de fait pour la conception de tels outils, et est considéré comme une bonne pratique dans l'architecture d'\api{}. Le \gls{rest} ne définit pas comment une \api{} doit être implémentée, mais définit la structure de l'interaction client-serveur. Historiquement, le développement de ce standard est fortement lié à l'établissement du protocole \gls{http}, puisque le concepteur du \gls{rest} est l'un des ingénieur.e.s à l'origine du protocole. Le \gls{rest} définit un ensemble de cinq contraintes supplémentaires à celles présentes dans le protocole \gls{http}\footcite[p. 94]{fielding_architectural_2000}. Une \api{} \gls{rest} doit répondre aux contraintes suivantes:

\begin{itemize}
	\item Être sans état\footcite[p. 78-79]{fielding_architectural_2000}. Cela signifie qu'une requête du client au serveur doit contenir l'ensemble des informations nécessaires au traitement de la requête. Le serveur ne peut accéder à un contexte ou à d'autres informations pour traiter la requête. Cela permet de rendre les requêtes plus faciles à interpréter, limite le risque d'erreurs et permet à l'\api{} de fonctionner à plus grande échelle, puisqu'elle n'a pas besoin d'utiliser de les ressources pour chercher des informations ailleurs que dans la requête.
	\item Présenter une interface uniforme\footcite[p. 81-82, 86-97]{fielding_architectural_2000}. C'est peut-être ce principe qui est définitoire du \gls{rest}: l'interface, c'est-à-dire la partie de l'\api{} qui est exposée au client, doit toujours être la même. Il y a donc un découplage entre la communication avec le client (réception des requêtes et envoi des réponse) et le traitement des requêtes, qui ne sont pas accessibles au client. Cette séparation permet de modifier la manière dont une requête est traitée sans devoir changer la sémantique et la structure de l'interaction avec le client. Ce principe implique d'autres contraintes:
	\begin{itemize}
		\item L'identification des ressources dans des requêtes: un client requête une \gls{uri} et le serveur lui renvoie une représentation de cette \gls{uri}. Dans le contexte du Web, cela veut dire qu'un \gls{url} doit nécessairement être fourni au moment de la requête et que celui-ci doit pointer vers les ressources à traiter.
		\item Les ressources sont communiquées sous la forme de représentations. Cela veut dire que les données envoyées au client peuvent être dans une structure ou un format différents de ceux de la base de données: l'\api{} doit traduire les données telles qu'elles sont dans la base en leur représentation.
		\item Les réponses \gls{http} doivent être auto-descriptives: les en-têtes et le corps de la requête doivent contenir assez de (méta-)données pour pouvoir être manipulées par le client sans avoir besoin d'informations extérieures.
		\item Utilisation de l'hypermédia comme moteur de navigation. Comme sur un site Web normal, des hyperliens doivent permettre de naviguer d'une ressource à l'autre et doivent être accessibles directement depuis l'\api{}.
	\end{itemize}
	\item Autoriser la mise en cache explicite\footcite[p. 79-81]{fielding_architectural_2000}. Une réponse du serveur au client doit explicitement indiquer si les données contenues dans une réponse peuvent être mises en cache (c'est-à-dire, stockées dans la mémoire pour être accédées plus tard). La possibilité de cacher les données peut potentiellement diminuer le nombre de requêtes envoyées au serveur.
	\item Présenter une architecture en couches\footcite[p. 82-84]{fielding_architectural_2000}. Une application peut être entièrement stockée sur un serveur, ou fonctionner par l'interaction de différents serveurs. Dans ce cas, un client peut être connecté à différents serveurs, mais ne doit pas savoir s'il se trouve sur un serveur intermédiaire ou un serveur final. Les serveurs intermédiaires peuvent modifier les messages à renvoyer au client, répartir les charges sur différents serveurs ou établir des politiques de sécurité.
	\item Diffuser du code à la demande (optionnel)\footcite[p. 84-85]{fielding_architectural_2000}.
\end{itemize}

Les concepts centraux dans ce système architectural -- du moins, pour une petite \api{} comme celle de \ktb{} sont le fait d'être sans état et l'uniformité de l'interface. Ces deux concepts signifient que les requêtes comme les réponses doivent être entièrement auto-descriptives. Les autres principes sont mieux adaptés à des \api{} à plus grande échelle: la mise en cache explicite suppose que la même requête puisse être envoyée en série par un client à un serveur; pour une \gls{api} d'un projet de recherche, il est plus probable qu'une requête soit faite une unique fois pour récupérer des données. L'utilisation d'une architecture en couches n'est pas du ressort de \textit{KatAPI}, puisque l'intégralité de l'\api{} est présente sur un seul serveur. Enfin, la diffusion de code exécutable n'est pas non plus adaptée aux données qui sont requêtées et diffusées via l'\api{}: celles-ci sont statiques et ne demandent pas d'être transformées par le client.

La mise au point d'une architecture sans état demande d'établir une sémantique pour les requêtes qui soit auto-descriptive, c'est-à-dire qui décrive l'intégralité de la requête. L'uniformité de l'interface, d'un point de vue de développement applicatif, est une problématique plus complexe. D'abord, elle demande d'établir des modèles de données uniformes pour le corps des réponses \gls{http}. Cela veut dire que, pour chaque format de réponse autorisé et point d'accès aux données possible, les réponses doivent être contenues dans une structure qui est toujours la même. Ensuite, les en-têtes doivent être constitués pour décrire adéquatement la réponse. Cela passe par la définition d'un statut \gls{http} et d'un type MIME à chaque réponse. Ainsi, une machine peut savoir quel format de réponse est obtenu, et comment la requête s'est déroulée. Cependant, l'utilisation d'hyperliens comme moteur de l'application n'a pas été implémentée: les réponses ne contiennent pas d'hyperliens qui permettent de naviguer automatiquement vers d'autres ressources ou actions. L'ensemble des ressources accessibles et la manière d'y accéder sont au contraire définies de façon centralisée dans la documentation de l'\api{}, qui n'est pas lisible par une machine. Enfin, du point de vue de l'implémentation, la communication client-serveur est indépendante du traitement des requêtes et de l'interaction avec les bases de données.

Par conséquent, les choix techniques mis en place font de l'\api{} une application \textit{RESTlike} (c'est-à-dire, qui se conforme à un certain degré aux principes REST), voire \textit{RESTful} (qui se conforme entièrement aux principes REST). \textit{KatAPI} suit le standard REST là où il est pertinent pour les données transmises (ce qui exclut la condition de transmission de code et la clause de mise en cache). L'\api{} suit également les principes \gls{rest} là où il est de son ressort de les suivre (ce qui exclut une architecture en couches, puisque l'application est distincte de son installation sur un serveur). Suivre ces principes et s'en inspirer permet de concevoir une application au comportement uniforme, et où le client n'a pas à vérifier les réponses obtenues, puisqu'elles seront toujours les mêmes et qu'elles contiendront toutes les informations nécessaires à leur traitement (format de réponse, statut HTTP...).

\section{OAI-PMH, CTS et DTS: quels standards pour le partage du texte en humanités numériques?}
\sectionmark{OAI-PMH, CTS et DTS}
Les principes REST, présentés ci-dessus, concernent l'architecture et le design d'une \api{}; cependant, ils ne s'attaquent pas à une autre partie du problème: l'interopérabilité de ces applications. Chacune d'elles définit sa propre sémantique pour les requêtes et autorise certains formats de réponse. Cela conduit à un problème pour les programmes consommateurs d'\api{}: l'interaction avec deux \api{} demande la construction de requêtes différentes, et demande donc d'apprendre à utiliser différentes sémantiques. Lorsque celles-ci sont complexes, apprendre à utiliser une \api{} n'a rien d'anodin, et se servir de différentes \api{} en même temps devient difficile. De plus, l'absence d'interopérabilité signifie qu'il est difficile, voire impossible, de travailler de la même manière avec les données issues d'\api{} différentes. Si l'une renvoie du \json{} mais l'autre du \xml{}, par exemple, les résultats issus des deux \api{} doivent être utilisés différemment. Cela complexifie la convergence des données de la recherche et limite l'interopérabilité de ces données, ce qui est pourtant l'un des principes \gls{fair}\footcite[p. 932-933]{boeckhout_fair_2018}. Pour faire face à ce problème, des standards d'interopérabilité ont été développés. Ceux-ci définissent à minima une sémantique unique qui peut être implémentée par plusieurs \api{}. Parfois, ils définissent également des formats de réponse. Le plus célèbre de ces standards, dans les humanités, est le protocole IIIF, qui permet d'interagir avec une image (en lui ajoutant une couche d'annotations, par exemple). Dans les humanités centrées sur le texte, les standards d'\api{} sont plus diversifiés. Trois sont présentés ici: l'\gls{oaipmh}, le \gls{cts} et le \gls{dts}. Aucun d'entre eux n'a été adopté dans la conception de l'\api{} \ktb{}, mais ils sont tous riches de leçons dans le développement d'une telle application

\subsection{OAI-PMH: un premier standard à succès}
L'\gls{oaipmh} vient du monde des archives et des bibliothèques. Les bibliothèques ne conservant pas des objets uniques, mais des documents produits en série, elles sont pionnières dans le développement de méthodes computationnelles pour le partage des données\footcite[p. 2-3]{prime-claverie_defi_2017}. Aussi ce standard a-t-il connu une adoption inégalée, puisqu'il est aujourd'hui le standard d'interopérabilité le plus utilisé dans les bibliothèques\footcite[p. 5]{prime-claverie_defi_2017}; il est également utilisé par les plateformes en ligne HAL, OpenEditions ou encore CAIRN. Ce standard vise à permettre l'interopérabilité sémantique (uniformiser la sémantique des requêtes et des réponses) et technique (uniformiser les formats de réponse)\footcite[p. 6-14]{prime-claverie_defi_2017}. Il ne vise cependant pas à partager des documents, mais seulement leurs métadonnées (en d'autres termes, l'\gls{oaipmh} ne permet pas de partager un document, mais seulement sa notice bibliographique); il ne permet pas non plus de partager des données sur un document, mais sur une collection entière. Les réponses de l'\gls{oaipmh} sont constituées de collections de notices encodées en XML; l'interopérabilité sémantique des réponses est permise par l'utilisation du Dublin Core, un format considéré comme un plancher pour le partage de données bibliographiques. L'interopérabilité technique, elle, repose sur un format de réponse en \xml{}\footcite[p. 4]{prime-claverie_defi_2017}. Comme le montrent Prime-Claverie et Mahé, cette interopérabilité n'empêche cependant pas une grande variété dans les implémentations: certaines utilisent des réponses en \xmltei{}, d'autres non; les structures des réponses varient elles-aussi, avec différents éléments Dublin Core associés à différentes données\footcite[p. 6-14]{prime-claverie_defi_2017}. D'un point de vue technique, le fonctionnement d'\gls{oaipmh} est intéressant: l'entrepôt \gls{oaipmh} est distinct de la base d'où il récupère les données. Cela veut dire que, lorsqu'une requête est reçue, l'\api{} la communique à l'entrepôt \gls{oaipmh} qui transforme les informations contenues dans la base de données. D'un point de vue d'ingénierie, cela veut dire que les parties de ce système (base de données -- entrepôt \gls{oaipmh} -- \api{}) sont distincts\footcite[p. 4]{prime-claverie_defi_2017}. Par conséquent, les données n'ont pas besoin d'être stockées dans des formats compatibles; des transformations dans une partie n'impliquent pas de devoir transformer les autres parties (sauf pour permettre l'interaction entre les différents éléments du système). Par exemple, une modification de la structure de la base de données ne demande pas de transformer toute l'\api{}, mais seulement la manière dont les données sont transformées pour être compatibles avec le standard \gls{oaipmh}. 

Que retenir de cet exemple? Tout d'abord, que ce n'est pas parce qu'un standard existe qu'il sera implémenté uniformément. Une marge de manœuvre est toujours présente, ce qui peut amener à des résultats très différents. Bien sûr, cela va à l'encontre du principe d'interopérabilité et complexifie la convergence des ressources d'origine différente. Cependant, comme le rappellent Prime-Claverie et Mahé\footcite[p. 15-16]{prime-claverie_defi_2017}, ces variations ne sont pas nécessairement problématiques. Elles permettent aux différentes institutions qui implémentent un standard de fournir des données adaptées à certaines communautés de pratique -- il va de soit qu'une archive et une bibliothèque sont deux institutions très différentes, et qu'elles ne peuvent représenter leurs documents de la même manière. L'implémentation technique de l'\gls{oaipmh} est également intéressante: elle sépare les données (dans une base de données) de leur représentation. Ce qui est communiqué au client, c'est cette représentation, compatible avec le protocole \gls{oaipmh}. Cette idée, qui rappelle les principes \gls{rest}, est mise en place d'autres standards présentés ici. D'un point de vue de développement, la séparation entre les différentes parties nécessaires au fonctionnement de cette \api{} facilitent également son maintient et l'ajout de nouvelles fonctionnalités, puisque le système ne doit pas être modifié lorsque c'est seulement un élément qui est affecté. Cependant, l'\gls{oaipmh} n'est pas adapté aux besoins de \ktb{}: ce standard ne permet pas d'échanger du texte, mais seulement des métadonnées. De par sa taille, il est également difficile à implémenter pour un projet de recherche.

\subsection{CTS, DTS: des méthodes de standardisation pour l'échange de texte}
Le \gls{cts} a été développé dans un contexte très différent de l'\gls{oaipmh}. Il est issu d'un projet de recherche à Harvard, le \textit{Homer Multitext}, consacré à l'édition de l'\textit{Illiade} et de l'\textit{Odyssée} d'Homère. Le standard est donc pensé pour l'édition de textes canoniques antiques. Il naît d'un problème technique: comment faire coïncider la structure en arbre d'une édition numérique avec la structure citationnelle traditionnelle, où les citations font références à des pages. Aux origines du projet se trouve également l'idée qu'un texte existe à l'intérieur d'un système citationnel, où les textes fonctionnent par référence les uns aux autres\footcite{smith_four_2012}. Cette idée est particulièrement importante dans un projet d'édition critique, comme le \textit{Homer Multitext}, où les différents témoins des textes d'Homère doivent pouvoir être alignés et comparés. La \tei{} a développé ses propres systèmes de référence pour les éditions critiques, basés sur le concept d'arbres décisionnels (où chaque témoin peut être représenté par une feuille, et où les différentes feuilles viennent d'une branche commune)\footcite{tei_consortium_p5_2022}. Mais ce système ne permet pas de cibler efficacement un passage dans un texte, ni de faire référence à ce passage en dehors du document lui-même. Comment, dans ce cas, représenter des références dans une édition numérique? Comment rendre des parties de texte accessibles à l'extérieur d'un texte, dans une architecture client-serveur? 

La réponse proposée à l'initiative de Smith et Blackwell est le \gls{cts}. Ce système définit une sémantique permettant d'identifier un texte, un passage de texte ou même un ensemble de textes grâce à une \gls{uri}. Celle-ci cible de plus en plus précisément le passage voulu. Par exemple, \texttt{urn:ctsl:greekLit:tlg0012.tgl001.msA} permet de cibler, à l'aide d'un identifiant \gls{cts}, le manuscrit \texttt{msA} du texte \texttt{tlg0012.tgl001} du corpus \texttt{greekLit}\footcite{smith_four_2012}. L'intérêt de ce système de pointeurs vers un texte est qu'il peut être adapté au Web, en précédent l'identifiant ci-dessus de l'\gls{url} d'une \api{} supportant le standard \gls{cts}. Il est donc possible de cibler précisément et de récupérer un texte depuis un dépôt particulier. L'intérêt de ce système est également qu'il est généralisable à d'autres corpus; le standard a donc été adapté par plusieurs \api{}, qui ont dû définir leurs propres implémentations de ce standard: là où le standard est implémenté, il est possible d'accéder à l'aide d'une sémantique unique à n'importe quel(s) texte(s). Parmi ces implémentations peut être cité \textit{CapiTainS}, développée pour la \textit{Perseus Digital Library} et l'\textit{Open Philology Project}\footcite{almas_continuous_2018}. \gls{cts} est donc intéressant d'un point de vue de son ingénierie, puisqu'il permet la convergence des méthodes de partage et de diffusion du texte. Le standard est également intéressant d'un point de vue de la représentation du texte, puisqu'il permet de représenter un texte comme étant un graphe de citations et de références (une citation correspondant à une \gls{uri} reliée à une autre par un prédicat). Ce système de représentation permet donc de s'éloigner de la structure hiérarchique des éditions numériques en \tei{}, une représentation critiquée depuis ses débuts parce qu'elle impose un ordre hiérarchique unique à un texte, pourtant irréductible à une seule interprétation\footcite{renear_refining_1996}.

Le standard \gls{cts} n'est cependant pas parfait, et plusieurs critiques peuvent lui être faites. D'un point de vue de son développement, c'est un standard qui a été conçu dans une certaine communauté de pratique, et qui n'est donc pas adaptable à tous les textes; ensuite, c'est un format qui a été développé pour répondre aux besoins de chercheur.euse.s, et qui ne suit donc pas les meilleures pratiques en termes de conception d'\api{}. Par exemple, il ne définit pas de formats de données à utiliser pour la réponse à renvoyer à l'utilisateur.ice\footcite[p. 2]{almas_distributed_2021}. La \tei{} n'est donc pas requise, peut-être du fait de la critique faite par Smith et Blackwell des représentations hiérarchiques du texte. Si cela peut avoir un intérêt de ne pas vouloir \enquote{enfermer} le texte dans une hiérarchie qui lui est étrangère, ne pas utiliser la \tei{} pour une édition nativement numérique aujourd'hui est un choix pour le moins surprenant: ce standard dispose d'une très grande communauté d'utilisateur.ice.s, et est au cœur des humanités numériques centrées sur le texte. Le fait de ne pas imposer de format unique amène à beaucoup de variété dans les implémentations, ce qui s'oppose à un objectif de convergence des initiatives et ne garantit pas l'interopérabilité technique entre les \api{}. De fait, les implémentations de \gls{cts} varient beaucoup, comme le montre l'exemple de \textit{CapiTainS}, qui lui rend obligatoire l'utilisation du format \xml{} dans les réponses de l'API. 

C'est pourquoi un nouveau standard a été développé: le \gls{dts}. Alors que le \gls{cts} existe depuis une décennie, la première version publique du \gls{dts} a été publiée en 2018. Elle est basée sur le même principe que le standard précédent: une sémantique standardisée permet à une \gls{uri} de représenter un ou plusieurs (extraits) de texte. Plusieurs ajouts ont été faits à son prédécesseur. Le plus notable est l'obligation d'utiliser le \xmltei{} dans les réponses de l'\gls{api}\footcite[p. 3]{almas_distributed_2021}, ce qui garantit l'interopérabilité des ressources distribuées. Le standard cherche également à intégrer les meilleures pratiques en matière de développement Web, en utilisant des formats sémantiques (comme le \texttt{JSON-LD}) et en encourageant le développement d'\api{} RESTful. Ce standard est également considérablement plus complexe que le \gls{cts} puisque l'\api{} peut offrir plusieurs points d'accès aux texte; ces points d'accès correspondent à différents niveaux de la collection (allant de la collection dans son ensemble au document). Bien que récent, le format a été implémenté par plusieurs projets, dont \textit{TEI Publisher}, une application en ligne visant à publier des données de recherche en \tei{}.

Ces deux standards sont intéressants, mais ne sont pas adaptés à \textit{KatAPI}. D'abord, leur implémentation complexifie considérablement la conception d'une \api{}, et son utilisation est peut-être plus adaptée à des initiatives faisant converger plusieurs projets. Mais le principal problème posé par les trois standards présentés ici est qu'ils sont tous développés pour partager des textes réels, qui ont une existence \enquote{en dehors de l'API}. Or, \textit{KatAPI} n'est pas seulement censée partager des textes issus du projet (c'est-à-dire, des catalogues ou des extraits de ceux-ci). Elle doit tout aussi bien partager des données de recherche issues du projet et construire des extraits du corpus en fonction des requêtes des utilisateur.ice.s. Cette \api{} repose donc, comme nous le verrons, sur la création de documents \textit{ex-nihilo} à partir de l'agrégation et de la transformation d'autres documents. Les critères bibliographiques servant à situer texte ou extrait dans une collection ne sont donc pas entièrement pertinents ici. L'\api{} doit fonctionner comme un moteur de recherche plutôt que comme un catalogue dans lequel il est possible de sélectionner une ou plusieurs ressources. Cependant, les standards \gls{cts} et \gls{dts} présentent des bonnes pratiques, et de nombreux enseignements sont à en tirer. D'abord, il est nécessaire de proposer une réponse en \xmltei{}, puisque ce standard de fait peut permettre de faire converger des données issues de différents projets. De \gls{cts} ressort l'intérêt de proposer plusieurs points d'accès au corpus, qui correspondent à différentes échelles dans celui-ci. Il n'existe pas une seule voie d'accès pour un texte, et c'est pourquoi ce principe sera suivi pour \textit{KatAPI}. De \gls{cts} et \gls{dts}, il faut également retenir l'utilisation de l'\gls{url} comme d'un pointeur, à la sémantique clairement définie, vers les ressources pertinentes (un principe déjà énoncé dans le protocole HTTP). Enfin, des trois standards présentés ici, il faut retenir le principe de la \textit{separation of concerns} (\enquote{séparation des préoccupations}). Ce principe central du développement applicatif est très bien exemplifié dans le fonctionnement d'\gls{oaipmh}: la base de donnée est distincte de l'entrepôt \gls{oaipmh} qui est lui-même distinct de la partie de l'\api{} chargée de recevoir des requêtes et de transmettre des réponses au client. Ce principe permet de minimiser l'impact d'un processus sur un autre et de réduire les relations entre les parties d'un programme à un strict minimum. C'est un concept qui a été suivi dans l'architecture de \textit{KatAPI}, où la réception et l'analyse des requêtes, la récupération des données, la construction des réponses et l'envoi de celle-ci à l'utilisateur.ice sont distinctes.

\section{Pour qui sont ces API? Qu'est-ce qui est demandé d'un tel outil?}
\sectionmark{Pour qui sont ces API?}
Cette dernière question n'est pas anodine. Il semblerait en effet que relativement peu d'\api{} soient développées dans des contextes d'humanités numériques; celles qui sont développées sont plutôt le fait de grandes institutions -- comme le projet \textit{Europeana}, ou la Bibliothèque nationale de France -- et de plateformes partagées qui adoptent le standard \gls{oaipmh}. Il existe également de nombreux services nécessitant l'utilisation d'\api{}, comme les serveurs IIIF permettant le partage d'image, et les serveurs \gls{dts} qui commencent à se développer. La conception d'\api{} semple être le fait d'infrastructures qui disposent de grands volumes de données et de ressources permettant de planifier et d'implémenter de tels outils sur le long terme. 

Une étude réalisée dans le cadre du projet \textit{Europeana} aide à situer le statut des \api{} dans les humanités numériques. Cette étude offre un point de vue intéressant, puisqu'elle s'appuie sur des entretiens avec des chercheur.euse.s issue.e.s des humanités numériques et des humanités s'appuyant sur des méthodes quantitatives. Cette étude arrive à un constat pessimiste: les chercheur.euse.s ne sont pas des utilisateur.ice.s d'\api{}\footcite[p. 288]{edmond_apis_2015}. Même lorsque leurs recherches s'appuient sur le traitement de données, voire sur l'usage de méthodes computationnelles (traitement statistique à l'aide de \py{} ou \texttt{R}), ces personnes ont tendance à récupérer leurs données manuellement; ce qui leur importe, c'est les données, et non la manière d'y accéder\footcite[p. 290]{edmond_apis_2015}. Les \api{} sont, à l'inverse, beaucoup plus utilisées par des ingénieur.e.s et des personnes ayant eu une formation technique. Au delà de ce constat, l'étude propose des réflexions intéressantes sur le statut des \api{} dans les humanités en général et les humanités numériques en particulier. Trois critères sont identifiés pour la décision d'utiliser une source de données en recherche\footcite[p. 292-294]{edmond_apis_2015}:

\begin{itemize}
	\item Les données. Le critère de choix principal est la qualité et la complétude des données et des métadonnées.
	\item L'expertise technique nécessaire. Ce critère est relativement logique: un.e chercheur.euse n'utilisera une \api{} que si il ou elle a le moyen de le faire. Un problème ici est la méconnaissance des \api{} par les chercheur.euse.s, qui peuvent ne même pas connaître l'existence de tels outils. Cependant, l'étude remarque que, une fois qu'ils ont connaissance de telles sources, les chercheur.euse.s n'hésitent pas à se former à l'utilisation d'\api{}.
	\item Les environnements sociaux et techniques des chercheur.euse.s. Le critère précédent décrit des capacités réelles, alors que celui-ci traite de la perception. Plus un.e chercheur.euse perçoit que des outils techniques sont difficiles d'accès, moins il ou elle est susceptible de les utiliser. 
\end{itemize}

Pourquoi, alors, développer une \api{}? Au vu du volume du corpus, il peut être intéressant d'y avoir accès de façon automatisée. Avant le développement de cette \api{}, la seule manière d'accéder à des données brutes était de les télécharger sur les dépôts GitHub du projet. Dans ce cas, il est uniquement possible de récupérer un fichier complet, c'est-à-dire un catalogue entier ou un jeu de données portant sur l'ensemble du corpus. La seule manière d'accéder à des données sélectionnées et filtrer en fonction de ses besoins est de passer par l'application Web \enquote{pour huamin.e.s}, mais celle-ci ne permet pas de télécharger les données brutes. Au sein du panorama d'outils développés pour le projet, les méthodes de diffusion de données manquaient. C'est pourquoi une \api{} a été développée. Plus largement, les \api{} peuvent être particulièrement utiles pour un projet de recherche et pour l'application des principes \gls{fair} en humanités numériques. Une \api{} diminue, sur le long terme, le travail nécessaire pour diffuser des données. Dans le cas d'une \api{} \enquote{réactive}, qui construit des documents sur mesure, elle permet également d'explorer des sous-catégories, ou des sections du corpus. Une telle \api{} peut permettre la création de nouveaux jeux de données à la demande, ce qui est d'un intérêt certain.

L'étude d'Edmond et Garnett citée ci-dessus ne doit pas être prise avec pessimisme, indiquant que l'outil que l'on développe ne sera jamais utilisé. Au contraire, les critères socio-techniques qu'elles mettent en avant derrière l'utilisation d'une \api{} permettent de mieux adapter l'outil développé aux besoins. Il est nécessaire, lorsque cela est possible, de développer un outil qui diminue la distance perçue par les chercheur.euse.s. Pour cela il faut documenter l'application, de façon claire et, lorsque cela est possible, concise. Ensuite, il faut chercher à montrer que l'utilisation d'une \api{} n'est pas très compliquée: il peut être intéressant de concevoir des tutoriels, ou, comme cela a été fait pour \textit{KatAPI}, des méthodes pour tester l'\api{} en temps réel. Depuis la page de documentation, il est possible de composer un \gls{dictionnaire} contenant les paramètres pour lancer une requête. Une fois la réponse reçue, le résultat s'affiche sur la page. De cette étude, il faut également retenir que une \api{} ne sera utilisée que si elle offre l'accès à des données de qualité. Cela va dans le sens des principes \gls{fair}: pour partager des données, celles-ci doivent être documentées et éditorialisées pour qu'un.e chercheur.euse sache quelles données seront reçues et envisage des manières de les utiliser.

Une autre étude\footcite{corral_towards_2014}, menée sur des \api{} généralistes, permet également de mieux comprendre le terrain pour de tels outils. Cette étude est basée sur l'analyse statistique des réponses obtenues obtenues pour 10955 \textit{Buisness APIs}, terme qui recoupe des applications développées par des entreprises (comme l'API de \textit{Twitter}), à but commercial (comme l'API de \textit{PayPal}), mais aussi des \api{} créées à but non-lucratifs (comme celle de \textit{Wikipedia}). L'étude date d'il y a quelques années, et il est donc possible que les tendances de design d'\api{} aient évoluées depuis. Les statistiques coincident cependant avec mon expérience de ces outils. Les résultats obtenus permettent de mieux comprendre quelles sont les tendances actuelles en terme de design d'\api{}. Les deux formats de réponse dominants sont le \json{} et le \xml{}: 81,08\% des applications proposent l'un ou l'autre format. Seules 21,37\% utilisent les deux formats, ce qui est le cas de \textit{KatAPI}. Un autre fait intéressant est que une immense majorité d'\api{} sont \textit{RESTlike}\footcite[p. 3]{corral_towards_2014}. Contrairement aux API \textit{RESTful}, les API \textit{RESTlike} sont inspirées par les principes \gls{rest} sans nécessairement les appliquer totalement. Ce terme s'est développé du fait de l'implémentation très inégale du standard. Le problème est que le terme \textit{RESTlike} est nécessairement imprécis; il est donc difficile de tirer une conclusion de cette statistique: dans une large mesure, les principes \gls{rest} ont servi au développement de \textit{KatAPI}. Quoi qu'il en soit, \textit{KatAPI} semble s'inscrire, par les formats utilisés et les principes architecturaux suivis, dans le paysage actuel des \api{}.

Les standards et études présentés ici permettent de mieux cerner le statut des \api{} centrées sur le texte en humanités numériques; elles permettent également d'identifier des tendances dans le desgin d'\api{} ainsi que les besoins des utilisateur.ice.s. En ayant cette compréhension du paysage technique pour ces applications, il est possible de définir clairement le périmètre de l'\api{} et la manière dont l'interaction client-serveur doit s'organiser, dans la sémantique des requêtes autant que dans les réponses obtenues.

\chapter{Définir un périmètre: que partager, et comment partager?}
\chaptermark{Définir un périmètre}
Après avoir présenté le paysage des \api{} en général et le statut de ces outils dans les humanités numériques en particulier, ce chapitre décrit \textit{KatAPI} du point de vue de l'utilisateur.ice: quelles données peuvent être obtenues via l'\api{}, quels paramètres de recherche sont autorisés et quels sont les formats de données retournés par l'application. C'est donc les principes de la communication client-serveur de \textit{KatAPI} qui sont ici présentés.

\section{Grands principes pour l'architecture de l'\api{}}
Pour plus de clarté, ici sont présentés de façon concise l'ensemble des principes auxquels l'application doit se conformer; ceux-ci forment une sorte de cahier des charges pour son implémentation technique.

\begin{itemize}
	\item L'application supporte uniquement la méthode \gls{http} \texttt{GET}: il est uniquement possible de demander des données à l'application, et non d'ajouter des données à une base de données, par exemple.
	\item L'application supporte deux formats de réponse: \json{} et \xmltei{}. Le format par défaut est le \json{}, pour sa légèreté et sa facilité de manipulation. Dans les deux cas, la structure des réponses est la même: un en-tête qui décrive le contexte de la réponse (à ne pas confondre avec les en-têtes \gls{http}) et un corps, qui contient les données récupérées.
	\item Trois niveaux d'accès aux données sont possibles. Il est possible de faire une requête pour un catalogue entier; des statistiques sur un ou plusieurs catalogues; une ou plusieurs entrées de catalogues.
	\item L'application suit le principe de séparation des préoccupations. L'interaction avec le client, le traitement des requêtes et la base de données sont des parties distinctes qui ne communiquent que lorsque cela est nécessaire.
	\item L'\api{} suit les principes \gls{rest} lorsque cela est possible. Elle est sans état et présente une interface uniforme. Cela veut dire que, pour les trois niveaux d'accès aux données, trois modèles de données seulement existent et sont adaptés en \json{} et \xmltei{}.
	\item L'application a un traitement strict des requêtes. Une requête n'est pas traitée si elle contient des paramètres non-autorisés (qui ne font pas partie de la sémantique définie pour l'interaction client-serveur), ou des valeurs associées à ces paramètres qui ne sont pas autorisées.
	\item L'application envoie des réponses précises et auto-descriptives, même en cas d'erreur. Plusieurs statuts \gls{http} sont définis pour différents cas de figures; si erreur il y a, un message d'erreur complet et décrivant le contexte et les raisons de l'erreur est renvoyé par l'\api{}. Cette erreur constitue un document \json{} ou \xmltei{} valide.
\end{itemize}

\section{Quelles données partager?}
À différentes étapes, une grande variété de données ont été produites; de plus, différentes manières d'accéder aux données ont été constituées par le projet. Par exemple, un système de réconciliation des différentes entrées de catalogue permet d'identifier lorsqu'un manuscrit est vendu plusieurs fois, et que celui-ci est donc présent dans différents catalogues. Cela permet de regrouper ensemble différentes occurrences d'un même manuscrit. Ce type de données pourrait être partagé, de même que les données extraites de \sparql{} et présentées dans la partie précédente. Cependant, la mise à disposition de différents types de données est difficile tout en se conformant au principe d'uniformité de l'interface du \gls{rest}. En effet, chaque source de données a sa propre structure. Il donc est nécessaire, pour chaque source de données, de définir une représentation en \json{} et en \tei{}. Pour se conformer à l'objectif originel du projet \mssktb{} (étudier des catalogues en vente), il a été choisi de ne diffuser que des données issues des catalogues à travers l'\api{}. Cela élimine donc les données issues de \sparql{}. Pour ne se conserver qu'une seule représentation par type de données, il a été choisi de ne pas diffuser non plus de données sur les manuscrits \enquote{réconciliés}, puisque cela amènerait à avoir deux modèles de données pour les manuscrits, selon qu'ils aient été réconciliés ou non. De plus, ce processus de réconciliation prend plusieurs secondes à s'exécuter, ce augmente le temps de réponse de l'\api{} et peut devenir problématique si de nombreuses requêtes sont reçues en même temps par l'application.

Au final, trois niveaux d'accès aux corpus ont été définis. Ceux-ci correspondent à différents degrés de granularité dans le corpus. Chacun de ces formats, enfin, a un modèle de données qui lui est propre. Celui-ci est transposé -- lorsque cela est possible -- à la fois en \xmltei{} et en \json{}. 

\begin{itemize}
	\item Premier niveau: catalogue complet (\texttt{cat\_full}): l'intégralité des données contenues dans un catalogue peut être requêtée. Dans ce cas, il n'est possible que de requêter un catalogue à la fois. Celui-ci doit être clairement identifié à l'aide de son identifiant unique (l'\texttt{@xml:id}). Il est renvoyé dans son intégralité au format \xml{} uniquement: la traduction d'un fichier \xmltei{} complet en \json{} est complexe; de plus, si un.e utilisateur.ice demande un catalogue de façon aussi ciblée, alors il ou elle souhaitera probablement un format plus complexe que le \json{} et pourra tirer parti du balisage sémantique permis par la \tei{}.
	\item Deuxième niveau: statistiques sur une collection de catalogues (\texttt{cat\_stat}): des données statistiques sont retournées pour un ou plusieurs catalogues (prix moyen et médian des items, variance des prix au sein du catalogue, nombre d'items en vente...). En utilisant d'autres paramètres de recherche, il est possible de cibler précisément un sous-ensemble de catalogues, comme ceux issus de la \textit{Revue des autographes...}, ou ceux publiés dans une certaine tranche de dates. Ce degré de granularité permet donc de produire des sous-ensembles pour des études statistiques et thématiques ciblées.
	\item Troisième niveau: au niveau de l'entrée (\texttt{item}). Ce degré permet d'accéder à une ou plusieurs entrées de catalogues, et donc de récupérer l'ensemble des informations contenues dans les catalogues pour ces entrées. Il est possible de cibler des entrées par nom d'auteur.ice, date d'écriture, date de vente ou par identifiant \texttt{@xml:id}, ce qui permet de ne retourner qu'un identifiant. Ce degré de granularité permet donc de constituer des jeux de données restreints, avec par exemple tous les manuscrits écrits par un.e auteur.ice à une certaine période.
\end{itemize}

Chacun de ces degrés d'accès aux données correspond à une source de données différente. Le premier niveau (\texttt{cat\_full}) correspond à un document \tei{} représentant un catalogue dans son intégralité. Ce format permet donc l'accès aux sources directes du projet. Le deuxième niveau (\texttt{cat\_stat}) donne l'accès à un \json{} produit à partir d'une analyse statistique de tous les catalogues. Les entrées pertinentes de ce \json{} sont traduites en \xmltei{} si c'est le format de requête qui est demandé par l'utilisateur.ice. Enfin, le niveau \texttt{item} correspond à deux sources de données: premièrement, les catalogues eux-mêmes (au niveau de l'entrée, et non du catalogue complet); deuxièmement, une représentation en \json{} des entrées de catalogues. Pour accélérer le fonctionnement de l'\api{} lorsque la requête est faite au niveau de l'item, les données en \json{} sont d'abord lues avant, si besoin, d'utiliser la \tei{}. Les trois degrés de granularité des données sont donc centraux à l'architecture de l'\api{}: ils définissent trois bases de données à utiliser; ils déterminent aussi trois représentations de données différentes (c'est-à-dire, trois structures pour les réponses de l'\api{}). Grâce au principe de séparation des préoccupations, il est possible de rendre plus tard d'autres données accessibles et de permettre donc la diffusion de données depuis de nouvelles sources et la construction de nouvelles représentations. Les degrés de granularité déjà définis ne seront pas transformés par l'ajout d'autres degrés de granularité pour l'accès au corpus. Puisque les données et leur représentation sont distinctes, il est également possible de modifier la structure des sources de données (la structure des catalogues, par exemple) sans que le format de sortie ne soit affecté. Il suffit pour ce faire de faire en sorte que la représentation des données soit la même malgré le changement de la source de données.

\section{Codifier l'accès aux données: une sémantique pour les requêtes faites à l'API}
\sectionmark{Codifier l'accès aux données}
\subsection{La sémantique de l'API: principes généraux}
Les trois niveaux présentés au dessus sont autant de points d'accès aux données. Ils définissent les degrés de précision possibles pour accéder au données, mais ne définissent pas entièrement comment récupérer les informations voulues. À cette fin, une sémantique complète a été définie pour accéder aux données. Celle-ci s'organise autour des trois points d'accès présentés ci-dessus, puisque certains paramètres peuvent être interdits, ou que ceux-ci acceptent différentes valeurs en fonction du point d'accès aux données. Les paramètres de recherche autorisés sont les suivantes:

\begin{itemize}
	\item \texttt{level}: il s'agit du niveau auquel faire une requête. C'est ce paramètre qui définit le point d'accès aux données, et le degré de précision autorisé pour les recherches. 
	\item \texttt{format}: le format de la réponse renvoyée par le serveur au client.
	\item \texttt{id}: rechercher un catalogue ou une entrée de catalogue par son identifiant.
	\item \texttt{name}: rechercher un catalogue par type (\textit{Revue des autographes...}, vente aux enchères...) ou une entrée de catalogue par nom d'auteur.ice.
	\item \texttt{sell\_date}: la date de vente à laquelle correspond un catalogue, ou la date de vente d'un manuscrit.
	\item \texttt{orig\_date}: la date d'écriture d'un manuscrit.
\end{itemize}

Ces cinq paramètres offrent un vocabulaire commun pour accéder à toutes les données issues des catalogues. Pour une \api{}, avoir une sémantique claire et facile d'accès est important, et c'est pourquoi les paramètres de recherche sont limités à ces cinq mots clés. Le problème est que ces cinq mots clés permettent d'accéder à différents types de données, en fonction du point d'accès choisi avec le paramètre \texttt{level}. Deux grands types peuvent être identifiés: les données portant sur un catalogue et celles portant sur un manuscrit. Ces deux catégories portent cependant sur des objets très différents: bien que la sémantique soit la même pour toute l'\api{}, il n'est pas possible de rechercher un catalogue et un manuscrit de la même manière dans les bases de données disponibles. Cette sémantique doit donc être définie et adaptée aux différents points d'entrée aux données.

Comme cela a été dit, l'\api{} réalise un contrôle strict des requêtes: une requête n'est faite que si elle correspond à la sémantique des requêtes; si elle contient des paramètres interdits, alors la requête n'est pas lancée et un message d'erreur est renvoyé à l'utilisateur.ice. Cela permet d'économiser les ressources du serveur: chaque requête a un certain prix. Celui ci peut s'exprimer en terme de temps (le traitement d'une requête n'étant pas instantané) et en termes computationnels (la charge processeur nécessaire à traiter une requête, c'est-à-dire rechercher des informations dans plusieurs bases de données, construire des réponses et les renvoyer à l'utilisateur.ice). Par ailleurs, certaines requêtes pourraient correspondre à la sémantique définie, mais n'avoir aucun sens pour le moteur de recherche: si un identifiant (\texttt{id}) et un nom (\texttt{name}) sont fournis, laquelle de ces deux informations utiliser pour identifier les items pertinents? Un nom et un identifiant peuvent en effet pointer vers deux ressources très différentes. Le parti pris a donc été de diminuer les coûts de traitement et le risque de requêtes contradictoires en contrôlant strictement celles-ci. D'un point de vue de sécurité informatique, le contrôle des requêtes est également important, afin d'éviter des requêtes mal intentionnées. La sémantique des requêtes ne dépend donc pas seulement des mots clés, mais aussi des valeurs qui y sont associées. Les principales variations dépendent du point d'accès aux données choisi. Cependant, dans tous les cas, une valeur doit être fournie pour le paramètre \texttt{id} ou \texttt{name}, puisque c'est à partir de ceux-ci qu'est faite une recherche. 

\subsection{Au niveau du catalogue complet (\texttt{cat\_full})}
Au niveau du catalogue complet (\texttt{cat\_full}), le contrôle des requêtes est très précis, puisque les deux paramètres autorisés sont \texttt{format} et \texttt{id}.
\begin{itemize}
	\item Le seul format de réponse autorisé (paramètre \texttt{format}) est la \tei{}, pour trois raisons. D'un point de vue scientifique, un catalogue encodé en \tei{} contient des informations qui ne peuvent être facilement représentées sous la forme d'un \json{}. D'un point de vue scientifique, les catalogues en \tei{} sont le fruit d'un travail éditorial particulier; il est considéré qu'un.e utilisateur.ice qui fasse une requête aussi précise souhaiterait disposer d'une représentation aussi précise que la \tei{}. D'un point de vue computationnel, la représentation en \json{} d'un catalogue complet encodé en \tei{} serait très difficile, et aboutirait certainement à une perte d'informations.
	\item À part \texttt{format}, le seul autre paramètre autorisé est \texttt{id}. Une requête au niveau du catalogue complet ne peut renvoyer qu'un seul de ces documents à la fois, et essayer de cibler un catalogue par son nom, ou sa date de publication risquerait de créer des doublons. Là encore, il est supposé qu'un.e utilisateur.ice voulant obtenir un catalogue complet sait précisément celui que il ou elle cherche, et pourrait donc fournir directement son identifiant. Cela dit, il est tout à fait possible de récupérer plusieurs catalogues en lançant une série de requêtes avec différents identifiants. Suivant le principe de contrôle strict des requêtes, seul un identifiant valide sera recherché. Un identifiant valide correspond à l'expression régulière \texttt{CAT\_\textbackslash{}d+}, soit \texttt{CAT\_} suivi d'un nombre entier (par exemple, \texttt{CAT\_000001, CAT\_000499}).
\end{itemize}

\subsection{Au niveau des statistiques sur plusieurs catalogues (\texttt{cat\_stat})}
Lorsque des données statistiques sur des catalogues sont recherchées (au niveau \texttt{cat\_stat}), l'\api{} offre plus de liberté dans les paramètres fournis.
\begin{itemize}
	\item Le \texttt{format} de réponse accepte deux valeurs possibles: \texttt{tei} ou \texttt{json}.
	\item Un \texttt{id} ne peut être fourni en même temps qu'un \texttt{name}, pour éviter des requêtes impossibles à traiter. 
	\item Un identifiant doit toujours être conforme à l'\gls{expression régulière} \texttt{CAT\_\textbackslash{}d+}, afin de toujours identifier un catalogue (par exemple: \texttt{CAT\_000420}).
	\item Le paramètre \texttt{name} n'accepte que certaines valeurs. Celles-ci correspondent aux différents types de catalogues établis par le projet: \texttt{RDA} pour ceux issus de la revue des autographes, \texttt{AUC} pour les ventes aux enchères...
	\item Le paramètre \texttt{orig\_date} n'est pas autorisé: au niveau d'un catalogue complet, il n'y a pas de date de création, mais seulement la date de la vente à laquelle correspond le catalogue.
	\item Le paramètre \texttt{sell\_date} n'accepte que des valeurs au format \texttt{AAAA} ou \texttt{AAAA-AAAA}, ce qui est validé par l'\gls{expression régulière} \texttt{\textbackslash{}d\{4\}(\textbackslash{}d\{4\})+}.
\end{itemize}

\subsection{Au niveau de l'item (\texttt{item})}
C'est au niveau de l'item que la plus grande liberté est admise pour les paramètres de recherche:
\begin{itemize}
	\item Le \texttt{format} de réponse peut être \texttt{tei} ou du \texttt{json}.
	\item Une entrée de catalogue peut être ciblée par son identifiant avec le paramètre \texttt{id}. Cependant, l'identifiant doit correspondre au format de notation défini par \mssktb{} en se conformant à l'expression régulière \texttt{CAT\_\textbackslash{}d+\_e\textbackslash{}d+\_d\textbackslash{}d+}. Des valeurs autorisées sont par exemple: \texttt{CAT\_000069\_e2\_d1, CAT\_000420\_e49\_d1}.
	\item Les paramètres \texttt{sell\_date} et \texttt{orig\_date} sont tous les deux autorisés et peuvent être utilisés en même temps, puisqu'un manuscrit a à la fois une date de création et une date de vente. Le format de date autorisé est le même que pour le niveau \texttt{cat\_stat}. Cela permet par exemple de cibler un manuscrit écrit à une période et vendu une certaine année.
\end{itemize}

\subsection{Six paramètres de recherche, de nombreuses possibilités}
À partir de seulement cinq paramètres, c'est un moteur de recherche à filtre qui est mis au point et qui permet de définir la granularité des données à traiter, leur période et le format obtenu. Il est donc possible, en tant qu'utilisateur.ice de l'\api{}, de choisir entre la facilité de traitement (avec une réponse en \json{}) et un format à la sémantique clairement documentée (la \tei{}). Que les données soient retournées en \tei{} ou en \json{}, la précision des résultats obtenus est la même, puisque les deux formats de réponse sont des représentations des mêmes données, en accord avec les principes \gls{rest}. Une sémantique définie aussi précisément a ses avantages: elle permet de ne faire que des recherches qui ont un sens. Définir une sémantique claire et des incompatibilités entre différents paramètres de recherche garantit que l'\api{} pourra traiter toutes les requêtes sans risque de contradiction.

Le contrôle des données envoyées par le client permet également de ne faire que des recherches qui permettront d'obtenir un résultat, ce qui est aussi intéressant pour les utilisateur.ice.s. Cependant, ce contrôle augmente la difficulté d'utilisation de l'\api{}. Cela risque d'augmenter la niveau de technicité perçu par un.e chercheur.euse, ce qui risque de les décourager d'utiliser l'outil\footcite[p. 292-294]{edmond_apis_2015}. Pour diminuer cette distance perçue, quatre solutions ont été définies:

\begin{itemize}
	\item Des valeurs par défaut ont été établies pour certains paramètres. Par exemple, lorsqu'un \texttt{format} n'est pas spécifié par l'utilisateur.ice, la réponse est en \json{} par défaut (sauf si c'est un catalogue entier qui est recherché). Cela permet d'omettre des paramètres, et donc de faciliter l'utilisation de \textit{KatAPI}. La définition de valeurs par défaut semble aller à l'encontre de l'architecture \enquote{sans-état} voulue par le \gls{rest}, mais de nombreuses autres \api{} suivent ce principe (celle de \wkd{}, par exemple).
	\item La recherche d'un nom est insensible à la casse, aux accents et à la ponctuation. Les résultats obtenus en recherchant le \texttt{name SÉVIGNÉ} seront les mêmes que pour \texttt{sevigne} et \texttt{Sévigné}.
	\item Un système d'essai en temps réel, depuis la version \enquote{pour humain.e.s}, du site a été mis au point. Il est possible d'écrire un \json{} contenant les paramètres voulus dans une barre de recherche pour faire une requête. Celle-ci est traitée par le serveur qui retourne une réponse; celle-ci s'affiche sur la même page Web. Cela permet d'essayer une \api{} -- qui par définition n'a pas une interface graphique, ce qui est rebutant pour un.e utilisateur.ice non formé.e aux méthodes computationnelles -- depuis une interface graphique.
	\item En cas d'erreur, les réponses identifient précisément l'erreur et permettent de corriger sa requête sans devoir consulter la documentation, comme cela est expliqué dans la section suivante.
\end{itemize}

\section{Quelles représentations pour les données? Principes suivis pour le partage d'informations, formats et structure des réponses de l'API}
\sectionmark{Quelles représentations pour les données?}
Une \api{} n'a de sens que si elle est clairement documentée: c'est la seule manière de garantir que son fonctionnement soit clairement compréhensible par l'utilisateur.ice. La sémantique présentée ci-dessus est donc également documentée sur le site \ktb{}. Mais la sémantique d'une \api{} ne se limite pas dans les paramètres de recherche; elle définit également les formats de réponse de l'application. En effet, si ceux-ci ne sont pas clairement compréhensibles par un.e humain.e, ils risquent d'être inutilisables. La définition de formats de réponse est donc une sorte de travail éditorial, qui doit répondre à trois besoins:

\begin{itemize}
	\item Les réponses doivent être structurées et manipulables par des machines. C'est le cas de la \tei{} comme du \json{}, qui disposent tous les deux d'une structure hiérarchique en arbre permettant de clairement distinguer les différentes parties de la réponse.
	\item Les réponses doivent être des représentations uniformes de données, en accord avec les principes \gls{rest}. Cela veut dire que, pour les différents points d'accès aux données, un seul modèle doit exister et qu'il doit être le même, peu importe le nombre de résultats ait été retourné par l'application. En accord avec ces principes, les réponses doivent également être auto-descriptives.
	\item La réponse doit correspondre aux principes \gls{fair} autant qu'aux attentes des chercheur.euse.s et être compréhensible et utilisable par des personnes humaines. 
\end{itemize}

C'est le troisième point qui est le plus problématique: pour qu'un fichier soit manipulable par une machine, il suffit qu'il présente une structure précise. Pour qu'une réponse ait du sens, qu'elle doit compréhensible par une personne humaine, la tâche est cependant plus compliquée. En effet, une réponse d'une \api{} doit, en général, être aussi légère et concise que possible, puisqu'elle doit être envoyée à un client qui se trouve à distance. Une réponse \enquote{lourde} est également plus difficile à traiter par une machine. Une personne humaine risque également d'être découragée par une réponse trop complexe, qui présente par exemple des structures trop imbriquées et donc des éléments difficiles d'accès. Cependant, il n'est pas possible de demander à l'utilisateur.ice de se référer systématiquement à une documentation externe pour comprendre ce que l'application lui a renvoyé. Cette situation est encore complexifiée lorsque l'on essaye d'adhérer aux principes \gls{fair} et aux besoins de la recherche. En effet, ces principes autant que les chercheur.euse.s mettent l'accent sur l'importance des métadonnées dans le choix d'une source de données plutôt qu'une autre\footcite[p. 290-291 et p. 932-933 respectivement]{edmond_apis_2015, boeckhout_fair_2018}. Il est bien sûr possible de faire figurer toutes les métadonnées nécessaires dans la documentation de l'\api{} qui est accessible en ligne. Cependant, cela demande de devoir régulièrement consulter une source externe; si les résultats d'une requête sont transmis de manière brute à d'autres personnes, il est également nécessaire que celles-ci disposent des métadonnées nécessaires à leur utilisation. Il est donc intéressant d'inclure celles-ci dans la réponse renvoyée par l'\api{}, quitte à ce qu'elles soient ignorées par l'utilisateur.ice. Deux types de métadonnées peuvent être définies: celles qui concernent les données originelles et celles qui définissent le contexte de récupération des données et de production des ressources (c'est-à-dire, la requête faite à l'\api{}). Dans la première catégorie se classent la définition de la licence sous laquelle les données sont diffusées et la définition des termes spécifiques au projet qui pourraient être présents dans les réponses; dans la deuxième catégorie se placent les métadonnées qui permettent de définir le contexte de production de la ressource, c'est-à-dire la date de la requête, son contenu et le statut \gls{http} de la réponse. Il va cependant de soit qu'il est impossible de contenir toutes les métadonnées définissant le projet \ktb{}, le contexte de production des données et les choix faits pendant leur traitement. Ces informations sont notamment contenues dans le \texttt{tei:teiHeader} (l'en-tête) des catalogues encodés. Il est donc pertinent de consulter la documentation de l'\api{} et les catalogues encodés pour mieux comprendre les données présentes dans la réponse. Cependant, une réponse doit contient toutes les données nécessaires à sa compréhension minimale, même par une personne autre que celle qui a lancé la requête. Pour faire coïncider ce besoin avec la nécessité d'une réponse compréhensible par une machine et qui corresponde au principe \gls{rest} d'uniformité de l'interface, c'est donc une véritable éditorialisation des données à renvoyer au client qui est nécessaire.

\subsection{Les réponses, en général}
Les formats de réponse varient en fonction de plusieurs facteurs: le point d'accès aux données, le format de réponse demandé par le client et le fait qu'il y ait eu une erreur. Tous ces facteurs amènent à des structures de données qui sont différentes. Ce sont des représentations. Cependant, à un niveau abstrait et indépendant de sa représentation, une réponse peut toujours être représentée de la même manière (figure \ref{fig:response})\footnote{
	Des exemples de réponses en différents formats et avec différents paramètres sont visibles en annexes: au niveau \texttt{cat\_stat} en \json{} (\ref{appendix:api_cat_stat_json}) et \tei{} (\ref{appendix:api_cat_stat_json}), au niveau de l'\texttt{item} en \json{} (\ref{appendix:api_item_json}) et \tei{} (\ref{appendix:api_item_xml}); des messages d'erreur sont également présents en annexes, en \json{} (\ref{appendix:api_error_json}), et, là encore, en \tei{} (\ref{appendix:api_error_xml}). Un exemple de réponse complète est également \href{https://github.com/paulhectork/tnah2022_memoire/blob/main/texte_sources/annexes/api_cat_full.xml}{accessible depuis le dépôt en ligne de ce mémoire}, puisque le document est trop long pour être inclus en annexes.
}.

\begin{figure}[h!]
	\tikz[scale=0.75, transform shape]{
		\node[expl, minimum height=1.5cm] (http) at (0,4)%
		{En-tête HTTP}; 
		\node[db] (start) at (0,0)%
		{Réponse};
		\node[base] (header) at (-5,-3)%
		{En-tête de la réponse};
		\node[base] (body) at (5,-3)%
		{Corps de la réponse};
		\node[base] (header1) at (-8.5,-6)%
		{Métadonnées sur la requête};
		\node[base] (header2) at (-2.85,-6)%
		{Métadonnées sur le contenu de la réponse};
		\node[base] (body1) at (2.85,-6)%
		{Premier résultat ou message d'erreur};
		\node[base] (body2) at (8.5,-6)%
		{Second résultat ou message d'erreur};
		
		\draw[arrow] (start) -- (header);
		\draw[arrow] (start) -- (body);
		\draw[arrow] (header) -- (header1);
		\draw[arrow] (header) -- (header2);
		\draw[arrow] (body) -- (body1);
		\draw[arrow] (body) -- (body2);
		\draw[doublearrow, dash pattern=on 3pt off 4pt on \the\pgflinewidth off 4pt] (start) -- (http);
	}
	\caption{Modèle de réponse renvoyé par \textit{KatAPI}}
	\label{fig:response}
\end{figure}

Toutes les réponses revoyées par l'\api{} contiennent un en-tête \gls{http} et la réponse elle-même. L'en-tête \gls{http} sert à caractériser la réponse à l'aide de métadonnées. Il contient de nombreuses informations qui permettent d'interpréter la réponse, dont la plupart sont produites automatiquement: par exemple, des informations sont contenues dans l'en-tête \gls{http} sur le serveur ayant renvoyé la réponse, la possibilité de mettre les données reçues par le client en cache ou encore la date de la requête. Parmi toutes ces informations, deux sont définies par l'\api{} à chaque requête: le statut \gls{http} (qui indique comment s'est déroulée l'interaction avec le serveur) et le type MIME (qui identifie le format de la réponse). Ainsi, les en-têtes permettent à un client d'interpréter le message reçu en réponse.

La réponse est elle-même séparée entre un en-tête et un corps. Le premier définit le contexte dans lequel la réponse avec le serveur a été faite. Cet en-tête a plus de précision que celui prévu par le protocole \gls{http}; contrairement à celui-ci, qui n'est plus accessible une fois l'interaction avec le serveur terminée, l'en-tête de la réponse est toujours accessible, puisqu'il fait partie du fichier renvoyé. Le corps de la réponse en lui-même contient les données correspondant à la requête du client, ou, si une erreur a eu lieu, un message d'erreur descriptif. Cette séparation de la réponse en un en-tête et un corps est obligatoire lors de l'utilisation de la \tei{}; son utilisation par le \json{} est également inspirée par la structure des réponses \sparql{}\footcite{beckett_sparql_2013}, bien que celles-ci contiennent beaucoup moins de métadonnées qu'une réponse de \textit{KatAPI}.

\subsection{L'en-tête des réponses, un conteneur pour les métadonnées}
Si l'en-tête n'est pas voué à être conservé par les utilisateur.ice.s ayant réalisé des requêtes, il est néanmoins essentiel. Il permet à une personne qui n'est pas familière avec le projet d'aborder les données reçues et identifie précisément à quels critères elles correspondent. Il est garant du respect des principes \gls{fair}, puisqu'il contient suffisamment de métadonnées pour que quiconque manipule la réponse dispose d'informations suffisantes à leur réutilisation. Décrivant le contexte d'une réponse, il rend la réponse auto-descriptive, ce qui correspond avec l'utilisation des principes \gls{rest}. Les informations relatives à la requête sont les suivantes (exemples \ref{code:api_header_context_json}, \ref{code:api_header_context_tei}):

\begin{itemize}
	\item La requête, représentée sous la forme d'une table associant les paramètres de recherche utilisés (\texttt{level, format...}) aux valeurs que l'utilisateur.ice leur a associées.
	\item La date à laquelle la requête est reçue par le serveur, au format ISO. Cette information est surtout utile dans le cas où la réponse serait enregistrée par l'utilisateur.ice pour y accéder plus tard. Cela permet de dater les données produites, ce qui est utile puisque de nouveaux catalogues peuvent être ajoutés ultérieurement; dans ce cas, la réponse du serveur ne serait plus à jour.
	\item Le statut \gls{http} de la réponse. Celui-ci est également présent dans l'en-tête \gls{http}, et sa présence ici peut donc sembler superflue. Il a été rajouté à cause du système de gestion des erreurs. Un choix de conception de l'application a en effet été de construire des messages d'erreurs sous la forme de \json{} ou de \tei{} valides. Cela veut dire qu'une erreur retourne une réponse valide qui décrive l'erreur. Dans le cas où les réponses obtenues par le client sont traitées automatiquement, un programme informatique ne détectera donc pas forcément de problème. L'ajout d'un code de statut permet d'adapter facilement un programme à ce cas de figure, en vérifiant à chaque réponse le code \gls{http} dans le corps du document.
\end{itemize}

\begin{listing}
	\begin{minted}[breakanywhere]{json}
{
	"license": "Attribution 2.0 Generic (CC BY 2.0)",
	"query": {
		"format": "json",
		"level": "cat_stat",
		"name": "RDA",
		"sell_date": "1800-1900"
	},
	"query_date": "2022-08-24T16:41:42.604421",
	"status_code": 200
	# reste de l'en-tête
}
	\end{minted}
	\caption{Extrait d'en-tête de réponse en \json{} décrivant le contexte d'une requête}
	\label{code:api_header_context_json}
\end{listing}

Les informations relatives aux données contenues dans le corps de la réponse, elles, permettent de mieux comprendre les données. Ces métadonnées sont différentes selon si le format de réponse est le \json{} ou le \tei{}. Dans les deux cas, une réponse contient une licence, qui définit de quelle manière les données peuvent être utilisées. La licence Creative Commons Attribution 2.0 Generic (CC BY 2.0) est utilisée par le projet. Étant une licence libre, elle permet aux utilisateur.ice.s de réutiliser les données en les citant. Toutes les réponses partagent également une ou plusieurs \enquote{taxonomies} (l'usage de ce terme est issu de la \tei{}). Celles-ci servent à définir les termes spécifiques au projet, qui ne seraient pas nécessairement compréhensibles par tou.te.s les utilisateur.ice.s. Les taxonomies associent à des termes présents dans le corps de la réponse une définition. L'explication du terme \texttt{variance\_price\_c} dans une taxonomie en \tei{} est visible dans l'exemple \ref{code:taxonomy}. Ces taxonomies améliorent la compréhension de la réponse par une personne humaine; mais elles offrent aussi des possibilités de traitement par une machine, puisqu'il est par exemple possible de remplacer un terme spécifique au projet par une définition. Les taxonomies présentes dans une réponse changent selon le point d'accès aux données choisi, puisque ce sont des termes différents qui auront besoin d'être expliqués à chaque fois.

\begin{listing}[h]
	\begin{minted}{xml}
<category xml:id="cat_stat_keys_variance_price_c">
	<catDesc>The variance of the prices inside the catalogue.</catDesc>
</category>
	\end{minted}
	\caption{Un élément d'une taxonomie en \tei{}}
	\label{code:taxonomy}
\end{listing}

Si une réponse est encodée en \tei{}, alors des informations supplémentaires sont présentes. Deux raisons sont derrière ce choix, qui implique que les réponses en \json{} et en \tei{} diffèrent. D'abord, la \tei{} définit toute une sémantique qui permet de caractériser très efficacement le contexte de production des données. Elle requiert qu'un document contienne un minimum d'informations dans son en-tête, ce qui a encouragé à étoffer l'en-tête. Ensuite, il a été considéré que la \tei{} est plus susceptible que le \json{} d'être un format définitif, dans lequel la richesse d'informations est privilégiée. Un \json{}, au contraire, est utilisé parce qu'il est pratique, et il est susceptible d'être retraité par un.e utilisateur.ice de l'\api{} afin qu'il s'adapte à ses besoins. Par ailleurs, la présence ou l'absence de ces données ne change pas la structure globale de la réponse, mais seulement l'en-tête. Les informations supplémentaires contenues dans le \tei{} sont notamment un titre (\textit{KatAPI query results}, soit \enquote{Résultats de requête KatAPI}) et la mention des différents projets qui ont produit les données (\textit{e-Ditiones, Katabase et Manuscript SaleS Catalogues}) (annexe \ref{appendix:api_cat_stat_xml}).

Les métadonnées relatives à la requête doivent être encodées de façon légèrement différente lorsqu'un catalogue entier est requêté. Dans ce cas, la réponse n'est pas créée \textit{ex nihilo}, elle est construite en récupérant un document entier dans la base de données de catalogues. Cela pose une question à propos de la nature du document: faut-il modifier le catalogue encodé, en sachant que celui-ci est déjà un objet édité et pensé de façon cohérente? Le document transmis au client lors d'une requête est-il différent de celui qui est présent dans le serveur? En plus de ces questions pratiques, le problème est technique: les métadonnées relatives à la requête sont normalement encodées en \tei{} dans un élément \texttt{tei:publicationStmt}, qui décrit le contexte de publication d'un document électronique. Dans un catalogue complet, cet élément est déjà utilisé. Le fait que cet élément soit déjà utilisé, mais qu'il doive être réutilisé lors d'une requête résume bien la question posée ci-dessus. La réponse à ce problème est pragmatique. Il est toujours possible, à cause d'un problème interne à l'\api{} ou dû au transfert de la réponse au client, que le catalogue soit corrompu ou contienne des erreurs. Dans ce cas, le catalogue transmis n'est pas différent de celui présent dans le serveur, mais il peut être considéré comme une édition de celui-ci. De ce fait, il est toujours nécessaire d'encoder le contexte dans lequel le catalogue a été transmis au client. La solution trouvée consiste à intégrer le contexte de la requête à l'intérieur d'un élément \texttt{tei:availability} -- qui définit les conditions d'accès à un document -- dans le \texttt{tei:publicationStmt} (exemple \ref{code:api_header_context_tei}). Cela permet de ne pas perdre d'informations de l'original, tout en intégrant à la réponse les métadonnées relatives à la requête.

\begin{listing}[hp!]
	\begin{minted}[breakanywhere]{xml}
<publicationStmt>
	<publisher>Projet e-Ditiones, Université de Neuchâtel</publisher>
	<availability status="restricted">
		<licence target="https://creativecommons.org/licenses/by/2.0">Attribution 2.0 Generic (CC BY 2.0)</licence>
		<p>KatAPI query results. File created automatically by KatAPI, an API developped as part of the<ref target="https://katabase.huma-num.fr/">Manuscript SaleS Catalogues project</ref></p>
		<p>Query run on<date when-iso="2022-08-24T16:41:52.101590">2022-08-24T16:41:52.101590</date></p>
		<p>Query ran with HTTP status code:<ref target="https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/200"/></p>
		<p>The current file has been retrieved and updated as a response to the query:
			<table>
				<head>Query parameters</head>
				<row>
					<cell role="key" xml:id="id">id</cell>
					<cell role="key" xml:id="output_format">format</cell>
					<cell role="key" xml:id="level">level</cell>
				</row>
				<row>
					<cell role="value" corresp="id">CAT_000300</cell>
					<cell role="value" corresp="format">tei</cell>
					<cell role="value" corresp="level">cat_full</cell>
				</row>
			</table>
		</p>
	</availability>
</publicationStmt>
	\end{minted}
	\caption{Exemple de \texttt{tei:publicationStmt} décrivant le contexte de la requête}
	\label{code:api_header_context_tei}
\end{listing}

L'en-tête sert à contextualiser les données contenues dans le corps de la réponse, afin qu'elles aient du sens au moment où elles sont reçues, mais aussi sur le long terme. En décrivant le contexte de la requête et de la production des docuemnt, et en indiquant la licence sous laquelle les documents sont diffusés, l'en-tête cherche à s'adapter aux principes \gls{fair}. L'éditorialisation de l'en-tête cherche également à construire une structure commune pour les différents points d'entrée, en accord avec les principes \gls{rest}. Son rôle principal est de permettre la compréhension du corps des réponses, qui sont elles mêmes issues d'un travail d'éditorialisation.

\subsection{Les corps de réponse}
À un niveau abstrait, les corps de réponse prennent toujours la forme d'une liste contenant les résultats pertinents en fonction de la requête faite par l'utilisateur.ice. Selon le point d'accès aux données, les résultats obtenus diffèrent.

\subsubsection{Le corps d'une réponse au format \texttt{cat\_full}}
Ce cas particulier implique un fonctionnement particulier de l'\api{}: plutôt que de construire un jeu de données sur mesure à transmettre au client, il s'agit de vérifier si le fichier demandé existe. Cela implique, comme on l'a vu, un en-tête de réponse est particulier; le corps l'est aussi. Dans le cas où une catalogue est trouvé, c'est le corps de ce catalogue qui est retourné au client. Cependant, si aucun catalogue correspondant à l'identifiant fourni par le client n'est trouvé, le corps comme l'en-tête sont différents. Il n'est pas possible de reprendre un en-tête existant, et un en-tête sur mesure est donc constitué, comme pour les points d'entrée \texttt{cat\_stat} et \texttt{item}. Le corps est vide, puisqu'aucun résultat n'a été trouvé (\ref{code:api_cat_full_empty}).

\begin{listing}[h!]
	\begin{minted}{xml}
<TEI>
	<teiHeader>
		<!-- ... -->
	</teiHeader>
	<text>
		<body>
			<div type="search-results"/>
		</body>
	</text>
</TEI>
	\end{minted}
	\caption{Extrait de réponse au niveau \texttt{cat\_full} lorsqu'aucun catalogue n'est trouvé}
	\label{code:api_cat_full_empty}
\end{listing}

\subsubsection{Le corps d'une réponse au format \texttt{cat\_stat}}
À ce niveau de granularité, la réponse consiste en une liste de résultats correspondants aux paramètres de recherche fournis par l'utilisateur.ice. Chaque résultat est un identifiant de catalogue associé à des statistiques sur celui-ci; si les manuscrits vendus dans le catalogue sont à prix fixe (par opposition aux items vendus aux enchères), des statistiques supplémentaires sont incluses sur les prix. Il est considéré que l'intérêt de ce niveau de granularité est de permettre une comparaison entre les différents catalogues; c'est pourquoi tous les prix sont exprimés en francs constants 1900. La liste complète des données pouvant être transmises au client sur un catalogue est donc:

\begin{itemize}
	\item Le titre du catalogue.
	\item Le type de catalogue (\textit{Revue des autographes, catalogue de vente aux enchères}...).
	\item Le nombre de manuscrits en vente dans un catalogue.
	\item L'année de la vente.
	\item La somme du prix de tous les items du catalogue.
	\item Le prix de l'item le plus cher en vente.
	\item La liste des items les plus cher du catalogue.
	\item Le prix le plus faible pour un item.
	\item La moyenne, le premier quartile et la médiane du prix d'un item dans ce catalogue.
	\item Le mode du prix, c'est-à-dire le prix le plus fréquemment attribué à un item.
	\item La variance des prix des items, ce qui permet de mesurer et de comparer la volatilité des prix d'un catalogue à un autre.
\end{itemize}

Comment représenter ces données? La représentation en \json{} est assez simple, puisqu'il s'agit simplement de créer un \gls{dictionnaire} associant des clés (identifiant le type de donnée) à l'information elle-même (\ref{code:api_cat_stat_json}\footnote{
	Un exemple de réponse complet est disponible en annexes (\ref{appendix:api_cat_stat_json}).
}). Il est cependant plus difficile d'exprimer ces résultats dans un fichier \tei{}. Celle-ci impose des contraintes strictes sur la manière de structurer des éléments: seulement certains d'entre eux sont autorisés à certains endroits, et certains éléments doivent obligatoirement en contenir d'autres, par exemple. De plus, chaque élément a sa signification propre, qui doit être respectée dans la construction de la réponse; la \tei{} étant pensée pour le texte, il n'est pas évident de l'adapter à une liste de statistiques. Mais le véritable problème n'est pas seulement technique: la \tei{} est, par définition, spécifique et propre à un projet. Il existe une certaine liberté dans l'utilisation des éléments, de sorte que différents encodages soient des représentations différentes d'un même texte; un encodage est donc une interprétation du texte, qui dépend des visées d'un projet. À l'inverse, le format de réponse d'une \api{} doit être générique et pratique: être facilement utilisable et compréhensible (même sans connaissance approfondie de la \tei{}) et pouvoir s'adapter aux différents besoins des utilisateur.ice.s, sans privilégier une vision scientifique. Par expérience, les formats de réponse retournés par une \api{} ne correspondent en général pas aux besoins de l'utilisateur.ice de l'\api{}, qui récupère les données dans les réponses pour les adapter à ses propres besoins; dans ce cas, il est nécessaire de manipuler le \xml{} retourné et, par expérience, plus ce format est complexe, plus il est difficile de le manipuler avec des méthodes computationnelles. Une arborescence la plus simple possible doit donc être privilégiée, afin de faciliter sa manipulation. Cela encourage la création d'un format le plus générique possible. Faire coïncider un besoin de généricité avec un format qui encourage la spécificité n'est pas évident. 


\begin{listing}[h!]
	\begin{minted}{python}
"CAT_000018": {
	"cat_type": "RDA",
	"currency": "FRF",
	"high_price_c": 561.0,
	"high_price_items_c": {
		"CAT_000018_e144": 561.0
	},
	"item_count": 192,
	"low_price_c": 1.53,
	"mean_price_c": 10.565811518324606,
	"median_price_c": 5.1,
	"mode_price_c": 3.06,
	"sell_date": "1873-08",
	"title": "RDA, N\u00b037 (ao\u00fbt 1873)",
	"total_price_c": 2018,
	"variance_price_c": 1658.1071772210191
}
	\end{minted}
	\caption{Représentation \json{} des données portant sur un catalogue}
	\label{code:api_cat_stat_json}
\end{listing}

Aussi le parti pris a-t-il été d'encoder les données de la façon la plus simple possible (\ref{code:api_cat_stat_tei}\footnote{
	Pour un exemple de réponse complète, voir en annexes (\ref{appendix:api_cat_stat_xml}).
}). Les différents catalogues sont contenus dans un \texttt{tei:list}; en s'inspirant de l'encodage choisi pour les manuscrits dans les catalogues, chaque catalogue est représenté dans un \texttt{tei:item}. À l'intérieur est contenu un \texttt{tei:label} qui contient l'identifiant du catalogue. Les différentes données sont contenues dans un \texttt{tei:term}, un élément qui permet d'encoder un terme ou un symbole technique\footcite{tei_consortium_p5_2022}. Ce choix est adapté, puisque les différents termes associés aux données sont propres au projet. Le terme en lui-même est encodé dans un attribut \texttt{@key}, tandis que la valeur est dans le corps de l'élément. Cela permet de reproduire l'association clé-valeur utilisée dans le \json{} afin de permettre une similarité entre les deux formats de représentation des données. Pour maintenir l'arborescence la plus simple possible, la liste des items les plus chers est contenue à la racine du \texttt{tei:item} plutôt que dans une liste imbriquée. Dans ce cas, le prix se trouve dans le corps de l'élément, et l'identifiant du manuscrit dans un attribut \texttt{@ana}. L'usage d'attributs permet de caractériser les éléments de façon bien plus précise qu'avec un \json{}. Un attribut \texttt{@type} est utilisé pour caractériser certains types de données (date, prix constants); lorsqu'une requête est faite en utilisant certains paramètres, comme \texttt{sell\_date}, et que ces paramètres sont présents dans la réponse, alors un attribut \texttt{@ref} est utilisé pour pointer vers le descriptif de la requête dans l'en-tête. Cela permet de lier corps et en-tête des données.

\begin{listing}[h!]
	\begin{minted}{xml}
<item ana="CAT_000362">
	<label>CAT_000362</label>
	<term key="title">Vente Jacques Charavay, août 1875, nº 185</term>
	<term key="cat_type">LAC</term>
	<term key="sell_date" type="date">1875</term>
	<term key="item_count">106</term>
	<term key="currency">FRF</term>
	<term key="total_price_c" type="constant-price">1039</term>
	<term key="low_price_c" type="constant-price">1.27</term>
	<term key="high_price_c" type="constant-price">102.0</term>
	<term key="mean_price_c" type="constant-price">9.810188679245282</term>
	<term key="median_price_c" type="constant-price">4.59</term>
	<term key="mode_price_c" type="constant-price">3.06</term>
	<term key="variance_price_c" type="constant-price">194.2879773228907</term>
	<term key="high_price_items_c" type="constant-price" ana="CAT_000362_e27096">102.0</term>
</item>
	\end{minted}
	\caption{Représentation en \xmltei{} des données portant sur un catalogue}
	\label{code:api_cat_stat_tei}
\end{listing}

Ces choix d'encodage permettent de construire des réponses simples, avec un minimum d'imbrication entre les éléments; l'utilisation d'attributs permet de créer des liens entre mots clés et valeurs, mais aussi des liens entre différentes parties de la réponse (puisque l'attribut \texttt{@key} du corps de la réponse est défini dans l'élement \texttt{tei:taxonomy} de l'en-tête). Un format de réponse en \tei{} permet donc de commenter et de caractériser les données avec une précision qui n'est pas possible dans un \json{}. Cependant, grâce aux choix de modélisation, une représentation des données en \tei{} présente la même structure qu'un \json{}, soit une série de couples clés-valeurs.

\subsubsection{Le corps d'une réponse au format \texttt{item}}
La problématique de la modélisation des réponses au niveau de l'item de catalogue est bien différente de ce qui a été exposé pour le niveau \texttt{cat\_stat}. Pour le point d'accès présenté ci-dessus, les données en \tei{} sont créées \textit{ex nihilo} à partir d'un \json{}. Il était donc nécessaire de trouver un moyen de les représenter dans un autre format. Une autre spécificité du point d'accès présenté ci-dessus est qu'il ne contient que des statistiques; de fait, la \tei{} n'est pas pensée pour ce type de format, ce qui demande de trouver un moyen pour adapter ces données dans ce format. Au niveau de l'entrée de catalogue, les données représentées sont des textuelles, puisque la réponse envoyée par le serveur contient une liste d'entrées de catalogue. De plus, ces données ont déjà été encodées en \tei{}, dans les catalogues originels. Le choix a été de ne pas modifier ces représentations: elles sont le fruit d'un travail scientifique d'édition, d'extraction de données, de normalisation et d'enrichissement. Les catalogues, encodés en \tei{}, ne sont donc pas seulement représentatifs des choix au moment de la première édition numérique des catalogues. Ils contiennent également des informations produites tout au long de la chaîne de traitement, dont les identifiants \wkd{} extraits lors de la résolution d'entités nommées décrite dans la partie précédente. L'encodage des items, tel qu'il est fait dans les catalogues, est donc une représentation synthétique de ceux-ci, qui témoigne des choix scientifiques faits tout au long de la chaîne de traitement. Conserver cet encodage permet de disposer d'une représentation complète et déjà éditorialisée des données; cela permet également de représenter tout le travail fait sur les données, et donc de diffuser celles-ci de manière transparente, en accord avec les principes \gls{fair}. Les choix d'encodage pour les sont également précisément documentés, ce dont peut bénéficier un.e chercheur.euse souhaitant les réutiliser. Par ailleurs, les données diffusées par \textit{KatAPI} ont traversé toute une chaîne de traitement; celle-ci est susceptible de s'étoffer, avec l'ajout de nouvelles étapes; dans ce cas, l'encodage des catalogues évoluerait lui-aussi. Il est alors naturel que la représentation de ces données évolue elle aussi, afin de s'adapter aux évolutions scientifiques du projet. Pour toutes ces raisons, il est plus intéressant de reprendre l'encodage déjà réalisé plutôt que de recréer une nouvelle représentation. Le problème est que les formats de réponse pourront alors changer, ce qui peut être peu pratique pour les utilisateur.ice.s de l'\api{} (qui, si il.elle.s retraitent les réponses automatiquement, devront modifier leur chaîne de traitement). Cependant, ces évolutions sont justifiées et souhaitables, puisqu'elles reflètent l'évolution d'un travail scientifique. Le corps des réponses, en \tei{} et au niveau \texttt{item}, est donc composé d'une \texttt{tei:list} contenant toutes les entrées de catalogues représentées par un \texttt{tei:item} (\ref{code:api_item_tei}\footnote{
	Pour un exemple de réponse complète, voir l'annexe \ref{appendix:api_item_xml}.
}).

\begin{listing}[h!]
	\begin{minted}{xml}
<list>
	<head>Search results</head>
	<item n="108" xml:id="CAT_000204_e108">
		<num type="lot">108</num>
		<name type="author" ref="wd:Q255">BEETHOVEN (L. van)</name>
		<trait>
		<p>le grand compositeur de musique.</p>
		</trait>
		<desc xml:id="CAT_000204_e108_d1">
		<term ana="#document_type_9">L. s.</term> à M. M. Schlesinger, à Berlin; Vienne, <date when="1820-05-31">31 mai 1820</date>, <measure type="length" unit="p" n="2">2 p.</measure>
		<measure type="format" unit="f" ana="#document_format_4">in-4</measure>, cachet</desc>
		<note>Curieuse lettre sur ses ouvrages. Il leur accorde le droit de vendre ses compositions en Angleterre, y compris les airs écossais, aux conditions indiquées par lui. Il s'engage à leur livrer dans trois mois trois sonates pour le prix de 90 florins qu'ils ont fixé. C'est pour leur être agréable qu'il accepte un si petit honoraire. « Je suis habitué à faire des sacrifices, la composition de mes OEuvres n'étant pas faite seulement au point de vue du rapport des honoraires, mais surtout dans l'intention d'en tirer quelque chose de bon pour l'art.»</note>
	</item>
	<!-- autres items --->
</list>
	\end{minted}
	\caption{Représentation en \xmltei{} des réponses de l'API au niveau \texttt{item}}
	\label{code:api_item_tei}
\end{listing}

La représentation en \json{} des entrées de catalogue existait elle aussi avant le développement de l'\api{}. Cette représentation cherchant à être l'équivalent le plus fidèle possible des entrées de catalogues encodées en \tei{}, elle a été réutilisée pour les réponses de l'\api{} (\ref{code:api_item_json}\footnote{
	Pour un exemple de réponse complète de l'\api{} en \xmltei{} au niveau \texttt{item}, voir l'annexe \ref{appendix:api_item_json}.
}). Au niveau \texttt{item}, la représentation des données est donc équivalente à leur représentation dans les différentes bases de données utilisées par l'\api{}. Cette représentation implique nécessairement une perte d'information. En premier lieu, seul le nom de famille de l'auteur.ice est conservé; l'élément \texttt{tei:note} est supprimé, de même que le numéro de lot dans le catalogue. La représentation en \json{} contient également toutes les informations produites durant la chaîne de traitement (normalisation, enrichissement), puisque ces informations, contenues dans des attributs, ont été extraites. Comme pour les réponses en \tei{}, les termes normalisés et spécifiques au projet sont définis au sein de taxonomies dans l'en-tête. Au premier abord, utiliser la structure de données présente dans les bases de données pour construire une réponse peut sembler aller à l'encontre du principe d'uniformité de l'interface du \gls{rest}: la structure des réponses n'est pas indépendante de la source de données. Ce choix se justifie cependant par les spécificités des données de recherche. Les informations, telles qu'elles sont stockées dans les différents fichiers consultés par l'\api{}, sont représentatifs de ce travail de recherche et de choix d'encodage spécifiques. Réutiliser ces structures de données permet de transmettre non seulement les données, mais l'intégralité de la recherche, puisque l'encodage numérique fait partie intégrante du travail scientifique. La structure des données est par ailleurs relativement stable sur le long terme; en évoluant, elle ne change pas drastiquement, puisque seulement de nouveaux attributs ou couples clés-valeurs sont ajoutés aux données. Cela permet donc une relative pérennité des représentations et des formats de réponse renvoyés au client. De plus, utiliser des données pré-existentes en \json{} et en \tei{} garantit que, à ce niveau, la des données représentation a une structure équivalente dans les deux formats.

\begin{listing}[h]
	\begin{minted}{json}
"CAT_000185_e608_d1": {
	"author": "S\u00e9vign\u00e9",
	"author_wikidata_id": null,
	"date": "1685",
	"desc": "\n                        L. aut. \u00e0 sa fille; mercredi 14 f\u00e9vrier (1685), 7 p. 1/2\n                        in-4\n                    ",
	"format": 4,
	"number_of_pages": 7.5,
	"price": null,
	"sell_date": "1881",
	"term": 8
}

	\end{minted}
	\caption{Représentation en \json{} des réponses de l'API au niveau \texttt{item}}
	\label{code:api_item_json}
\end{listing}

\subsubsection{Le corps d'une réponse en cas d'erreur}
Comme cela a été dit, l'un des prérequis pour \textit{KatAPI} était la création de messages d'erreurs structurés et autodescriptifs, en \tei{} ou en \json{}. Deux types d'erreurs ont été définies. D'abord, les erreurs dues à une requête incorrecte de la part du client (soit qu'elle ne respecte pas la sémantique pour les requêtes, soit qu'elle utilise des valeurs non-autorisées). Ensuite, les erreurs de la part du serveur: l'application a été testée pour minimiser le risque d'erreurs, mais celles-ci sont toujours possibles; un système de gestion des erreurs a donc été mis en place pour informer l'utilisateur.ice si une telle erreur a lieu. Les réponses retournées ont la même structure dans les deux cas. Les choix de représentation des erreurs ont été faits pour être conformes avec la structure globale définie pour les réponses (\ref{fig:response}), mais aussi pour être cohérents avec les choix d'encodages faits pour les autres représentations présentées ci-dessus. Les réponses sont donc représentées sous la forme d'une liste qui associe à des clés des descriptions des erreurs. Ces clés correspondent, lorsque cela est possible, au nom des paramètres pour lesquelles des erreurs ont survenu. Les messages permettent à l'utilisateur.ice de corriger son erreur afin de pouvoir récupérer les résultats. En plus de cette liste, un message introductif définit l'erreur qui a eu lieu afin de savoir si l'erreur est due au client ou au serveur; pour aller dans le même sens, le statut \gls{http} est modifié dans l'entrée afin de caractériser précisément l'erreur. Lorsque le message d'erreur est en \json{}, l'encodage de la réponse est relativement simple (\ref{code:api_error_json}\footnote{
	Un message d'erreur complet de l'\api{} est visible en annexes (\ref{appendix:api_error_json}).
}).

\begin{listing}[h]
	\begin{minted}{json}
"results": {
	"__error_type__": "Invalid parameters or parameters combination",
	"error_description": {
		"format": "The format must match: (tei|json)",
		"id_incompatible_params": "Invalid parameters with parameter id: ['sell_date']",
		"name+id": "You cannot provide both a name and an id",
		"sell_date": "The format must match: \d{4}(-\d{4})?",
		"unallowed_params": "Unallowed parameters for the API: ['api']"
	}
}
	\end{minted}
	\caption{Corps de réponse en cas d'erreur de la part du client en \json{}}
	\label{code:api_error_json}
\end{listing}

En \xmltei{}, la structure des données est inspirée de celle des autres formats de réponse, et particulièrement des réponses obtenues au niveau \texttt{item} (\ref{code:api_error_tei}\footnote{
	Un message d'erreur complet en \json{} est visible en annexes: \ref{appendix:api_error_xml}.
}). Les différents messages d'erreur sont contenus au sein d'une liste; chaque erreur correspond à un \texttt{tei:item}; le code du message d'erreur se trouve dans un attribut \texttt{@ana} de cet élément et dans le \texttt{tei:label}, ce qui permet d'identifier l'erreur; le message d'erreur en lui-même est contenu dans un \texttt{tei:desc}. Ainsi, les messages d'erreur correspondent aux principes définis pour les réponses \gls{rest}: ce sont des représentations qui sont toujours uniformes. Leur structure est de plus analogue aux autres représentations définies pour l'\api{}, ce qui permet à un.e utilisateur.ice de comprendre plus facilement les différents formats de réponse. Enfin, ces messages d'erreurs ont l'avantage d'être entièrement auto-descriptifs, et de pointer vers une manière de corriger sa requête. Cela limite le besoin d'avoir à se référer à une documentation externe pour corriger ses erreurs. Les messages d'erreurs émis par l'\api{} cherchent à être le plus facilement compréhensibles, autant du point de vue des messages eux-mêmes que de leur encodage. En effet, la structure définie pour ces réponses est la même que celle établie pour les réponses valides; ce sont également les mêmes éléments de la \tei{} qui sont utilisés, ce qui permet qu'un.e utilisateur.ice ne soit pas dérouté.e par la structure du message d'erreur et puisse uniquement se concentrer sur son contenu.

\begin{listing}[h]
	\begin{minted}{xml}
div type="error-message">
	<list>
		<head>Invalid parameters or parameters combination</head>
		<item ana="no_name+id">
			<label>no_name+id</label>
			<desc>You must specify at least a name or an id</desc>
		</item>
		<item ana="sell_date" corresp="sell_date">
			<label>sell_date</label>
			<desc>The format must match: \d{4}(-\d{4})?</desc>
		</item>
	</list>
</div>
	\end{minted}
	\caption{Corps de réponse en cas d'erreur de la part du client en \xmltei{}}
	\label{code:api_error_tei}
\end{listing}

Plus largement, les formats de réponses présentés dans cette partie sont garants à la fois du respect des principes \gls{rest}. Ils sont tous des implémentations différentes d'un modèle commun, lui-même inspiré des structures en en-tête/corps utilisés par le format de réponse \sparql{}, mais aussi par de nombreux standards d'encodage numérique, dont la \tei{}. Cette double inspiration reflète le statut intermédiaire des réponses envoyées par l'\api{} au client: ce sont à la fois des réponses d'\api{} (et donc des formats techniques, faits pour être manipulés par des machines) et des éditions crées à la demande pour répondre aux besoins d'utilisateur.ice.s. Répondre à leurs demandes implique également de respecter les principes \gls{fair}, et c'est aussi à cette fin que les réponses de l'\api{} ont été modélisées. En effet, celles-ci visent à contenir toutes les données et métadonnées nécessaires à la compréhension d'un résultat par une personne humaine ainsi qu'à son traitement par une machine. La quantité d'informations intégrées aux réponses permet de faire de celles-ci de simple formats de réponse qui seront modifiés par le client; mais elles peuvent également être conservées et restées intelligibles sur le long terme. La modélisation de l'\api{} au croisement des besoins de chercheur.euse.s et de bonnes pratiques informatiques met en avant que ces deux besoins ne sont pas contradictoires. En encourageant à produire des données compréhensibles et réutilisables, le \gls{fair} comme le \gls{rest} encouragent à mieux penser la conception d'applications, afin de produire des outils utiles et des réponses qui soient détaillées sans être excessivement complexes.

\chapter{Implémentation et fonctionnement interne de \textit{KatAPI}}
\chaptermark{Implémentation et fonctionnement technique}
Le chapitre précédent s'attache à décrire le fonctionnement de l'\api{} côté client, c'est-à-dire la manière dont ce dernier interagit avec l'application, en présentant notamment la sémantique des requêtes et la structure des réponses. Cependant, une \api{} n'est pas seulement une interaction avec un client, c'est aussi un programme composé d'une série de fonctions chargées de traiter la requête du client, d'interagir avec la base de données et de construire une réponse. Ce chapitre décrit donc le fonctionnement de l'\api{} côté serveur: comment les données sont reçues, la manière dont elles sont traitées et comment les réponses sont construites.

En suivant le principe de séparation des préoccupations, le fonctionnement interne de l'\api{} (\ref{fig:api_backend}) peut être divisé en trois parties: la réception des requêtes et la vérification de leur validité, l'interaction avec les bases de données et la construction des réponses.

\section{Réception des requêtes}
Comme cela a été précisé au début du chapitre précédent, l'\api{} procède à un contrôle strict des requêtes afin de ne pas faire essayer de traiter des demandes contradictoires et de ne pas lancer de requêtes inutiles. Trois étapes de vérifications ont lieu afin de garantir le respect de la sémantique des requêtes:

\begin{itemize}
	\item Validité des paramètres utilisés: l'\api{} vérifie que la requête ne contienne pas de paramètres non autorisés.
	\item Validité des valeurs utilisés: l'\api{} vérifie que toutes les valeurs associées à des paramètres soient autorisées. Cette validation est faite à l'aide d'\glspl{expression régulière} pour les champs qui demandent des informations normalisées, tel que les dates (qui doivent être au format \enquote{AAAA} ou \enquote{AAAA-AAAA}).
	\item Absence de paramètres contradictoires: certains paramètres ne sont pas autorisés avec d'autres, car cela entraînerait la construction de requêtes incohérentes, en cherchant par exemple un nom d'auteur.ice et un identifiant qui ne correspondent pas. Pour éviter ce cas de figure, l'\api{} vérifie qu'une requête ne contienne pas de combinaisons \enquote{non-autorisées}.
\end{itemize}

Si la vérification se fait en plusieurs étapes, elle a lieu intégralement pour chaque requête (c'est-à-dire que l'exécution de la vérification ne cesse pas à la première erreur rencontrée). Cela permet d'obtenir une liste complète de toutes les erreurs présentes dans la requêtes: à chaque erreur détectée par l'\api{} est associé un mot clé. Si la requête n'est pas valide, alors il n'y a pas d'interaction avec le serveur. Une erreur \gls{http} 422 \textit{Unprocessable Content} (\textit{Contenu ne pouvant être traité}) est faite. Ce code d'erreur signifie que la requête est correcte d'après le protocole \gls{http} (sans quoi elle ne serait pas parvenue au serveur), mais qu'elle ne peut pas être traitée par le serveur\footcite[§15.5.21. \textit{422 Unprocessable Content}]{fielding_http_2022}. Le client doit donc modifier sa requête avant de la relancer. La liste d'erreurs constituée pendant la vérification est alors passée à un constructeur de réponse au format défini par le client (\json{} ou \tei{}). Ce constructeur de ajoute à la réponse un message pour chaque erreur rencontrée; il définit également l'en-tête de la réponse, avec le contexte de la requête, des taxonomies (éventuellement) et enfin le statut \gls{http}. Pour finir, les en-têtes \gls{http} sont établis, avec notamment le statut de la réponse et son type MIME, qui garantissent que le client pourra traiter ce que le serveur lui envoie. L'interaction avec le serveur prend alors fin.

\section{Interaction avec les bases de données et construction des réponses}
\sectionmark{Interaction...}
Si aucune erreur n'a été identifiée, alors la requête est traitée par le serveur. Dans un premier temps sont définies des valeurs par défaut pour les requêtes. Si aucune valeur n'a été fournie pour le paramètre \texttt{format}, alors le format de réponse est le \json{}; si aucun point d'accès n'a été défini, alors des données sont traitées au niveau du manuscrit. Commence alors la phase de récupération des données. Celle-ci est très différente en fonction du point d'accès défini par l'utilisateur.ice.

\subsection{Au niveau du catalogue complet (\texttt{cat\_full})}
C'est au niveau du catalogue complet que le traitement est le plus simple: l'\api{} se contente de chercher si le catalogue demandé par l'utilisateur.ice existe. Si c'est le cas, alors ce catalogue est passé à un constructeur de réponse. Celui-ci complète l'en-tête du catalogue en ajoutant dans le \texttt{tei:publicationStmt} le contexte de la requête (date, paramètres de la requête) et le statut \gls{http} 200, qui indique que l'interaction s'est déroulée normalement\footcite[§15.3.1 200 \textit{OK}]{fielding_http_2022}. Si le catalogue demandé n'est pas trouvé, alors le constructeur de réponse adopte un fonctionnement différent. Normalement, la réponse pour ce point d'accès est construite en ajoutant des données à un document pré-existant. Si celui-ci n'existe pas, alors une réponse complète doit être créée \textit{ex-nihilo} pour être renvoyée à l'utilisateur.ice. Dans ce cas, la réponse créée prend le même format que celle des deux autres points d'accès. Le constructeur renseigne le contexte de la requête et ajoute le statut \gls{http} 200. Celui-ci est utilisé même lorsqu'aucune réponse n'est obtenue: le fait que la ressource recherchée par le client n'existe pas ne veut pas dire pour autant qu'il y ait eu une erreur. Enfin, les en-têtes sont construits pour que la réponse soit renvoyée au client.


\subsection{Aux niveaux des manuscrits et des statistiques sur les catalogues (\texttt{item} et \texttt{cat\_stat})}
Aux niveaux \texttt{cat\_stat} et \texttt{item}, le traitement d'une requête fonctionne de façon analogue. Deux bases de données en \json{} contiennent des données sur tous les manuscrits et tous les catalogues. L'application commence alors par chercher dans ces fichiers tous les catalogues ou manuscrits pertinents. La recherche se fait en deux temps.

D'abord, l'application identifie toutes les manuscrits dont l'auteur.ice correspond au nom fourni par le client, ou tous les catalogues dont le type correspond à celui recherché par le client (\textit{RDA, AUC...}). Pour augmenter le nombre de résultats pertinents à retourner à l'utilisateur.ice, la recherche se fait en simplifiant à la fois la requête et les informations présentes dans la source de données. Par exemple, quand un manuscrit est recherché à partir du nom d'un.e auteur.ice, cette recherche se fait en comparant le nom fourni par le client avec celui présent dans la source de données. Normalement, cette recherche se fait par alignement complet des informations de la requête avec celles du fichier \json{}. Les données sont donc retraitées pour que la comparaison se fasse sans prendre en compte les différences de casse, d'accents et de ponctuation. Par exemple, si le client recherche tous les manuscrits écrits par \enquote{sévigné}, alors des manuscrits dont l'autrice est décrite comme étant \enquote{SÉVIGNÉ}, \enquote{Sévigné} ou \enquote{SEVIGNE} seront également jugés pertinents. Cette simplification de chaînes de caractères va dans le même sens que les méthodes utilisées par les moteurs de recherche contemporains. Cependant, la recherche pourrait être alignée plus finement encore, par exemple en sélectionnant les items pertinents non pas par correspondance de chaînes de caractères, mais en calculant une distance de Levenshtein. Celle-ci correspond au nombre de caractères de différence entre deux chaînes de caractères, et permet donc d'inclure un certain degré de bruit qui peut être très utile pour récupérer tous les résultats pertinents, surtout au vu des erreurs d'OCR qui rajoutent du bruit aux données. La recherche par nom d'auteur.ice.s a également une faiblesse majeure: elle ne se fait que par noms de famille, puisque ce n'est que ceux-ci qui sont présents dans la source de données.

Ensuite, ces résultats sont filtrés en fonction des autres paramètres de la requête du client, à savoir les dates de vente et, pour les manuscrits, de création. Si une date fournie correspond à une année, alors l'application ne conserve que les entrées datant de cette année. Si c'est au contraire une plage de dates qui est fournie, alors l'application ne conserve que les entrées qui sont contenues dans cette plage. Pour les manuscrits, date de création et date de vente peuvent être fournies. Dans ce cas, un manuscrit doit correspondre à ces deux dates (ou plages de dates) pour être conservé.

Une fois les données pertinentes extraites, soit une réponse est construite en \json{}, soit ces résultats sont transposés en \tei{}. C'est au niveau de la transposition qu'apparaît la différence de traitement entre les deux niveaux. Au niveau \texttt{cat\_stat}, il n'existe pas de représentation \tei{} des statistiques sur les différents catalogues. L'ensemble de ces statistiques sont donc extraites de la base de données en \json{} avant d'être traduites en un \tei{}. Lorsque des informations sont recherchées au niveau des manuscrits, cependant, une représentation \tei{} existe déjà. C'est donc elle qui doit être renvoyée à l'utilisateur.ice. Pourquoi, alors, ne pas rechercher directement les données pertinentes dans les fichiers \tei{}? Ce choix s'explique par des raisons de performance. Si les données sont directement extraites de la \tei{}, alors l'application doit rechercher des manuscrits dans près de 500 fichiers, ce qui demande d'ouvrir tous ces fichiers, de lire leur contenu et de rechercher à l'intérieur les manuscrits correspondants. Au contraire, la base de données sur les manuscrits en \json{} n'est qu'un seul (très volumineux) fichier. Il est donc plus rapide de commencer par ouvrir cette source de données pour extraire tous les identifiants des manuscrits correspondant aux paramètres souhaités. Un identifiant de manuscrit commençant par l'identifiant du catalogue dans lequel il est contenu, il ne reste plus qu'à ouvrir les catalogues pertinents pour récupérer les descriptions des manuscrits encodées en \tei{}.

Pour finir, des réponses complètes sont construites à partir des données extraites. En \json{} comme en \tei{}, la méthode est la même que celle qui a déjà été présentée: l'en-tête du document est reconstruite pour contenir les métadonnées décrivant la requête et les données contenues dans le corps de la réponse; ensuite, l'en-tête \gls{http} est défini, et la réponse est retournée à l'utilisateur.ice.

\section{Gestion des erreurs imprévues}
Le processus de traitement d'une requête a été testé, et ne rencontre théoriquement pas d'erreur. Cependant, l'application est exposée au public; une erreur imprévue est donc toujours possible, du fait d'une requête du client qui comprenne un problème imprévu ou d'une erreur qui n'ait pas été rencontrée pendant la conception de l'application et la rédaction des tests. Comme il n'est pas possible que l'application s'arrête tout simplement de fonctionner en cas d'erreur imprévue, un processus de gestion des erreurs internes a été défini. Si une erreur arrive entre le moment où une requête commence à être traitée et le moment où l'interaction prend fin, alors une erreur \gls{http} \textit{Internal Server Error} (\enquote{Erreur de serveur interne}) 500 est émise. Ce code d'erreur est un code générique qui indique au client qu'une erreur imprévue a été rencontrée\footcite[§15.6.1. 500 \textit{Internal Server Error}]{fielding_http_2022}. L'émission de cette erreur lance un processus isolé du reste de l'application de construction et de renvoi d'un message d'erreur. Ce processus étant entièrement séparé de la chaîne de traitement \enquote{normale} d'une requête, il ne risque pas d'être impacté par une autre erreur issue de \textit{KatAPI}. En cas d'erreur 500, une réponse est construire en \tei{} ou en \json{}. Elle contient dans son en-tête le contexte de la requête et la taxonomies nécessaires; le corps de la réponse est fait d'un message indiquant qu'une erreur imprévue a été rencontrée. Comme toujours avant l'envoi d'une réponse au client, les en-têtes \gls{http} sont définis; enfin, la requête est envoyée au client.

\widepage
\begin{figure}[p]
	\centering
	\tikz[scale=0.75, transform shape]{
		\node[base] (client) at (0,-10)%
			{Client};
		\node[base] (server) at (0,-7)%
			{Serveur};
		\node[choice] (valid) at (0,-4)%
			{Est-ce que la requête est valide?};
		\node[choice] (level) at (0,0.5)%
			{Quel est le point d'accès?};
		\node[base] (error422) at (7,-4)%
			{Erreur HTTP 422};
		\node[base] (catfull) at (-7,4)%
			{\texttt{cat\_full}};
		\node[base] (catstat) at (0,4)%
			{\texttt{cat\_stat}};
		\node[base] (item) at (7,4)%
			{\texttt{item}};
		\node[transf] (catfull-get) at (-7,6)%
			{Extraction du catalogue};
		\node[transf] (catstat-get) at (0,6)%
			{Extraction de données sur les catalogues};
		\node[transf] (item-get) at (7,6)%
			{Extraction de données sur les items};
		\node[choice] (catstat-format) at (0,9)%
			{Quel est le format demandé?};
		\node[choice] (item-format) at (7,9)%
			{Quel est le format demandé?};
		\node[transf] (catstat-tei) at (-4.5,13)%
			{Traduction des données en \tei{}};
		\node[transf] (item-tei) at (4.5,13)%
			{Extraction des données en \tei{} depuis les catalogues};
		\node[transf] (build-json) at (8,17)%
			{Construction d'une réponse en \json{}};
		\node[transf] (build-tei) at (-6,17)%
			{Construction d'une réponse en \tei{}};
		\node[transf, minimum width=7cm] (headers) at (0,20)%
			{Construction des en-têtes HTTP};
		\node[%
			outline,%
			minimum width=22cm,%
			minimum height=11cm,%
			dash dot dot,%
			draw=persimmon,%
			label={%
				[rotate=-90,yshift=0.5cm,xshift=-4cm]%
				right:Erreur HTTP 500 lancée en cas de problème
			}%
		] (error500) at (1,8.75) {};
		
		\node[blank] at (-2.5,-8.5) {Requête};
		\node[blank] at (2.5,-8.5) {Réponse};
		\node[blank,rotate=-90,minimum width=4cm,text width=7cm] at (11.75,-2) %
			{Construction d'une réponse \\ en \json{} ou \tei{}};
		\node[blank] at (8.5,10.5) {\json{}};
		\node[blank] at (-2.25,10.5) {\tei{}};
		\node[blank] at (1.25,10.5) {\json{}};
		\node[blank] at (5.5,10.5) {\tei{}};
		\node[blank] at (4,-4.3) {NON};
		\node[blank] at (0.5,-1.75) {OUI};
		
		\begin{pgfonlayer}{bg}
			\draw[arrow] (client) -- (-1.5,-10) -- (-1.5,-7.75) -- (server);
			\draw[arrow] (server) -- (1.5,-7) -- (1.5,-9.25) -- (client);
			\draw[arrow] (server) -- (valid);
			\draw[arrow] (valid) -- (error422);
			\draw[arrow] (valid) -- (level);
			\draw[arrow] (level) -- (catfull);
			\draw[arrow] (level) -- (catstat);
			\draw[arrow] (level) -- (item);
			\draw[arrow] (catfull) -- (catfull-get);
			\draw[arrow] (catstat) -- (catstat-get);
			\draw[arrow] (item) -- (item-get);
			\draw[arrow] (catfull-get) -- (-7,16) -- (build-tei);
			\draw[arrow] (catstat-get) -- (catstat-format);
			\draw[arrow] (item-get) -- (item-format);
			\draw[arrow] (item-format) -- (item-tei);
			\draw[arrow] (catstat-format) -- (catstat-tei);
			\draw[arrow] (catstat-tei) -- (-4.5,15) -- (build-tei);
			\draw[arrow] (item-tei) -- (0,13) -- (build-tei);
			\draw[arrow] (item-format) -- (8,11) -- (build-json);
			\draw[arrow] (catstat-format) -- (1,11.5) -- (8,11.5) -- (build-json);
			\draw[arrow] (build-tei) -- (headers);
			\draw[arrow] (build-json) -- (headers);
			\draw[arrow] (headers) -- (-11,20) -- (-11,-7) -- (server);
			\draw[dotted, ultra thick] (error422) -- (11,-4) -- (11,15) -- (9,15) -- (build-json);
			\draw[dotted, ultra thick] (9,15) -- (0,15) -- (build-tei);
		\end{pgfonlayer}
	}
	\caption{Fonctionnement interne de \textit{KatAPI}}
	\label{fig:api_backend}
\end{figure}
\restoregeometry

\section{En conclusion}
L'application présentée ici vise à être un outil pour chercheur.euse.s, qui permette le partage de données de façon automatisée. Cela peut faciliter la récupération de données brutes, sans avoir à passer par un téléchargement \enquote{à la main}. L'objectif est donc d'enrourager la réutilisation de données dans un contexte de science ouverte. L'\api{} va cependant plus loin que la simple récupération de données brutes, puisqu'elle fonctionne comme un moteur de recherche à facettes. Elle permet par exemple de rechercher tous les manuscrits vendus entre 1880 et 1890 et écrits par Mme de Sévigné entre 1660 et 1680. Cette fonctionnalité, et la possibilité de mener des recherches à différents niveaux, peut aider à la constitution de jeux de données sur mesure, ce qui peut être utile autant dans la suite du projet que pour d'autres chercheur.euse.s. Si les données partagées sont brutes, leur partage demande d'être tout sauf brut. Des données hors contexte sont inutilisables, autant par une personne humaine que par une machine. C'est pourquoi deux standards ont été suivis: l'un technique (le \gls{rest}) et l'autre scientifique, le \gls{fair}. Ces standards et principes servent à la recherche, puisqu'ils permettent tout simplement la production de données utilisables par des chercheur.euse.s. Cependant, ils aident également à la technique, puisqu'ils forcent à penser aux manières de bien diffuser des données, une question qui sont éminemment technique. La conception de cette \api{}, et la réflexion qu'elle engendre sur les manières de diffuser des données de recherche, montrent que le partage de données n'est pas uniquement un problème technique, qui dépend de la disponibilité d'outils. Ce n'est pas non plus seulement un problème légal, où des licences encadrant clairement le partage et l'utilisation de données par autrui sont nécessaires. La diffusion de données de recherche est avant tout un problème scientifique, qui ne peut être résolu que par une bonne compréhension de ce qui est partagé. Il apparaît, au final, qu'il n'existe pas vraiment de données \enquote{brutes}: celles-ci demandent à être éditorialisées et incluses dans des fichiers structurés et documentés afin d'être réutilisables. Même en essayer de s'éloigner du texte (les catalogues encodés) pour arriver à diffuser des données, le processus de modélisation et rappelle l'importance de la structuration des données, qu'il s'agisse de texte ou de statistiques. Il est impossible de \enquote{seulement} diffuser des données, et on en revient donc toujours à ce que Flanders et Jannidis disent dans leur introduction au livre \textit{The Shape of Data in the Digital Humanities} (2019):

\begin{displayquote}
	Les processus de modélisation inscrivent en des termes formels notre connaissance du contenu et de la sémantique de nos données à l'intérieur de ces mêmes données.\footnote{
		\cite[p. 9]{flanders_data_2019}. Traduction de l'auteur. Original: \enquote{In effect, modelling processes write our knowledge about the content and semantics of our data into that data in formal terms [...]}.
	}
\end{displayquote}

% \section{Gestion des erreurs}
% L'\api{} étant une application devant interagir avec des utilisateur.ice.s et gérer leurs requêtes, il n'est pas pensable qu'elle \enquote{plante} ou ne renvoie pas d'erreur. Tout un système de gestion des erreurs a donc été défini. Ces erreurs peuvent être classées en deux catégoriés: côté client (dues à des entrées invalides des utilisateur.ice.s)  et côté serveur (erreurs inattendues qui empêchent l'exécution d'une requête). Si ces erreurs sont rencontrées, des réponses sont construites en \json{} ou \xmltei{} (selon le format demandé par l'utilisateur.ice.s). Celles-ci décrivent l'erreur et permettent donc aux utilisateur.ice.s de corriger les erreurs qui ont pu avoir lieu côté client.

% \section{Garantir le bon fonctionnement de l'application}
% De la même manière que les systèmes de gestion des erreurs garantissent que l'application continue à fonctionner même en cas d'erreur, les tests garantissent que l'\api{} soit fonctionnelle, même dans \enquote{des conditions extrêmes}. Les réponses, formats et données retournées sont donc testés. C'est ce protocole de test qui est présenté ici.