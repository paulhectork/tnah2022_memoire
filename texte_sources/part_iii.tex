%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%% TROISIEME PARTIE %%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\part{Rendre la recherche réutilisable et interopérable: \textit{KatAPI}, une API pour échanger des données structurées}

La problématique de cette partie est la suivante: comment rendre la recherche en humanités numériques réutilisable et encourager le partage de données entre projets de recherche? La réponse à cette question, au sein du projet \mssktb{} prend la forme d'une \api{}. Celle-ci diffuse des données source du projet, mais aussi des informations issues de la recherche et du traitement computationnel de celles-ci dans deux formats structurés: le \json{} et le \xmltei{}.

En guise d'introduction, il me semble important ici de faire un bref rappel des principes fondamentaux du développement applicatif et de l'architecture du Web. Certains de ces principes ont déjà été présentés, mais ce rappel permettra de rendre la suite de ce chapitre plus claire.

Le Web est une architecture de type client-serveur qui permet l'interaction de machines dans un réseau décentralisé. Cette architecture définit deux fonctions possibles pour une machine: client (qui envoie et récupère des données distantes) et serveur (qui contient une application permettant l'interaction avec le client, ainsi qu'une base de données). Dans le Web, l'architecture client-serveur repose sur un protocole technique qui pose les principes de l'interaction entre des machines: le \gls{http}. Selon ce principe, l'accès d'un client à une ressource stockée sur un serveur (une page Web, par exemple) se fait au travers d'un \gls{url}. Celui-ci sert à localiser la ressource. L'interaction est définie par des requêtes (du client au serveur) et par des réponses (du serveur au client). Six types de requêtes sont possibles, qui correspondent à autant d'actions: demander des données à un serveur, en supprimer, les mettre à jour... Requêtes et réponses ont la même structure: elles sont composées d'un en-tête \gls{http} (qui contient des métadonnées sur la requête ou la réponse) et d'un corps (qui contient la requête ou la réponse en elle-même; celui-ci peut être vide). Parmi les métadonnées contenues dans l'en-tête, deux sont importantes dans notre contexte (surtout pour les réponses du client au serveur): le statut et le type MIME. Un statut est un code à trois chiffres qui caractérise la réponse et le déroulement de l'interaction client-serveur. \enquote{200} indique que tout va bien, \enquote{404} que la ressource demandée n'existe pas (c'est-à-dire, que l'\gls{url} de la requête ne pointe pas vers une ressource existante). Le type MIME est une manière standardisée de définir le format d'une réponse: \enquote{\texttt{application/json}} lorsque la réponse est au format \json{}, \enquote{\texttt{application/xml}} lorsque du \xml{} est renvoyé.

Une \api{} est une application, c'est-à-dire un ensemble de fonctions rassemblées pour permettre l'interaction entre un client et un serveur. Souvent, et c'est le cas pour les applications du projet \mssktb{}, une application permet l'interaction avec une base de données, elle-aussi stockée sur le serveur. Par exemple, lorsque l'on accède à une page \textit{Wikipedia}, l'application reçoit une requête de la part d'un client; elle va chercher dans la base les données pertinentes, les structure sous la forme d'une page HTML et les renvoie à l'utilisateur.ice, qui verra la page s'afficher sur son écran. La principale différence entre une \api{} Web et une application (comme \textit{Wikipedia}) est que l'\api{} est \enquote{un site Web pour machines}. Elle ne contient pas d'interface graphique et les réponses renvoyées par l'\api{} sont des données dites \enquote{brutes}; celles-ci ont l'avantage d'être lisibles et manipulables par une machine. L'interaction avec une \api{} se fait en envoyant une requête à l'application avec un \gls{url} qui contient les paramètres de la requête et des valeurs associées à ces paramètres (quelles données demander, quel format de réponse utiliser...) et éventuellement un corps de requête qui contienne des données (ce qui n'est pas le cas lorsque la requête correspond à une demande de données). L'\gls{url} contient donc la sémantique de la requête, il correspond à une question posée à un serveur de façon structurée. L'intérêt d'une telle \api{} est que, pour peu que l'on sache interagir avec elle, il est possible de récupérer automatiquement des données structurées, prêtes à être utilisées. Pour télécharger un jeu de données, il n'y a pas besoin, par exemple, d'aller sur la bonne page Web, de cliquer sur un bouton \enquote{Télécharger} et d'enregistrer le fichier au bon endroit. Toutes ces opérations peuvent être faites automatiquement, comme cela a été fait pour plus de 80000 requêtes lors de l'interaction avec \wkd{} décrite précédemment. Cette perspective est particulièrement intéressante pour un projet de recherche, puisqu'elle peut permettre de récupérer automatiquement les jeux de données produits par un autre projet, ce qui encourage la réutilisation des données de la recherche. Pour des ingénieur.e.s des données, les \api{} facilitent grandement le travail de récupération automatisée d'informations: elles permettent de \enquote{se concentrer sur le quoi, et non sur le comment}\footnote{\textit{focus on the what, and not on the how}. Citation issue de \cite[p. 2]{murdock_inpho_2011}.}.

Souvent, un site Web peut être composé d'une version accessible pour des utilisateur.ice.s humain.e.s et pour des machines; c'est le cas dans le projet \ktb{}. L'application pour humain.e.s a déjà été développée; c'est la version pour les machines, son fonctionnement et son utilité pour permettre la réutilisation des données du projet qui est donc présentée dans cette partie.

\chapter{Standards de design et statut des API dans pour les humanités numériques centrées sur le texte}
\chaptermark{Standards de design et statut}
Il n'existe aucune norme communément acceptée pour la conception d'une \api{}: dans l'absolu, tant que celle-ci fonctionne, elle peut être considérée comme une \api{}. Cependant, des standards se sont développés afin de regrouper les différentes méthodes et de développer des bonnes pratiques de design. Deux types de standards sont ici présentés: les standards d'architecture et les standards d'interopérabilité. Un standard d'architecture ou de design, comme le \gls{rest}, définit comment concevoir l'interaction client-serveur dans une \api{} et proposent une manière de structurer les réponses du serveur. Il ne définit cependant pas quels paramètres de recherches sont autorisés, ni le corps d'une réponse doit être organisé. Il ne définit pas non plus précisément comment organiser une requête, c'est-à-dire quel \gls{url} construire pour accéder aux données. C'est le rôle des standards d'interopérabilité (\gls{oaipmh}, \gls{cts}, \gls{dts}). Ceux-ci définissent la sémantique des requêtes (c'est-à-dire les paramètres autorisés) et la manière de construire un \gls{url} pour accéder à certaines données. Ils permettent donc l'interopérabilité, puisqu'une même syntaxe peut être utilisée pour requêter différentes \api{}. Ni le \gls{rest}, ni les standards d'interopérabilité ne définissent l'implémentation d'une \api{}: les deux types de standards s'intéressent à l'interaction du client avec l'\api{}, ils ne définissent pas l'application en elle-même. Une application qui se conforme à un standard garantit simplement un certain type d'interaction client-serveur. En plus de ces deux standards qui sont ici présentés, les principes \gls{fair} sont également décrits: ceux-ci ne définissent ni implémentation, ni sémantique, mais sont simplement des principes généraux pour la manière dont des données doivent être partagées dans un contexte de science ouverte et réutilisable.

% Ici est présenté un état de l'art sur la conception d'\api{} dans un contexte d'humanités numériques. Sont présentés un standard de design pour la conception d'api (le REST), l'architecture API-DTS (équivalent du IIIF pour le texte). Si l'\api{} conçue ne se rattache pas à ces concepts, ceux-ci ont servi d'inspiration pour l'architecture de \textit{KatAPI}. Les principes FAIR (essentiels pour la recherche ouverte et interopérable) sont également présentés, ainsi que l'état de l'art pour le design d'\api{} dans un contexte d'humanités numériques. Il apparaît que de tels outils sont majoritairement conçus par des institutions (\textit{DataBnF}...) plutôt que par de simples projets de recherche.

\section{Que faire du FAIR? Le partage des données de la recherche}
Les principes \gls{fair}\footcite{boeckhout_fair_2018} sont essentiels aux problématiques de la science ouverte. Celle-ci encourage non seulement la diffusion de la recherche dans des formats traditionnels (articles, conférences...), mais aussi la diffusion de données brutes issues de la recherche scientifique. L'objectif, dans la diffusion de ces données brutes, est de rendre les données réutilisables, mais aussi de permettre la reproductibilité de la recherche, et donc la vérification des résultats obtenus. 

La problématique de la diffusion de données recherche brutes se retrouve bien sûr en humanités numériques. Dans le domaine de la reconnaissance optique de caractères, par exemple, se développe le partage de vérités de terrain. La reconnaissance de caractères est permise par l'entrainement d'un algorithme d'apprentissage machine sur des textes qui ont été transcrits manuellement; c'est ce couple texte numérisé/transcription qui constitue la vérité de terrain. Or la production de ces données demande beaucoup de temps ainsi que des compétences spécifiques pour des graphies difficiles à lire et des langues rares\footnote{Un exemple de ces corpus \enquote{difficiles} est le développement de la reconnaissance optique de caractères pour le Cham, langue parlée par une minorité originaire du Sud-Est de l'Asie. Celle-ci comprend environ 30000 locuteurs. Le projet travaille également à la reconnaissance du Cham ancien, qui est extrêmement méconnu (\cite{schweyer_analyse_2022}).}. Pour faciliter le développement de méthodes de reconnaissance optique de caractères se développent donc des initiatives pour faciliter le partage de vérités de terrains. Parmi ces initiatives se trouve le projet \textit{HTR United}\footcite{chague_sharing_2022}, qui offre un portail pour l'accès à et le dépôt de vérités de terrains. Celles-ci sont partagées avec des métadonnées précisant par exemple leur contexte de production, le domaine auquel appartient au corpus.

La diffusion de données de recherche est cependant une opération plus complexe qu'il ne pourrait y paraître; c'est pourquoi les principes \gls{fair} ont été édités en 2014\footcite[p. 931]{boeckhout_fair_2018}. Ils forment une base minimale de recommandations sur la manière de partager des données de recherche. Cette base minimale est composée de quatre principes\footcite[p. 932-933]{boeckhout_fair_2018}: 

\begin{itemize}
	\item \textit{Findability}: les jeux de données doivent être diffusés sur des dépôts publics; ils doivent être décrits avec suffisamment de métadonnées pour que leur périmètre et la manière dont ils ont été constitués soient clairement identifiables.
	\item \textit{Accessible}: les jeux de données doivent être accessibles librement et idéalement de façon manuelle aussi bien qu'automatique.
	\item \textit{Reusable}: les jeux de données doivent être réutilisables. Cela implique de définir un périmètre pour la réutilisation des données, notamment au travers de licences.
	\item \textit{Interoperable}: les jeux de données doivent être diffusés dans des formats structurés, compréhensible par des humain.e.s et, idéalement, manipulables par des machines.
\end{itemize}

Qu'en est-il de la relation entre ces principes et la conception d'\api{}? La diffusion automatisée par le biais d'applications semble aller main dans la main avec les principes \gls{fair}. Une \api{} permet de diffuser automatiquement des données brutes et structurées dans des formats interopérables. Cependant, une \api{} n'adhère pas par défaut aux principes \gls{fair}. Elle garantit l'accessibilité des données; pour qu'elles soient réutilisables, la conception d'\api{} doit être considérablement étoffée. Il faut en effet définir le contexte de production des données, ainsi que la licence dans laquelle elles sont diffusées. Il est donc nécessaire d'ajouter des métadonnées aux réponses de l'\api{} ou de trouver un moyen de documenter les conditions de réutilisation des données. La notion de \enquote{dépôt public} requis par les principes \gls{fair} pour partager des données change également de sens. L'\api{} sert pas à partager les données sur un autre dépôt qui agrège des jeux de données, elle sert à les diffuser à des utilisateur.ice.s. Une \api{} pour la recherche forme donc sa propre plateforme de diffusion des données. Enfin, il faut garantir que les données soient compréhensibles. Cet aspect des principes \gls{fair} n'est pas anodine dans la conception d'une \api{}. Non seulement celle-ci doit renvoyer des réponses structurées et valides; la sémantique des réponses doit également être explicitée. Cela veut dire que, soit dans l'\api{}, soit dans la documentation, le sens de chaque élément doit être précisé. La documentation est ici importante; mais l'utilisation de la \tei{} est également intéressante en vue de ce besoin de produire des données compréhensibles. Ce standard, en plus d'être très pratiqué dans les humanités numériques, est défini dans les \textit{TEI Guidelines}\footcite{tei_consortium_p5_2022} et dispose donc d'une documentation officielle. Au delà de ces principes abstraits, de véritables standards techniques peuvent servir d'inspiration dans le développement d'\api{} pour diffuser des données de recherche.

\section{Le REST: un modèle pour le design d'API}
Ici est présenté le standard REST, défini par Roy Fielding\footcite{fielding_architectural_2000}; ce standard architectural est considéré comme l'idéal à atteindre en matière de design d'\api{}. Il n'a cependant pas été suivi ici, en partie parce qu'il est mieux adapté à un projet de plus grande échelle, et en partie car il ne fonctionne pas de façon optimale avec le modèle de données défini, et notamment avec le choix de construire une \api{} renvoyant des réponses conformes à la \tei{}.

Le standard \gls{rest} (\enquote{État de transfert représentatif}) est un standard et un style pour la conception d'\api{} dans une architecture client-serveur. Il est aujourd'hui un standard de fait pour la conception de tels outils, et est considéré comme une bonne pratique dans l'architecture d'\api{}. Le standard \gls{rest} ne définit pas comment une \api{} doit être implémentée, mais définit la structure de l'interaction client-serveur. Historiquement, le développement de ce standard est fortement lié à l'établissement du protocole \gls{http}, puisque le concepteur du \gls{rest} est l'un des ingénieur.e.s à l'origine du protocole. Le \gls{rest} définit un ensemble de quatre contraintes supplémentaires à celles présentes dans le protocole \gls{http}\footcite[p. 94]{fielding_architectural_2000}. Une \api{} \gls{rest} doit répondre aux contraintes suivantes:

\begin{itemize}
	\item Être sans état\footcite[p. 78-79]{fielding_architectural_2000}. Cela signifie qu'une requête du client au serveur doit contenir l'ensemble des informations nécessaires au traitement de la requête. Le serveur ne peut accéder à un contexte ou à d'autres informations pour traiter la requête. Cela permet de rendre les requêtes plus faciles à interpréter, limite le risque d'erreurs et permet à l'\api{} de fonctionner à plus grande échelle, puisqu'elle n'a pas besoin d'utiliser de les ressources pour chercher des informations ailleurs que dans la requête.
	\item Présenter une interface uniforme\footcite[p. 81-82, 86-97]{fielding_architectural_2000}. C'est peut-être ce principe qui est définitoire du \gls{rest}: l'interface, c'est-à-dire la partie de l'\api{} qui est exposée au client, doit toujours être la même. Il y a donc un découplage entre la communication avec le client (réception des requêtes et envoi des réponse) et le traitement des requêtes, qui ne sont pas accessibles au client. Cette séparation permet de modifier la manière dont une requête est traitée sans devoir changer la sémantique et la structure de l'interaction avec le client. Ce principe implique d'autres contraintes:
	\begin{itemize}
		\item L'identification des ressources dans des requêtes: un client requête une \gls{uri} et le serveur lui renvoie une représentation de cette \gls{uri}. Dans le contexte du Web, cela veut dire qu'un \gls{url} doit nécessairement être fourni au moment de la requête et que celui-ci doit pointer vers les ressources à traiter.
		\item Les ressources sont communiquées sous la forme de représentations. Cela veut dire que les données envoyées au client peuvent être dans une structure ou un format différents de ceux de la base de données: l'\api{} doit traduire les données telles qu'elles sont dans la base en leur représentation.
		\item Les réponses \gls{http} doivent être auto-descriptives: les en-têtes et le corps de la requête doivent contenir assez de (méta-)données pour pouvoir être manipulées par le client sans avoir besoin d'informations extérieures.
		\item Utilisation de l'hypermédia comme moteur de navigation. Comme sur un site Web normal, des hyperliens doivent permettre de naviguer d'une ressource à l'autre et doivent être accessibles directement depuis l'\api{}.
	\end{itemize}
	\item Autoriser la mise en cache explicite\footcite[p. 79-81]{fielding_architectural_2000}. Une réponse du serveur au client doit explicitement indiquer si les données contenues dans une réponse peuvent être mises en cache (c'est-à-dire, stockées dans la mémoire pour y être accédées plus tard). La possibilité de cacher les données peut potentiellement diminuer le nombre de requêtes envoyées au serveur.
	\item Présenter une architecture en couches\footcite[p. 82-84]{fielding_architectural_2000}. Une application peut être entièrement stockée sur un serveur, ou fonctionner par l'interaction de différents serveurs. Dans ce cas, un client peut être connectés à différents serveurs, mais ne doit pas savoir s'il se trouve sur un serveur intermédiaire ou un serveur final. Les serveurs intermédiaires peuvent modifier les messages à renvoyer au client, répartir les charges sur différents serveurs ou établir des politiques de sécurité.
	\item Diffuser du code à la demande (optionnel)\footcite[p. 84-85]{fielding_architectural_2000}.
\end{itemize}

Les concepts centraux dans ce système architectural -- du moins, pour une petite \api{} comme celle de \ktb{} sont le fait d'être sans état et l'uniformité de l'interface. Ces deux concepts signifient que les requêtes comme les réponses doivent être entièrement auto-descriptives. Les autres principes sont mieux adaptés à des \api{} à plus grande échelle: la mise en cache explicite suppose que la même requête puisse être envoyée en série par un client à un serveur; pour une \gls{api} d'un projet de recherche, il est plus probable qu'une requête soit faite une unique fois pour récupérer des données. L'utilisation d'une architecture en couche n'est pas du ressort de \textit{KatAPI}, puisque l'intégralité de l'\api{} est présente sur un seul serveur. Enfin, la diffusion de code exécutable n'est pas non plus adaptée aux données qui sont requêtées et diffusées via l'\api{}.

La mise au point d'une architecture sans état demande de mettre au point une sémantique pour les requêtes qui soit auto-descriptive, c'est-à-dire qui décrive l'intégralité de la requête. L'uniformité de l'interface, d'un point de vue de développement applicatif, est une problématique plus complexe. D'abord, elle demande d'établir des modèles de données uniformes pour le corps des réponses \gls{http}. Cela veut dire que, pour chaque format de réponse autorisé et point d'accès aux données possible, les réponses doivent être contenues dans une structure qui est toujours la même. Ensuite, les en-têtes doivent être constitués pour décrire adéquatement la réponse. Cela passe par la définition d'un statut \gls{http} et d'un type MIME à chaque réponse. Ainsi, une machine peut savoir quel format de réponse est obtenu, et comment la requête s'est déroulée. Cependant, l'utilisation d'hyperliens comme moteur de l'application n'a pas été implémentée: les réponses ne contiennent pas d'hyperliens qui permettent de naviguer automatiquement vers d'autres ressources ou actions. L'ensemble des ressources accessibles et la manière d'y accéder sont au contraire définies de façon centralisée dans la documentation de l'\api{}, qui n'est pas lisible par une machine. Enfin, du point de vue de l'implémentation, la communication client-serveur est indépendante du traitement des requêtes et de l'interaction avec les bases de données.

Par conséquent, les choix techniques mis en place font de l'\api{} une application \textit{RESTlike} (c'est-à-dire, qui se conforme à un certain degré aux principes REST), voire \textit{RESTful} (qui se conforme entièrement aux principes REST). \textit{KatAPI} suit le standard REST là où il est pertinent pour les données transmises (ce qui exclut la condition de transmission de code et la clause de mise en cache). L'\api{} suit également les principes \gls{rest} là où il est de son ressort de les suivre (ce qui exclut une architecture en couches, puisque l'application est distincte de son installation sur un serveur). Suivre ces principes et s'en inspirer permet de concevoir une application au comportement uniforme, et où le client n'a pas à vérifier les réponses obtenues, puisqu'elles seront toujours les mêmes et qu'elles contiendront toutes les informations nécessaires à leur traitement (format de réponse, statut HTTP...).

\section{OAI-PMH, CTS et DTS: quels standards pour le partage du texte en humanités numériques?}
\sectionmark{OAI-PMH, CTS et DTS}
Les principes REST, présentés ci-dessus, concernent l'architecture et le design d'une \api{}; cependant, ils ne s'attaquent pas à une autre partie du problème: l'interopérabilité des \api{}. Chacune de ces applications définit sa propre sémantique pour les requêtes et autorise certains formats de réponse. Cela conduit à un problème pour les programmes consommateurs d'\api{}: l'interaction avec deux \api{} demande la construction de requêtes différentes, et demande donc d'apprendre à utiliser différentes \api{}. Lorsque celles-ci sont complexes, apprendre à utiliser une \api{} n'a rien d'anodin, et se servir de différentes \api{} devient complexe. De plus, l'absence d'interopérabilité signifie qu'il est difficile, voire impossible, de travailler de la même manière avec les données issues d'\api{} différentes. Si l'une renvoie du \json{} mais l'autre du \xml{}, par exemple, les résultats issus des deux \api{} doivent être utilisés différemment. Cela complexifie la convergence des données de la recherche et limite l'interopérabilité de ces données, qui est pourtant l'un des principes \gls{fair}\footcite[p. 932-933]{boeckhout_fair_2018}. Pour faire face à ce problème, des standards d'interopérabilité ont été développés. Ceux-ci définissent à minima une sémantique unique qui peut être implémentée par plusieurs \api{}. Parfois, ils définissent également des formats de réponse. Le plus célèbre de ces standards, dans les humanités, est le protocole IIIF, qui permet d'interagir avec une image (en lui ajoutant une couche d'annotations, par exemple). Dans les humanités centrées sur le texte, les standards d'\api{} sont plus diversifiés. Trois sont présentés ici: l'\gls{oaipmh}, le \gls{cts} et le \gls{dts}. Aucun d'entre eux n'a été adopté dans la conception de l'\api{} \ktb{}, mais ils sont tous riches de leçons dans le développement d'une telle application

\subsection{OAI-PMH: un premier standard à succès}
L'\gls{oaipmh} vient du monde des archives et des bibliothèques. Les bibliothèques ne conservant pas des objets uniques, mais des documents produits en série, elles sont pionnières dans le développement de méthodes computationnelles pour le partage des données\footcite[p. 2-3]{prime-claverie_defi_2017}. Aussi ce standard a-t-il connu une adoption inégalée, puisqu'il est aujourd'hui le standard d'interopérabilité le plus utilisé dans les bibliothèques\footcite[p. 5]{prime-claverie_defi_2017}; il est y compris utilisé par les plateformes en ligne HAL, OpenEditions ou encore CAIRN. Ce standard vise à permettre l'interopérabilité sémantique (uniformiser la sémantique des requêtes et des réponses) et technique (uniformiser les formats de réponse)\footcite[p. 6-14]{prime-claverie_defi_2017}. Il ne vise cependant pas à partager des documents, mais seulement leurs métadonnées (en d'autres termes, l'\gls{oaipmh} ne permet pas de partager un document, mais seulement sa notice bibliographique); il ne permet pas non plus de partager des données sur un document, mais sur une collection entière. Les réponses de l'\gls{oaipmh} sont constituées de collections de notices encodées en XML; l'interopérabilité sémantique des réponses est permise par l'utilisation du Dublin Core, un format considéré comme un plancher pour le partage de données bibliographiques. L'interopérabilité technique, elle, repose sur un format de réponse en \xml{}\footcite[p. 4]{prime-claverie_defi_2017}. Comme le montrent Prime-Claverie et Mahé, cette interopérabilité n'empêche cependant pas une grande variété dans les implémentations: certaines utilisent des réponses en \xmltei{}, d'autres non; les structures des réponses varient elles-aussi, avec différents éléments Dublin Core associés à différentes données\footcite[p. 6-14]{prime-claverie_defi_2017}. D'un point de vue technique, le fonctionnement d'\gls{oaipmh} est intéressant: l'entrepôt \gls{oaipmh} est distinct de la base d'où il récupère les données. Cela veut dire que, lorsqu'une requête est reçue, l'\api{} la communique à l'entrepôt \gls{oaipmh} qui transforme les informations contenues dans la base de données. D'un point de vue d'ingénierie, cela veut dire que les parties de ce système (base de données -- entrepôt \gls{oaipmh} -- \api{}) sont distincts\footcite[p. 4]{prime-claverie_defi_2017}. Par conséquent, les données n'ont pas besoin d'être stockées dans des formats compatibles; des transformations dans une partie n'impliquent pas de devoir transformer les autres parties (sauf pour permettre l'interaction entre les différents éléments du système). Par exemple, une modification de la structure de la base de données ne demande pas de transformer toute l'\api{}, mais seulement la manière dont ces données sont transformées pour être compatibles avec le standard \gls{oaipmh}. 

Que retenir de cet exemple? Tout d'abord, que ce n'est pas parce qu'un standard existe qu'il sera implémenté uniformément. Une marge de manœuvre est toujours présente, ce qui peut amener à des résultats très différents. Bien sûr, cela va à l'encontre du principe d'interopérabilité et complexifie la convergence des ressources d'origine différente. Cependant, comme le rappellent Prime-Claverie et Mahé\footcite[p. 15-16]{prime-claverie_defi_2017}, ces variations ne sont pas nécessairement problématiques. Elles permettent aux différentes institutions qui l'implémentent de fournir des données adaptées à certaines communautés de pratique -- il va de soit qu'une archive et une bibliothèque sont deux institutions très différentes, et qu'elles ne peuvent représenter leurs documents de la même manière. L'implémentation technique de l'\gls{oaipmh} est également intéressante: elle sépare les données (dans une base de données) de leur représentation. Ce qui est communiqué au client, c'est cette représentation, compatible avec le protocole \gls{oaipmh}. Cette idée, qui rappelle les principes \gls{rest}, est mise en place d'autres standards présentés ici. D'un point de vue de développement, la séparation entre les différentes parties nécessaires au fonctionnement de cet \api{} facilitent également son maintient et l'ajout de nouvelles fonctionnalités, puisque le système ne doit pas être modifié lorsque c'est seulement un élément qui est affecté. Cependant, l'\gls{oaipmh} n'est pas adapté aux besoins de \ktb{}: ce standard ne permet pas d'échanger du texte, mais seulement des métadonnées. De par sa taille, il est également difficile à implémenter pour un projet de recherche.

\subsection{CTS, DTS: des méthodes de standardisation pour l'échange de texte}
Le \gls{cts} a été développé dans un contexte très différent de l'\gls{oaipmh}. Il est issu d'un projet de recherche à Harvard, le \textit{Homer Multitext} consacré à l'édition de l'\textit{Illiade} et de l'\textit{Odyssée} d'Homère. Le standard est donc pensé pour l'édition de textes canoniques antiques. Il naît d'un problème technique: comment faire coïncider la structure en arbre d'une édition numérique avec la structure citationnelle traditionnelle, où les citations font références à des pages. Aux origines du projet se trouve également l'idée qu'un texte existe à l'intérieur d'un système citationnel, où les textes fonctionnent par référence les uns aux autres\footcite{smith_four_2012}. Cette idée est particulièrement importante dans un projet d'édition critique, comme le \textit{Homer Multitext}, où les différents témoins des textes d'Homère doivent pouvoir être alignés et comparés. La \tei{} a développé ses propres systèmes de référence pour les éditions critiques, basés sur le concept d'arbres décisionnels (où chaque témoin peut être représenté par une feuille, et où les différentes feuilles viennent d'une branche commune)\footcite{tei_consortium_p5_2022}. Mais ce système ne permet pas de cibler efficacement un passage dans un texte, ni de faire référence à ce passage en dehors du document lui-même. Comment, dans ce cas, représenter des références dans une édition numérique? Comment rendre des parties de texte accessibles à l'extérieur d'un texte, dans une architecture client-serveur? La réponse proposée à l'initiative de Smith et Blackwell est le \gls{cts}. Ce système définit une sémantique permettant d'identifier un texte, un passage de texte ou même un ensemble de textes grâce à une \gls{uri}. Celle-ci cible de plus en plus précisément le passage voulu. Par exemple, \texttt{urn:ctsl:greekLit:tlg0012.tgl001.msA} permet de cibler, à l'aide d'un identifiant \gls{cts}, le manuscrit \texttt{msA} du texte \texttt{tlg0012.tgl001} du corpus \texttt{greekLit}\footcite{smith_four_2012}. L'intérêt de ce système de pointeurs vers un texte est qu'il peut être adapté au Web, en précédent l'identifiant ci-dessus de l'\gls{url} d'une \api{} supportant le standard \gls{cts}. Il est donc possible de cibler précisément et de récupérer un texte depuis un dépôt particulier. L'intérêt de ce système est également qu'il est généralisable à d'autres corpus; le standard a donc été adapté par plusieurs \api{}, qui ont dû définir leurs propres implémentations de ce standard: là où le standard est implémenté, il est possible d'accéder à l'aide d'une sémantique unique à n'importe quel(s) texte(s). Parmi ces implémentations peut être cité \textit{CapiTainS}, développée pour la \textit{Perseus Digital Library} et l'\textit{Open Philology Project}\footcite{almas_continuous_2018}. \gls{cts} est donc intéressant d'un point de vue de l'ingénierie, puisqu'il permet la convergence des méthodes de partage et de diffusion du texte. Le standard est également intéressant d'un point de vue de la représentation du texte, puisqu'il permet de représenter un texte comme étant un graphe de citations et de références (une citation correspondant à une \gls{uri} reliée à une autre par un prédicat). Ce système de représentation permet donc de s'éloigner de la structure hiérarchique des éditions numériques en \tei{}, une représentation critiquée depuis ses débuts parce qu'elle impose un ordre hiérarchique unique à un texte, pourtant irréductible à une seule interprétation\footcite{renear_refining_1996}.

Le standard \gls{cts} n'est cependant pas parfait, et plusieurs critiques peuvent lui être faites. D'un point de vue de son développement, c'est un standard qui a été développé dans une certaine communauté de pratique, et qui n'est donc pas adaptable à tous les textes; ensuite, c'est un format qui a été développé pour répondre aux besoins de chercheur.euse.s, et qui ne suit donc pas les meilleures pratiques en termes de conception d'\api{}. Par exemple, il ne définit pas de formats de données à utiliser pour la réponse à renvoyer à l'utilisateur.ice\footcite[p. 2]{almas_distributed_2021}. La \tei{} n'est donc pas requise, peut-être de la critique faite par Smith et Blackwell des représentations hiérarchiques du texte. Si cela peut avoir un intérêt de ne pas vouloir \enquote{enfermer} le texte dans une hiérarchie qui lui est étrangère, ne pas utiliser la \tei{} pour une édition nativement numérique aujourd'hui est un choix pour le moins surprenant: ce standard dispose d'une très grande communauté d'utilisateur.ice.s, et est au cœur des humanités numériques centrées sur le texte. Le fait de ne pas imposer de format unique amène à beaucoup de variété dans les implémentations, ce qui s'oppose à un objectif de convergence des initiatives et ne garantit pas l'interopérabilité technique entre les \api{}. De fait, les implémentations de \gls{cts} varient beaucoup, comme le montre l'exemple de \textit{CapiTainS}, qui lui rend obligatoire l'utilisation du format \xml{} dans les réponses. C'est pourquoi un nouveau standard a été développé: le \gls{dts}. Alors que le \gls{cts} existe depuis une décennie, la première version publique du \gls{cts} a été publiée en 2018. Elle est basée sur le même principe que le standard précédent: une sémantique standardisée permet à une \gls{uri} de représenter un ou plusieurs (extraits) de texte. Plusieurs ajouts ont été faits à son prédécesseur. Le plus notable est l'obligation d'utiliser le \xmltei{}\footcite[p. 3]{almas_distributed_2021}, ce qui garantit l'interopérabilité des ressources distribuées. Le standard cherche également à intégrer les meilleures pratiques en matière de développement Web, en utilisant des formats sémantiques (comme le \texttt{JSON-LD}) et en encourageant le développement d'\api{} RESTful. Ce standard est également considérablement plus complexe que le \gls{cts} puisque l'\api{} peut offrir plusieurs points d'accès aux texte; ces points d'accès correspondent à différents niveaux de la collection (allant de la collection dans son ensemble au document). Bien que récent, le format a été implémenté par plusieurs projets, dont \textit{TEI Publisher}, une application en ligne visant à publier des données de recherche en \tei{}.

Ces deux standards sont intéressants, mais ne sont pas adaptés à \textit{KatAPI}. D'abord, leur implémentation complexifie considérablement la conception d'une \api{}, et son utilisation est peut-être plus adaptée à des initiatives faisant converger plusieurs projets. Mais le principal problème posé par les trois standards présentés ici est qu'ils sont tous développés pour partager des textes réels, qui ont une existence \enquote{en dehors de l'API}. Or, \textit{KatAPI} n'est pas seulement censée partager des textes issus du projet (c'est-à-dire, des catalogues ou des extraits de ceux-ci). Elle doit tout aussi bien partager des données de recherche issues du projet et construire des extraits du corpus en fonction des requêtes des utilisateur.ice.s. Cette \api{} repose donc, comme nous le verrons, sur la création de documents \textit{ex-nihilo} à partir de l'agrégation et de la transformation d'autres documents. Les critères bibliographiques servant à situer texte ou extrait dans une collection ne sont donc pas entièrement pertinents ici. L'\api{} doit fonctionner comme un moteur de recherche plutôt que comme un catalogue dans lequel il est possible de sélectionner une ou plusieurs ressources. Cependant, les standards \gls{cts} et \gls{dts} présentent des bonnes pratiques, et de nombreux enseignements sont à en tirer. D'abord, il est nécessaire de proposer une réponse en \xmltei{}, puisque ce standard de fait peut permettre de faire converger des données issues de différents projets. De \gls{cts} ressort l'intérêt de proposer plusieurs points d'accès au corpus, qui correspondent à différentes échelles dans celui-ci. Il n'existe pas une seule voie d'accès pour un texte, et c'est pourquoi ce principe sera suivi pour \textit{KatAPI}. De \gls{cts} et \gls{dts}, il faut également retenir l'utilisation de l'\gls{url} comme d'un pointeur, à la sémantique clairement définie, vers les ressources pertinentes (un principe déjà énoncé dans le protocole HTTP). Enfin, des trois standards présentés ici, il faut retenir le principe de la \textit{separation of concerns} (\enquote{séparation des préoccupations}). Ce principe central du développement applicatif est très bien exemplifié dans le fonctionnement d'\gls{oaipmh}: la base de donnée est distincte de l'entrepôt \gls{oaipmh} qui est lui-même distinct de la partie de l'\api{} chargée de recevoir des requêtes et de transmettre des réponses au client. Ce principe permet de minimiser l'impact d'un processus sur un autre et de réduire les relations entre les parties d'un programme à un strict minimum. C'est un concept qui a été suivi dans l'architecture de \textit{KatAPI}, où la réception et l'analyse des requêtes, la récupération des données, la construction des réponses et l'envoi de celle-ci à l'utilisateur.ice sont distinctes.

\section{Pour qui sont ces API? Qu'est-ce qui est demandé d'un tel outil?}
\sectionmark{Pour qui sont ces API?}
Cette dernière question n'est pas anodine. Il semblerait en effet que relativement peu d'\api{} soient développées dans des contextes d'humanités numériques; celles qui sont développées sont plutôt le fait de grandes institutions -- comme le projet \textit{Europeana}, ou la Bibliothèque nationale de France -- et de plateformes partagées qui adoptent le standard \gls{oaipmh}. Il existe également de nombreux services nécessitant l'utilisation d'\api{}, comme les serveurs IIIF permettant le partage d'image, et les serveurs \gls{dts} qui commencent à se développer. La conception d'\api{} semple être le fait d'infrastructures qui disposent de grands volumes de données et de ressources permettant de planifier et d'implémenter de tels outils sur le long terme. 

Une étude réalisée dans le cadre du projet \textit{Europeana} aide à situer le statut des \api{} dans les humanités numériques. Cette étude offre un point de vue intéressant, puisqu'elle s'appuie sur des entretierequêtens avec des chercheur.euse.s issue.e.s des humanités numériques et des humanités s'appuyant sur des méthodes quantitatives. Cette étude arrive à un constat pessimiste: les chercheur.euse.s ne sont pas des utilisateur.ice.s d'\api{}\footcite[p. 288]{edmond_apis_2015}. Même lorsque leurs recherches s'appuient sur le traitement de données, voire sur l'usage de méthodes computationnelles (traitement statistique à l'aide de \py{} ou \texttt{R}), ces personnes ont tendance à récupérer leurs données manuellement; ce qui leur importe, c'est les données, et non la manière d'y accéder\footcite[p. 290]{edmond_apis_2015}. Les \api{} sont, à l'inverse, beaucoup plus utilisées par des ingénieur.e.s et des personnes ayant eu une formation technique. Au delà de ce constat, l'étude propose des réflexions intéressantes sur le statut des \api{} dans les humanités en général et numériques en particulier. Trois critères sont identifiés pour la décision d'utiliser une source de données en recherche\footcite[p. 292-294]{edmond_apis_2015}:

\begin{itemize}
	\item Les données. Le critère de choix principal est la qualité et la complétude des données et des métadonnées.
	\item L'expertise technique nécessaire. Ce critère est relativement logique: un.e chercheur.euse n'utilisera une \api{} que si il ou elle a le moyen de le faire. Un problème ici est la méconnaissance des \api{} par les chercheur.euse.s, qui peuvent ne même pas connaître l'existence de tels outils. Cependant, l'étude remarque que, une fois qu'ils ont connaissance de telles sources, les chercheur.euse.s n'hésitent pas à se former à l'utilisation d'\api{}.
	\item Les environnements sociaux et techniques des chercheur.euse.s. Le critère précédent décrit des capacités réelles, alors que celui-ci traite de la perception. Plus un.e chercheur.euse perçoit que des outils techniques sont difficiles d'accès, moins il ou elle est susceptible de les utiliser. 
\end{itemize}

Pourquoi, alors, développer une \api{}? Au vu du volume du corpus, il peut être intéressant d'y avoir accès de façon automatisée. Avant le développement de cette \api{}, la seule manière d'accéder à des données brutes était de les télécharger sur les dépôts GitHub du projet. Dans ce cas, il est uniquement possible de récupérer un fichier complet, c'est-à-dire un catalogue entier ou un jeu de données portant sur l'ensemble du corpus. La seule manière d'accéder à des données sélectionnées et filtrer en fonction de ses besoins est de passer par l'application Web \enquote{pour huamin.e.s}, mais celle-ci ne permet pas de télécharger les données brutes. Au sein du panorama d'outils développés pour le projet, les méthodes de diffusion de données manquaient. C'est pourquoi une \api{} a été développée. Plus largement, les \api{} peuvent être particulièrement utiles pour un projet de recherche et pour l'application des principes \gls{fair} en humanités numériques. Une \api{} diminue, sur le long terme, le travail nécessaire pour diffuser des données. Dans le cas d'une \api{} \enquote{réactive}, qui construit des documents sur mesure, elle permet également d'explorer des sous-catégories, ou des sections du corpus. Une telle \api{} peut permettre la création de nouveaux jeux de données à la demande, ce qui est d'un intérêt certain.

L'étude d'Edmond et Garnett ne doit pas être prise avec pessimisme, indiquant que l'outil que l'on développe ne sera jamais utilisé. Au contraire, les critères sociaux-techniques qu'elles mettent en avant derrière l'utilisation d'une \api{} permettent de mieux adapter l'outil développé aux besoins. Il est nécessaire, lorsque cela est possible, de développer un outil qui diminue la distance perçue par les chercheur.euse.s. Pour cela il faut documenter l'application, de façon claire et, lorsque cela est possible, concise. Ensuite, il faut chercher à montrer que l'utilisation d'une \api{} n'est pas très compliquée: il peut être intéressant de concevoir des tutoriels, ou comme cela a été fait pour \textit{KatAPI}, des méthodes pour tester l'\api{} en temps réel. Depuis la page de documentation, il est possible de composer un \gls{dictionnaire} contenant les paramètres pour lancer une requête. Une fois la réponse reçue, le résultat s'affiche sur la page. De cette étude, il faut également retenir que une \api{} ne sera utilisée que si elle offre l'accès à des données de qualité. Cela va dans le sens des principes \gls{fair}: pour partager des données, celles-ci doivent être documentées et éditorialisées pour qu'un.e chercheur.euse sache quelles données seront reçues et envisage des manières de les utiliser.

Une autre étude\footcite{corral_towards_2014}, menée sur des \api{} généralistes, permet également de mieux comprendre le terrain pour de tels outils. Cette étude est basée sur l'analyse statistique des réponses obtenues obtenues pour 10955 \textit{Buisness APIs}, terme qui recoupe des applications développées par des entreprises (comme l'API de \textit{Twitter}), à but commercial (comme l'API de \textit{PayPal}), mais aussi des \api{} créées à but non-lucratifs (comme celle de \textit{Wikipedia}). L'étude date d'il y a quelques années, et il est donc possible que les tendances de design d'\api{} aient évoluées depuis. Les statistiques coincident cependant avec mon expérience de ces outils. Les résultats obtenus permettent de mieux comprendre quelles sont les tendances actuelles en terme de design d'\api{}. Les deux formats de réponse dominants sont le \json{} et le \xml{}: 81,08\% des applications proposent l'un ou l'autre format. Seules 21,37\% utilisent les deux formats, ce qui est le cas de \textit{KatAPI}. Un autre fait intéressant est que une immense majorité d'\api{} sont \textit{RESTlike}\footcite[p. 3]{corral_towards_2014}. Contrairement aux API \textit{RESTful}, les API \textit{RESTlike} sont inspirées par les principes \gls{rest} sans nécessairement les appliquer totalement. Ce terme s'est développé du fait de l'implémentation très inégale du standard. Le problème est que le terme \textit{RESTlike} est nécessairement imprécis; il est donc difficile de tirer une conclusion de cette statistique: dans une large mesure, les principes \gls{rest} ont servi au développement de \textit{KatAPI}. Quoi qu'il en soit, \textit{KatAPI} semble s'inscrire, par les formats utilisés et les principes architecturaux suivis, dans le paysage actuel des \api{}.

Les standards et études présentés ici permettent de mieux cerner le statut des \api{} centrées sur le texte en humanités numériques; elles permettent également d'identifier des tendances dans le desgin d'\api{} ainsi que les besoins des utilisateur.ice.s. En ayant cette compréhension du paysage technique pour ces applications, il est possible de définir clairement le périmètre de l'\api{} et la manière dont l'interaction client-serveur doit s'organiser, dans la sémantique des requêtes autant que dans les réponses obtenues.

\chapter{Définir un périmètre: que partager, et comment partager?}
\chaptermark{Définir un périmètre}
Après avoir présenté le paysage des \api{} en général et le statut de ces outils dans les humanités numériques en particulier, ce chapitre décrit \textit{KatAPI} du point de vue de l'utilisateur.ice: quelles données peuvent être obtenues via l'\api{}, quels paramètres de recherche sont autorisés et quels sont les formats de données retournés par l'application. C'est donc les principes de la communication client-serveur de \textit{KatAPI} qui sont ici présentés.

\section{Grands principes pour l'architecture de l'\api{}}
Pour plus de clarté, ici sont présentés de façon concise l'ensemble des principes auxquels l'application doit se conformer; ceux-ci forment une sorte de cahier des charges pour son implémentation technique.

\begin{itemize}
	\item L'application supporte uniquement la méthode \gls{http} \texttt{GET}: il est uniquement possible de demander des données à l'application, et non d'ajouter des données à une base de données, par exemple.
	\item L'application supporte deux formats de réponse: \json{} et \xmltei{}. Le format par défaut est le \json{}, pour sa légèreté et sa facilité de manipulation. Dans les deux cas, la structure des réponses est la même: un en-tête qui décrive le contexte de la réponse (à ne pas confondre avec les en-têtes \gls{http}) et un corps, qui contient les données récupérées.
	\item Trois niveaux d'accès aux données sont possibles. Il est possible de faire une requête pour un catalogue entier; des statistiques sur un ou plusieurs catalogues; une ou plusieurs entrées de catalogues.
	\item L'application suit le principe de séparation des préoccupations. L'interaction avec le client, le traitement des requêtes et la base de données sont des parties distinctes qui ne communiquent que lorsque cela est nécessaire.
	\item L'\api{} suit les principes \gls{rest} lorsque cela est possible. Elle est sans état et présente une interface uniforme. Cela veut dire que, pour les trois niveaux d'accès aux données, trois modèles de données seulement existent et sont adaptés en \json{} et \xmltei{}.
	\item L'application a un traitement strict des requêtes. Une requête n'est pas traitée si elle contient des paramètres non-autorisés (qui ne font pas partie de la sémantique définie pour l'interaction client-serveur), ou des valeurs associées à ces paramètres qui ne sont pas autorisées.
	\item L'application envoie des réponses précises et auto-descriptives, même en cas d'erreur. Plusieurs statuts \gls{http} sont définis pour différents cas de figures; si erreur il y a, un message d'erreur complet et décrivant le contexte et les raisons de l'erreur est renvoyé par l'\api{}. Cette erreur constitue un document \json{} ou \xmltei{} valide.
\end{itemize}

\section{Quelles données partager?}
À différentes étapes, une grande variété de données ont été produites; de plus, différentes manières d'accéder aux données ont été constituées par le projet. Par exemple, un système de réconciliation des différentes entrées de catalogue permet d'identifier lorsqu'un manuscrit est vendu plusieurs fois, et donc présent dans différents catalogues. Cela permet de regrouper ensemble différentes occurrences d'un même manuscrit. Ce type de données pourrait être partagé, de même que les données extraites de \sparql{} et présentées dans la partie précédente. Cependant, la mise à disposition de différents types de données est difficile tout en se conformant au principe d'uniformité de l'interface du \gls{rest}. En effet, chaque source de données a sa propre structure. Il donc est nécessaire, pour chaque source de données, de définir une représentation en \json{} et en \tei{}. Pour se conformer à l'objectif originel du projet \mssktb{} (étudier des catalogues en vente), il a été choisi de ne diffuser que des données issues des catalogues à travers l'\api{}. Cela élimine donc les données issues de \sparql{}. Pour ne se conserver qu'une seule représentation par type de données, il a été choisi de ne pas diffuser non plus de données sur les manuscrits \enquote{réconciliés}, puisque cela amènerait à avoir deux modèles de données pour les manuscrits, selon qu'ils aient été réconciliés ou non. De plus, ce processus de réconciliation prend quelques secondes à s'exécuter, ce augmente le temps de réponse de l'\api{} et peut devenir problématique si de nombreuses requêtes sont reçues en même temps pas l'application.

Au final, trois niveaux d'accès aux corpus ont été définis. Ceux-ci correspondent à différents degrés de granularité dans le corpus. Chacun de ces formats, enfin, a un modèle de données qui lui est propre. Celui-ci est transposé à la fois en \xmltei{} et en \json{}. 

\begin{itemize}
	\item Premier niveau: catalogue complet (\texttt{cat\_full}): l'intégralité des données contenues dans un catalogue peut être requêtée. Dans ce cas, il n'est possible que de requêter un catalogue à la fois. Celui-ci doit être clairement identifié à l'aide de son identifiant unique (l'\texttt{@xml:id}). Il est renvoyé dans son intégralité au format \xml{} uniquement: la traduction d'un fichier \xmltei{} complet en \json{} est complexe; de plus, si un.e utilisateur.ice demande un catalogue de façon aussi ciblée, alors il ou elle souhaitera probablement un format plus complexe que le \json{} et pourra tirer parti du balisage sémantique permise par la \tei{}.
	\item Deuxième niveau: statistiques sur une collection de catalogues (\texttt{cat\_stat}): des données statistiques sont retournées pour un ou plusieurs catalogues (prix moyen et médian des items, variance des prix au sein du catalogue, nombre d'items en vente...). En utilisant d'autres paramètres de recherche, il est possible de cibler précisément un sous-ensemble de catalogues, comme ceux issus de la \textit{Revue des autographes}, ou ceux publiés dans une certaine tranche de dates. Ce degré de granularité permet donc de produire des sous-ensemble pour des études statistiques et thématiques ciblées.
	\item Troisième niveau: au niveau de l'entrée (\texttt{itm}). Ce degré permet d'accéder à une ou plusieurs entrées de catalogues, et donc de récupérer l'ensemble des informations contenues dans les catalogues pour ces entrées. Il est possible de cibler des entrées par nom auteur.ice, date d'écriture, date de vente ou par identifiant \texttt{@xml:id}, ce qui permet de ne retourner qu'un identifiant. Ce degré de granularité permet donc de constituer des jeux de données restreints, avec par exemple tous les manuscrits écrits par un.e auteur.ice à une certaine période.
\end{itemize}

Chacun de ces degrés d'accès aux données correspond à une source de données différente. Le premier niveau (\texttt{cat\_full}) correspond à un document \tei{} représentant un catalogue dans son intégralité. Ce format permet donc l'accès aux sources directes du projet. Le deuxième niveau (\texttt{cat\_stat}) donne l'accès à un \json{} produit à partir d'une analyse statistique de tous les catalogues. Les entrées pertinentes de ce \json{} sont traduites en \xmltei{} si c'est le format de requête qui est demandée par l'utilisateur.ice. Enfin, le niveau \texttt{itm} correspond à deux sources de données: la première, c'est les catalogues eux-mêmes (au niveau de l'entrée, et non du catalogue complet); la deuxième, c'est une représentation en \json{} des entrées de catalogues. Pour accélérer le fonctionnement de l'\api{} lorsque la requête est faite au niveau de l'item, les données en \json{} sont d'abord lues avant, si besoin, d'utiliser la \tei{}. Les trois degrés de granularité des données sont donc centraux à l'architecture de l'\api{}: ils définissent trois bases de données à utiliser; ils déterminent aussi trois représentation de données différentes (c'est-à-dire, trois structures pour les réponses de l'\api{}). Grâce au principe de séparation des préoccupations, il est possible de rendre plus tard d'autres données accessibles et de permettre donc la diffusion de données depuis de nouvelles sources et la construction de nouvelles représentations. Les degrés de granularité déjà définis ne seront pas transformés par l'ajout d'autres degrés de granularité pour l'accès au corpus. Puisque les données et leur représentation sont distinctes, il est également possible de modifier la structure des sources de données (la structure des catalogues, par exemple) sans que le format de sortie ne soit affecté. Il suffit pour ce faire de faire en sorte que la représentation des données soit la même malgré le changement de la source de données.

Couplés aux autres paramètres de recherche, ces trois degrés d'accès aux données permettent de construire des sous-ensembles du corpus de catalogues avec un grand degré de précision.

\section{Codifier l'accès aux données: présentation des paramètres de recherche possibles}
\sectionmark{Codifier l'accès aux données}
Ici sont présentés les paramètres de recherche qui peuvent être utilisés pour récupérer des données, et comment ils permettent de filtrer ce qui est retourné par l'\api{}.

\section{Comment partager les données? Principes suivis pour le partage d'informations, formats et structure des réponses de l'API}
\sectionmark{Comment partager les données}
Cette section décrit les formats de réponse de l'\api{}, en \json{} et \xmltei{}, pour les différents paramètres de requête définis.

comment le header de la réponse permet de contenir des métadonnées tant voulues par le principe fair.

\chapter{Implémentation et fonctionnement technique de \textit{KatAPI}}
\chaptermark{Implémentation et fonctionnement technique}
Ce chapitre décrit le fonctionnement de l'\api{} côté serveur: comment les données sont reçues, la manière dont elles sont traitées et comment les réponses sont construites (notamment la création automatisée de documents \xmltei{}). Le système de gestion des erreurs est également présenté.

\section{Présentation générale}
Ici est présenté, schéma à l'appui, le fonctionnement technique de l'\api{} et la chaîne de traitement depuis la réception des requêtes jusqu'à l'envoi d'une réponse.

\section{Gestion des erreurs}
L'\api{} étant une application devant interagir avec des utilisateur.ice.s et gérer leurs requêtes, il n'est pas pensable qu'elle \enquote{plante} ou ne renvoie pas d'erreur. Tout un système de gestion des erreurs a donc été défini. Ces erreurs peuvent être classées en deux catégoriés: côté client (dues à des entrées invalides des utilisateur.ice.s)  et côté serveur (erreurs inattendues qui empêchent l'exécution d'une requête). Si ces erreurs sont rencontrées, des réponses sont construites en \json{} ou \xmltei{} (selon le format demandé par l'utilisateur.ice.s). Celles-ci décrivent l'erreur et permettent donc aux utilisateur.ice.s de corriger les erreurs qui ont pu avoir lieu côté client.

\section{Garantir le bon fonctionnement de l'application}
De la même manière que les systèmes de gestion des erreurs garantissent que l'application continue à fonctionner même en cas d'erreur, les tests garantissent que l'\api{} soit fonctionnelle, même dans \enquote{des conditions extrêmes}. Les réponses, formats et données retournées sont donc testés. C'est ce protocole de test qui est présenté ici.