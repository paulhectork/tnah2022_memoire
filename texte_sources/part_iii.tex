%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%% TROISIEME PARTIE %%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\part{Rendre la recherche réutilisable et interopérable: \textit{KatAPI}, une API pour échanger des données structurées}

La problématique de cette partie est la suivante: comment rendre la recherche en humanités numériques réutilisable et encourager le partage de données entre projets de recherche? La réponse à cette question, au sein du projet \mssktb{} prend la forme d'une \api{}. Celle-ci diffuse des données source du projet, mais aussi des informations issues de la recherche et du traitement computationnel de celles-ci dans deux formats structurés: le \json{} et le \xmltei{}.

En guise d'introduction, il me semble important ici de faire un bref rappel des principes fondamentaux du développement applicatif et de l'architecture du Web. Certains de ces principes ont déjà été présentés, mais ce rappel permettra de rendre la suite de ce chapitre plus claire.

Le Web est une architecture de type client-serveur qui permet l'interaction de machines dans un réseau décentralisé. Cette architecture définit deux fonctions possibles pour une machine: client (qui envoie et récupère des données distantes) et serveur (qui contient une application permettant l'interaction avec le client, ainsi qu'une base de données). Dans le Web, l'architecture client-serveur repose sur un protocole technique qui pose les principes de l'interaction entre des machines: le \gls{http}. Selon ce principe, l'accès d'un client à une ressource stockée sur un serveur (une page Web, par exemple) se fait au travers d'un \gls{url}. Celui-ci sert à localiser la ressource. L'interaction est définie par des requêtes (du client au serveur) et par des réponses (du serveur au client). Six types de requêtes sont possibles, qui correspondent à autant d'actions: demander des données à un serveur, en supprimer, les mettre à jour... Requêtes et réponses ont la même structure: elles sont composées d'un en-tête \gls{http} (qui contient des métadonnées sur la requête ou la réponse) et d'un corps (qui contient la requête ou la réponse en elle-même; celui-ci peut être vide). Parmi les métadonnées contenues dans l'en-tête, deux sont importantes dans notre contexte (surtout pour les réponses du client au serveur): le statut et le type MIME. Un statut est un code à trois chiffres qui caractérise la réponse et le déroulement de l'interaction client-serveur. \enquote{200} indique que tout va bien, \enquote{404} que la ressource demandée n'existe pas (c'est-à-dire, que l'\gls{url} de la requête ne pointe pas vers une ressource existante). Le type MIME est une manière standardisée de définir le format d'une réponse: \enquote{\texttt{application/json}} lorsque la réponse est au format \json{}, \enquote{\texttt{application/xml}} lorsque du \xml{} est renvoyé.

Une \api{} est une application, c'est-à-dire un ensemble de fonctions rassemblées pour permettre l'interaction entre un client et un serveur. Souvent, et c'est le cas pour les applications du projet \mssktb{}, une application permet l'interaction avec une base de données, elle-aussi stockée sur le serveur. Par exemple, lorsque l'on accède à une page \textit{Wikipedia}, l'application reçoit une requête de la part d'un client; elle va chercher dans la base les données pertinentes, les structure sous la forme d'une page HTML et les renvoie à l'utilisateur.ice, qui verra la page s'afficher sur son écran. La principale différence entre une \api{} Web et une application (comme \textit{Wikipedia}) est que l'\api{} est \enquote{un site Web pour machines}. Elle ne contient pas d'interface graphique et les réponses renvoyées par l'\api{} sont des données dites \enquote{brutes}; celles-ci ont l'avantage d'être lisibles et manipulables par une machine. L'interaction avec une \api{} se fait en envoyant une requête à l'application avec un \gls{url} qui contient les paramètres de la requête et des valeurs associées à ces paramètres (quelles données demander, quel format de réponse utiliser...) et éventuellement un corps de requête qui contienne des données (ce qui n'est pas le cas lorsque la requête correspond à une demande de données). L'\gls{url} contient donc la sémantique de la requête, il correspond à une question posée à un serveur de façon structurée. L'intérêt d'une telle \api{} est que, pour peu que l'on sache interagir avec elle, il est possible de récupérer automatiquement des données structurées, prêtes à être utilisées. Pour télécharger un jeu de données, il n'y a pas besoin, par exemple, d'aller sur la bonne page Web, de cliquer sur un bouton \enquote{Télécharger} et d'enregistrer le fichier au bon endroit. Toutes ces opérations peuvent être faites automatiquement, comme cela a été fait pour plus de 80000 requêtes lors de l'interaction avec \wkd{} décrite précédemment. Cette perspective est particulièrement intéressante pour un projet de recherche, puisqu'elle peut permettre de récupérer automatiquement les jeux de données produits par un autre projet, ce qui encourage la réutilisation des données de la recherche. Pour des ingénieur.e.s des données, les \api{} facilitent grandement le travail de récupération automatisée d'informations: elles permettent de \enquote{se concentrer sur le quoi, et non sur le comment}\footnote{\textit{focus on the what, and not on the how}. Citation issue de \cite[p. 2]{murdock_inpho_2011}.}.

Souvent, un site Web peut être composé d'une version accessible pour des utilisateur.ice.s humain.e.s et pour des machines; c'est le cas dans le projet \ktb{}. L'application pour humain.e.s a déjà été développée; c'est la version pour les machines, son fonctionnement et son utilité pour permettre la réutilisation des données du projet qui est donc présentée dans cette partie.

\chapter{Standards de design et statut des API dans pour les humanités numériques centrées sur le texte}
\chaptermark{Standards de design et statut}
Il n'existe aucune norme communément acceptée pour la conception d'une \api{}: dans l'absolu, tant que celle-ci fonctionne, elle peut être considérée comme une \api{}. Cependant, des standards se sont développés afin de regrouper les différentes méthodes et de développer des bonnes pratiques de design. Deux types de standards sont ici présentés: les standards d'architecture et les standards d'interopérabilité. Un standard d'architecture ou de design, comme le \gls{rest}, définit comment concevoir l'interaction client-serveur dans une \api{} et proposent une manière de structurer les réponses du serveur. Il ne définit cependant pas quels paramètres de recherches sont autorisés, ni le corps d'une réponse doit être organisé. Il ne définit pas non plus précisément comment organiser une requête, c'est-à-dire quel \gls{url} construire pour accéder aux données. C'est le rôle des standards d'interopérabilité (\gls{oaipmh}, \gls{cts}, \gls{dts}). Ceux-ci définissent la sémantique des requêtes (c'est-à-dire les paramètres autorisés) et la manière de construire un \gls{url} pour accéder à certaines données. Ils permettent donc l'interopérabilité, puisqu'une même syntaxe peut être utilisée pour requêter différentes \api{}. Ni le \gls{rest}, ni les standards d'interopérabilité ne définissent l'implémentation d'une \api{}: les deux types de standards s'intéressent à l'interaction du client avec l'\api{}, ils ne définissent pas l'application en elle-même. Une application qui se conforme à un standard garantit simplement un certain type d'interaction client-serveur. En plus de ces deux standards qui sont ici présentés, les principes \gls{fair} sont également décrits: ceux-ci ne définissent ni implémentation, ni sémantique, mais sont simplement des principes généraux pour la manière dont des données doivent être partagées dans un contexte de science ouverte et réutilisable.

% Ici est présenté un état de l'art sur la conception d'\api{} dans un contexte d'humanités numériques. Sont présentés un standard de design pour la conception d'api (le REST), l'architecture API-DTS (équivalent du IIIF pour le texte). Si l'\api{} conçue ne se rattache pas à ces concepts, ceux-ci ont servi d'inspiration pour l'architecture de \textit{KatAPI}. Les principes FAIR (essentiels pour la recherche ouverte et interopérable) sont également présentés, ainsi que l'état de l'art pour le design d'\api{} dans un contexte d'humanités numériques. Il apparaît que de tels outils sont majoritairement conçus par des institutions (\textit{DataBnF}...) plutôt que par de simples projets de recherche.

\section{Que faire du FAIR? Le partage des données de la recherche}
Les principes \gls{fair}\footcite{boeckhout_fair_2018} sont essentiels aux problématiques de la science ouverte. Celle-ci encourage non seulement la diffusion de la recherche dans des formats traditionnels (articles, conférences...), mais aussi la diffusion de données brutes issues de la recherche scientifique. L'objectif, dans la diffusion de ces données brutes, est de rendre les données réutilisables, mais aussi de permettre la reproductibilité de la recherche, et donc la vérification des résultats obtenus. 

La problématique de la diffusion de données recherche brutes se retrouve bien sûr en humanités numériques. Dans le domaine de la reconnaissance optique de caractères, par exemple, se développe le partage de vérités de terrain. La reconnaissance de caractères est permise par l'entrainement d'un algorithme d'apprentissage machine sur des textes qui ont été transcrits manuellement; c'est ce couple texte numérisé/transcription qui constitue la vérité de terrain. Or la production de ces données demande beaucoup de temps ainsi que des compétences spécifiques pour des graphies difficiles à lire et des langues rares\footnote{Un exemple de ces corpus \enquote{difficiles} est le développement de la reconnaissance optique de caractères pour le Cham, langue parlée par une minorité originaire du Sud-Est de l'Asie. Celle-ci comprend environ 30000 locuteurs. Le projet travaille également à la reconnaissance du Cham ancien, qui est extrêmement méconnu (\cite{schweyer_analyse_2022}).}. Pour faciliter le développement de méthodes de reconnaissance optique de caractères se développent donc des initiatives pour faciliter le partage de vérités de terrains. Parmi ces initiatives se trouve le projet \textit{HTR United}\footcite{chague_sharing_2022}, qui offre un portail pour l'accès à et le dépôt de vérités de terrains. Celles-ci sont partagées avec des métadonnées précisant par exemple leur contexte de production, le domaine auquel appartient au corpus.

La diffusion de données de recherche est cependant une opération plus complexe qu'il ne pourrait y paraître; c'est pourquoi les principes \gls{fair} ont été édités en 2014\footcite[p. 931]{boeckhout_fair_2018}. Ils forment une base minimale de recommandations sur la manière de partager des données de recherche. Cette base minimale est composée de quatre principes\footcite[p. 932-933]{boeckhout_fair_2018}: 

\begin{itemize}
	\item \textit{Findability}: les jeux de données doivent être diffusés sur des dépôts publics; ils doivent être décrits avec suffisamment de métadonnées pour que leur périmètre et la manière dont ils ont été constitués soient clairement identifiables.
	\item \textit{Accessible}: les jeux de données doivent être accessibles librement et idéalement de façon manuelle aussi bien qu'automatique.
	\item \textit{Reusable}: les jeux de données doivent être réutilisables. Cela implique de définir un périmètre pour la réutilisation des données, notamment au travers de licences.
	\item \textit{Interoperable}: les jeux de données doivent être diffusés dans des formats structurés, compréhensible par des humain.e.s et, idéalement, manipulables par des machines.
\end{itemize}

Qu'en est-il de la relation entre ces principes et la conception d'\api{}? La diffusion automatisée par le biais d'applications semble aller main dans la main avec les principes \gls{fair}. Une \api{} permet de diffuser automatiquement des données brutes et structurées dans des formats interopérables. Cependant, une \api{} n'adhère pas par défaut aux principes \gls{fair}. Elle garantit l'accessibilité des données; pour qu'elles soient réutilisables, la conception d'\api{} doit être considérablement étoffée. Il faut en effet définir le contexte de production des données, ainsi que la licence dans laquelle elles sont diffusées. Il est donc nécessaire d'ajouter des métadonnées aux réponses de l'\api{} ou de trouver un moyen de documenter les conditions de réutilisation des données. La notion de \enquote{dépôt public} requis par les principes \gls{fair} pour partager des données change également de sens. L'\api{} sert pas à partager les données sur un autre dépôt qui agrège des jeux de données, elle sert à les diffuser à des utilisateur.ice.s. Une \api{} pour la recherche forme donc sa propre plateforme de diffusion des données. Enfin, il faut garantir que les données soient compréhensibles. Cet aspect des principes \gls{fair} n'est pas anodine dans la conception d'une \api{}. Non seulement celle-ci doit renvoyer des réponses structurées et valides; la sémantique des réponses doit également être explicitée. Cela veut dire que, soit dans l'\api{}, soit dans la documentation, le sens de chaque élément doit être précisé. La documentation est ici importante; mais l'utilisation de la \tei{} est également intéressante en vue de ce besoin de produire des données compréhensibles. Ce standard, en plus d'être très pratiqué dans les humanités numériques, est défini dans les \textit{TEI Guidelines}\footcite{tei_consortium_p5_2022} et dispose donc d'une documentation officielle. Au delà de ces principes abstraits, de véritables standards techniques peuvent servir d'inspiration dans le développement d'\api{} pour diffuser des données de recherche.

\section{Le REST: un modèle pour le design d'API}
Ici est présenté le standard REST, défini par Roy Fielding\footcite{fielding_architectural_2000}; ce standard architectural est considéré comme l'idéal à atteindre en matière de design d'\api{}. Il n'a cependant pas été suivi ici, en partie parce qu'il est mieux adapté à un projet de plus grande échelle, et en partie car il ne fonctionne pas de façon optimale avec le modèle de données défini, et notamment avec le choix de construire une \api{} renvoyant des réponses conformes à la \tei{}.

Le standard \gls{rest} (\enquote{État de transfert représentatif}) est un standard et un style pour la conception d'\api{} dans une architecture client-serveur. Il est aujourd'hui un standard de fait pour la conception de tels outils, et est considéré comme une bonne pratique dans l'architecture d'\api{}. Le standard \gls{rest} ne définit pas comment une \api{} doit être implémentée, mais définit la structure de l'interaction client-serveur. Historiquement, le développement de ce standard est fortement lié à l'établissement du protocole \gls{http}, puisque le concepteur du \gls{rest} est l'un des ingénieur.e.s à l'origine du protocole. Le \gls{rest} définit un ensemble de quatre contraintes supplémentaires à celles présentes dans le protocole \gls{http}\footcite[p. 94]{fielding_architectural_2000}. Une \api{} \gls{rest} doit répondre aux contraintes suivantes:

\begin{itemize}
	\item Être sans état\footcite[p. 78-79]{fielding_architectural_2000}. Cela signifie qu'une requête du client au serveur doit contenir l'ensemble des informations nécessaires au traitement de la requête. Le serveur ne peut accéder à un contexte ou à d'autres informations pour traiter la requête. Cela permet de rendre les requêtes plus faciles à interpréter, limite le risque d'erreurs et permet à l'\api{} de fonctionner à plus grande échelle, puisqu'elle n'a pas besoin d'utiliser de les ressources pour chercher des informations ailleurs que dans la requête.
	\item Présenter une interface uniforme\footcite[p. 81-82, 86-97]{fielding_architectural_2000}. C'est peut-être ce principe qui est définitoire du \gls{rest}: l'interface, c'est-à-dire la partie de l'\api{} qui est exposée au client, doit toujours être la même. Il y a donc un découplage entre la communication avec le client (réception des requêtes et envoi des réponse) et le traitement des requêtes, qui ne sont pas accessibles au client. Cette séparation permet de modifier la manière dont une requête est traitée sans devoir changer la sémantique et la structure de l'interaction avec le client. Ce principe implique d'autres contraintes:
	\begin{itemize}
		\item L'identification des ressources dans des requêtes: un client requête une \gls{uri} et le serveur lui renvoie une représentation de cette \gls{uri}. Dans le contexte du Web, cela veut dire qu'un \gls{url} doit nécessairement être fourni au moment de la requête et que celui-ci doit pointer vers les ressources à traiter.
		\item Les ressources sont communiquées sous la forme de représentations. Cela veut dire que les données envoyées au client peuvent être dans une structure ou un format différents de ceux de la base de données: l'\api{} doit traduire les données telles qu'elles sont dans la base en leur représentation.
		\item Les réponses \gls{http} doivent être auto-descriptives: les en-têtes et le corps de la requête doivent contenir assez de (méta-)données pour pouvoir être manipulées par le client sans avoir besoin d'informations extérieures.
		\item Utilisation de l'hypermédia comme moteur de navigation. Comme sur un site Web normal, des hyperliens doivent permettre de naviguer d'une ressource à l'autre et doivent être accessibles directement depuis l'\api{}.
	\end{itemize}
	\item Autoriser la mise en cache explicite\footcite[p. 79-81]{fielding_architectural_2000}. Une réponse du serveur au client doit explicitement indiquer si les données contenues dans une réponse peuvent être mises en cache (c'est-à-dire, stockées dans la mémoire pour y être accédées plus tard). La possibilité de cacher les données peut potentiellement diminuer le nombre de requêtes envoyées au serveur.
	\item Présenter une architecture en couches\footcite[p. 82-84]{fielding_architectural_2000}. Une application peut être entièrement stockée sur un serveur, ou fonctionner par l'interaction de différents serveurs. Dans ce cas, un client peut être connectés à différents serveurs, mais ne doit pas savoir s'il se trouve sur un serveur intermédiaire ou un serveur final. Les serveurs intermédiaires peuvent modifier les messages à renvoyer au client, répartir les charges sur différents serveurs ou établir des politiques de sécurité.
	\item Diffuser du code à la demande (optionnel)\footcite[p. 84-85]{fielding_architectural_2000}.
\end{itemize}

Les concepts centraux dans ce système architectural -- du moins, pour une petite \api{} comme celle de \ktb{} sont le fait d'être sans état et l'uniformité de l'interface. Ces deux concepts signifient que les requêtes comme les réponses doivent être entièrement auto-descriptives. Les autres principes sont mieux adaptés à des \api{} à plus grande échelle: la mise en cache explicite suppose que la même requête puisse être envoyée en série par un client à un serveur; pour une \gls{api} d'un projet de recherche, il est plus probable qu'une requête soit faite une unique fois pour récupérer des données. L'utilisation d'une architecture en couche n'est pas du ressort de \textit{KatAPI}, puisque l'intégralité de l'\api{} est présente sur un seul serveur. Enfin, la diffusion de code exécutable n'est pas non plus adaptée aux données qui sont requêtées et diffusées via l'\api{}.

La mise au point d'une architecture sans état demande de mettre au point une sémantique pour les requêtes qui soit auto-descriptive, c'est-à-dire qui décrive l'intégralité de la requête. L'uniformité de l'interface, d'un point de vue de développement applicatif, est une problématique plus complexe. D'abord, elle demande d'établir des modèles de données uniformes pour le corps des réponses \gls{http}. Cela veut dire que, pour chaque format de réponse autorisé et point d'accès aux données possible, les réponses doivent être contenues dans une structure qui est toujours la même. Ensuite, les en-têtes doivent être constitués pour décrire adéquatement la réponse. Cela passe par la définition d'un statut \gls{http} et d'un type MIME à chaque réponse. Ainsi, une machine peut savoir quel format de réponse est obtenu, et comment la requête s'est déroulée. Cependant, l'utilisation d'hyperliens comme moteur de l'application n'a pas été implémentée: les réponses ne contiennent pas d'hyperliens qui permettent de naviguer automatiquement vers d'autres ressources ou actions. L'ensemble des ressources accessibles et la manière d'y accéder sont au contraire définies de façon centralisée dans la documentation de l'\api{}, qui n'est pas lisible par une machine. Enfin, du point de vue de l'implémentation, la communication client-serveur est indépendante du traitement des requêtes et de l'interaction avec les bases de données.

Par conséquent, les choix techniques mis en place font de l'\api{} une application \textit{RESTlike} (c'est-à-dire, qui se conforme à un certain degré aux principes REST), voire \textit{RESTful} (qui se conforme entièrement aux principes REST). \textit{KatAPI} suit le standard REST là où il est pertinent pour les données transmises (ce qui exclut la condition de transmission de code et la clause de mise en cache). L'\api{} suit également les principes \gls{rest} là où il est de son ressort de les suivre (ce qui exclut une architecture en couches, puisque l'application est distincte de son installation sur un serveur). Suivre ces principes et s'en inspirer permet de concevoir une application au comportement uniforme, et où le client n'a pas à vérifier les réponses obtenues, puisqu'elles seront toujours les mêmes et qu'elles contiendront toutes les informations nécessaires à leur traitement (format de réponse, statut HTTP...).

\section{OAI-PMH, CTS et DTS: quels standards pour le partage du texte en humanités numériques?}
\sectionmark{OAI-PMH, CTS et DTS}
Les principes REST, présentés ci-dessus, concernent l'architecture et le design d'une \api{}; cependant, ils ne s'attaquent pas à une autre partie du problème: l'interopérabilité des \api{}. Chacune de ces applications définit sa propre sémantique pour les requêtes et autorise certains formats de réponse. Cela conduit à un problème pour les programmes consommateurs d'\api{}: l'interaction avec deux \api{} demande la construction de requêtes différentes, et demande donc d'apprendre à utiliser différentes \api{}. Lorsque celles-ci sont complexes, apprendre à utiliser une \api{} n'a rien d'anodin, et se servir de différentes \api{} devient complexe. De plus, l'absence d'interopérabilité signifie qu'il est difficile, voire impossible, de travailler de la même manière avec les données issues d'\api{} différentes. Si l'une renvoie du \json{} mais l'autre du \xml{}, par exemple, les résultats issus des deux \api{} doivent être utilisés différemment. Cela complexifie la convergence des données de la recherche et limite l'interopérabilité de ces données, qui est pourtant l'un des principes \gls{fair}\footcite[p. 932-933]{boeckhout_fair_2018}. Pour faire face à ce problème, des standards d'interopérabilité ont été développés. Ceux-ci définissent à minima une sémantique unique qui peut être implémentée par plusieurs \api{}. Parfois, ils définissent également des formats de réponse. Le plus célèbre de ces standards, dans les humanités, est le protocole IIIF, qui permet d'interagir avec une image (en lui ajoutant une couche d'annotations, par exemple). Dans les humanités centrées sur le texte, les standards d'\api{} sont plus diversifiés. Trois sont présentés ici: l'\gls{oaipmh}, le \gls{cts} et le \gls{dts}. Aucun d'entre eux n'a été adopté dans la conception de l'\api{} \ktb{}, mais ils sont tous riches de leçons dans le développement d'une telle application

\subsection{OAI-PMH: un premier standard à succès}
L'\gls{oaipmh} vient du monde des archives et des bibliothèques. Les bibliothèques ne conservant pas des objets uniques, mais des documents produits en série, elles sont pionnières dans le développement de méthodes computationnelles pour le partage des données\footcite[p. 2-3]{prime-claverie_defi_2017}. Aussi ce standard a-t-il connu une adoption inégalée, puisqu'il est aujourd'hui le standard d'interopérabilité le plus utilisé dans les bibliothèques\footcite[p. 5]{prime-claverie_defi_2017}; il est y compris utilisé par les plateformes en ligne HAL, OpenEditions ou encore CAIRN. Ce standard vise à permettre l'interopérabilité sémantique (uniformiser la sémantique des requêtes et des réponses) et technique (uniformiser les formats de réponse)\footcite[p. 6-14]{prime-claverie_defi_2017}. Il ne vise cependant pas à partager des documents, mais seulement leurs métadonnées (en d'autres termes, l'\gls{oaipmh} ne permet pas de partager un document, mais seulement sa notice bibliographique); il ne permet pas non plus de partager des données sur un document, mais sur une collection entière. Les réponses de l'\gls{oaipmh} sont constituées de collections de notices encodées en XML; l'interopérabilité sémantique des réponses est permise par l'utilisation du Dublin Core, un format considéré comme un plancher pour le partage de données bibliographiques. L'interopérabilité technique, elle, repose sur un format de réponse en \xml{}\footcite[p. 4]{prime-claverie_defi_2017}. Comme le montrent Prime-Claverie et Mahé, cette interopérabilité n'empêche cependant pas une grande variété dans les implémentations: certaines utilisent des réponses en \xmltei{}, d'autres non; les structures des réponses varient elles-aussi, avec différents éléments Dublin Core associés à différentes données\footcite[p. 6-14]{prime-claverie_defi_2017}. D'un point de vue technique, le fonctionnement d'\gls{oaipmh} est intéressant: l'entrepôt \gls{oaipmh} est distinct de la base d'où il récupère les données. Cela veut dire que, lorsqu'une requête est reçue, l'\api{} la communique à l'entrepôt \gls{oaipmh} qui transforme les informations contenues dans la base de données. D'un point de vue d'ingénierie, cela veut dire que les parties de ce système (base de données -- entrepôt \gls{oaipmh} -- \api{}) sont distincts\footcite[p. 4]{prime-claverie_defi_2017}. Par conséquent, les données n'ont pas besoin d'être stockées dans des formats compatibles; des transformations dans une partie n'impliquent pas de devoir transformer les autres parties (sauf pour permettre l'interaction entre les différents éléments du système). Par exemple, une modification de la structure de la base de données ne demande pas de transformer toute l'\api{}, mais seulement la manière dont ces données sont transformées pour être compatibles avec le standard \gls{oaipmh}. 

Que retenir de cet exemple? Tout d'abord, que ce n'est pas parce qu'un standard existe qu'il sera implémenté uniformément. Une marge de manœuvre est toujours présente, ce qui peut amener à des résultats très différents. Bien sûr, cela va à l'encontre du principe d'interopérabilité et complexifie la convergence des ressources d'origine différente. Cependant, comme le rappellent Prime-Claverie et Mahé\footcite[p. 15-16]{prime-claverie_defi_2017}, ces variations ne sont pas nécessairement problématiques. Elles permettent aux différentes institutions qui l'implémentent de fournir des données adaptées à certaines communautés de pratique -- il va de soit qu'une archive et une bibliothèque sont deux institutions très différentes, et qu'elles ne peuvent représenter leurs documents de la même manière. L'implémentation technique de l'\gls{oaipmh} est également intéressante: elle sépare les données (dans une base de données) de leur représentation. Ce qui est communiqué au client, c'est cette représentation, compatible avec le protocole \gls{oaipmh}. Cette idée, qui rappelle les principes \gls{rest}, est mise en place d'autres standards présentés ici. D'un point de vue de développement, la séparation entre les différentes parties nécessaires au fonctionnement de cet \api{} facilitent également son maintient et l'ajout de nouvelles fonctionnalités, puisque le système ne doit pas être modifié lorsque c'est seulement un élément qui est affecté. Cependant, l'\gls{oaipmh} n'est pas adapté aux besoins de \ktb{}: ce standard ne permet pas d'échanger du texte, mais seulement des métadonnées. De par sa taille, il est également difficile à implémenter pour un projet de recherche.

\subsection{CTS, DTS: des méthodes de standardisation pour l'échange de texte}
Le \gls{cts} a été développé dans un contexte très différent de l'\gls{oaipmh}. Il est issu d'un projet de recherche à Harvard, le \textit{Homer Multitext} consacré à l'édition de l'\textit{Illiade} et de l'\textit{Odyssée} d'Homère. Le standard est donc pensé pour l'édition de textes canoniques antiques. Il naît d'un problème technique: comment faire coïncider la structure en arbre d'une édition numérique avec la structure citationnelle traditionnelle, où les citations font références à des pages. Aux origines du projet se trouve également l'idée qu'un texte existe à l'intérieur d'un système citationnel, où les textes fonctionnent par référence les uns aux autres\footcite{smith_four_2012}. Cette idée est particulièrement importante dans un projet d'édition critique, comme le \textit{Homer Multitext}, où les différents témoins des textes d'Homère doivent pouvoir être alignés et comparés. La \tei{} a développé ses propres systèmes de référence pour les éditions critiques, basés sur le concept d'arbres décisionnels (où chaque témoin peut être représenté par une feuille, et où les différentes feuilles viennent d'une branche commune)\footcite{tei_consortium_p5_2022}. Mais ce système ne permet pas de cibler efficacement un passage dans un texte, ni de faire référence à ce passage en dehors du document lui-même. Comment, dans ce cas, représenter des références dans une édition numérique? Comment rendre des parties de texte accessibles à l'extérieur d'un texte, dans une architecture client-serveur? La réponse proposée à l'initiative de Smith et Blackwell est le \gls{cts}. Ce système définit une sémantique permettant d'identifier un texte, un passage de texte ou même un ensemble de textes grâce à une \gls{uri}. Celle-ci cible de plus en plus précisément le passage voulu. Par exemple, \texttt{urn:ctsl:greekLit:tlg0012.tgl001.msA} permet de cibler, à l'aide d'un identifiant \gls{cts}, le manuscrit \texttt{msA} du texte \texttt{tlg0012.tgl001} du corpus \texttt{greekLit}\footcite{smith_four_2012}. L'intérêt de ce système de pointeurs vers un texte est qu'il peut être adapté au Web, en précédent l'identifiant ci-dessus de l'\gls{url} d'une \api{} supportant le standard \gls{cts}. Il est donc possible de cibler précisément et de récupérer un texte depuis un dépôt particulier. L'intérêt de ce système est également qu'il est généralisable à d'autres corpus; le standard a donc été adapté par plusieurs \api{}, qui ont dû définir leurs propres implémentations de ce standard: là où le standard est implémenté, il est possible d'accéder à l'aide d'une sémantique unique à n'importe quel(s) texte(s). Parmi ces implémentations peut être cité \textit{CapiTainS}, développée pour la \textit{Perseus Digital Library} et l'\textit{Open Philology Project}\footcite{almas_continuous_2018}. \gls{cts} est donc intéressant d'un point de vue de l'ingénierie, puisqu'il permet la convergence des méthodes de partage et de diffusion du texte. Le standard est également intéressant d'un point de vue de la représentation du texte, puisqu'il permet de représenter un texte comme étant un graphe de citations et de références (une citation correspondant à une \gls{uri} reliée à une autre par un prédicat). Ce système de représentation permet donc de s'éloigner de la structure hiérarchique des éditions numériques en \tei{}, une représentation critiquée depuis ses débuts parce qu'elle impose un ordre hiérarchique unique à un texte, pourtant irréductible à une seule interprétation\footcite{renear_refining_1996}.

Le standard \gls{cts} n'est cependant pas parfait, et plusieurs critiques peuvent lui être faites. D'un point de vue de son développement, c'est un standard qui a été développé dans une certaine communauté de pratique, et qui n'est donc pas adaptable à tous les textes; ensuite, c'est un format qui a été développé pour répondre aux besoins de chercheur.euse.s, et qui ne suit donc pas les meilleures pratiques en termes de conception d'\api{}. Par exemple, il ne définit pas de formats de données à utiliser pour la réponse à renvoyer à l'utilisateur.ice\footcite[p. 2]{almas_distributed_2021}. La \tei{} n'est donc pas requise, peut-être de la critique faite par Smith et Blackwell des représentations hiérarchiques du texte. Si cela peut avoir un intérêt de ne pas vouloir \enquote{enfermer} le texte dans une hiérarchie qui lui est étrangère, ne pas utiliser la \tei{} pour une édition nativement numérique aujourd'hui est un choix pour le moins surprenant: ce standard dispose d'une très grande communauté d'utilisateur.ice.s, et est au cœur des humanités numériques centrées sur le texte. Le fait de ne pas imposer de format unique amène à beaucoup de variété dans les implémentations, ce qui s'oppose à un objectif de convergence des initiatives et ne garantit pas l'interopérabilité technique entre les \api{}. De fait, les implémentations de \gls{cts} varient beaucoup, comme le montre l'exemple de \textit{CapiTainS}, qui lui rend obligatoire l'utilisation du format \xml{} dans les réponses. C'est pourquoi un nouveau standard a été développé: le \gls{dts}. Alors que le \gls{cts} existe depuis une décennie, la première version publique du \gls{cts} a été publiée en 2018. Elle est basée sur le même principe que le standard précédent: une sémantique standardisée permet à une \gls{uri} de représenter un ou plusieurs (extraits) de texte. Plusieurs ajouts ont été faits à son prédécesseur. Le plus notable est l'obligation d'utiliser le \xmltei{}\footcite[p. 3]{almas_distributed_2021}, ce qui garantit l'interopérabilité des ressources distribuées. Le standard cherche également à intégrer les meilleures pratiques en matière de développement Web, en utilisant des formats sémantiques (comme le \texttt{JSON-LD}) et en encourageant le développement d'\api{} RESTful. Ce standard est également considérablement plus complexe que le \gls{cts} puisque l'\api{} peut offrir plusieurs points d'accès aux texte; ces points d'accès correspondent à différents niveaux de la collection (allant de la collection dans son ensemble au document). Bien que récent, le format a été implémenté par plusieurs projets, dont \textit{TEI Publisher}, une application en ligne visant à publier des données de recherche en \tei{}.

Ces deux standards sont intéressants, mais ne sont pas adaptés à \textit{KatAPI}. D'abord, leur implémentation complexifie considérablement la conception d'une \api{}, et son utilisation est peut-être plus adaptée à des initiatives faisant converger plusieurs projets. Mais le principal problème posé par les trois standards présentés ici est qu'ils sont tous développés pour partager des textes réels, qui ont une existence \enquote{en dehors de l'API}. Or, \textit{KatAPI} n'est pas seulement censée partager des textes issus du projet (c'est-à-dire, des catalogues ou des extraits de ceux-ci). Elle doit tout aussi bien partager des données de recherche issues du projet et construire des extraits du corpus en fonction des requêtes des utilisateur.ice.s. Cette \api{} repose donc, comme nous le verrons, sur la création de documents \textit{ex-nihilo} à partir de l'agrégation et de la transformation d'autres documents. Les critères bibliographiques servant à situer texte ou extrait dans une collection ne sont donc pas entièrement pertinents ici. L'\api{} doit fonctionner comme un moteur de recherche plutôt que comme un catalogue dans lequel il est possible de sélectionner une ou plusieurs ressources. Cependant, les standards \gls{cts} et \gls{dts} présentent des bonnes pratiques, et de nombreux enseignements sont à en tirer. D'abord, il est nécessaire de proposer une réponse en \xmltei{}, puisque ce standard de fait peut permettre de faire converger des données issues de différents projets. De \gls{cts} ressort l'intérêt de proposer plusieurs points d'accès au corpus, qui correspondent à différentes échelles dans celui-ci. Il n'existe pas une seule voie d'accès pour un texte, et c'est pourquoi ce principe sera suivi pour \textit{KatAPI}. De \gls{cts} et \gls{dts}, il faut également retenir l'utilisation de l'\gls{url} comme d'un pointeur, à la sémantique clairement définie, vers les ressources pertinentes (un principe déjà énoncé dans le protocole HTTP). Enfin, des trois standards présentés ici, il faut retenir le principe de la \textit{separation of concerns} (\enquote{séparation des préoccupations}). Ce principe central du développement applicatif est très bien exemplifié dans le fonctionnement d'\gls{oaipmh}: la base de donnée est distincte de l'entrepôt \gls{oaipmh} qui est lui-même distinct de la partie de l'\api{} chargée de recevoir des requêtes et de transmettre des réponses au client. Ce principe permet de minimiser l'impact d'un processus sur un autre et de réduire les relations entre les parties d'un programme à un strict minimum. C'est un concept qui a été suivi dans l'architecture de \textit{KatAPI}, où la réception et l'analyse des requêtes, la récupération des données, la construction des réponses et l'envoi de celle-ci à l'utilisateur.ice sont distinctes.

\section{Pour qui sont ces API? Qu'est-ce qui est demandé d'un tel outil?}
\sectionmark{Pour qui sont ces API?}
Cette dernière question n'est pas anodine. Il semblerait en effet que relativement peu d'\api{} soient développées dans des contextes d'humanités numériques; celles qui sont développées sont plutôt le fait de grandes institutions -- comme le projet \textit{Europeana}, ou la Bibliothèque nationale de France -- et de plateformes partagées qui adoptent le standard \gls{oaipmh}. Il existe également de nombreux services nécessitant l'utilisation d'\api{}, comme les serveurs IIIF permettant le partage d'image, et les serveurs \gls{dts} qui commencent à se développer. La conception d'\api{} semple être le fait d'infrastructures qui disposent de grands volumes de données et de ressources permettant de planifier et d'implémenter de tels outils sur le long terme. 

Une étude réalisée dans le cadre du projet \textit{Europeana} aide à situer le statut des \api{} dans les humanités numériques. Cette étude offre un point de vue intéressant, puisqu'elle s'appuie sur des entretierequêtens avec des chercheur.euse.s issue.e.s des humanités numériques et des humanités s'appuyant sur des méthodes quantitatives. Cette étude arrive à un constat pessimiste: les chercheur.euse.s ne sont pas des utilisateur.ice.s d'\api{}\footcite[p. 288]{edmond_apis_2015}. Même lorsque leurs recherches s'appuient sur le traitement de données, voire sur l'usage de méthodes computationnelles (traitement statistique à l'aide de \py{} ou \texttt{R}), ces personnes ont tendance à récupérer leurs données manuellement; ce qui leur importe, c'est les données, et non la manière d'y accéder\footcite[p. 290]{edmond_apis_2015}. Les \api{} sont, à l'inverse, beaucoup plus utilisées par des ingénieur.e.s et des personnes ayant eu une formation technique. Au delà de ce constat, l'étude propose des réflexions intéressantes sur le statut des \api{} dans les humanités en général et numériques en particulier. Trois critères sont identifiés pour la décision d'utiliser une source de données en recherche\footcite[p. 292-294]{edmond_apis_2015}:

\begin{itemize}
	\item Les données. Le critère de choix principal est la qualité et la complétude des données et des métadonnées.
	\item L'expertise technique nécessaire. Ce critère est relativement logique: un.e chercheur.euse n'utilisera une \api{} que si il ou elle a le moyen de le faire. Un problème ici est la méconnaissance des \api{} par les chercheur.euse.s, qui peuvent ne même pas connaître l'existence de tels outils. Cependant, l'étude remarque que, une fois qu'ils ont connaissance de telles sources, les chercheur.euse.s n'hésitent pas à se former à l'utilisation d'\api{}.
	\item Les environnements sociaux et techniques des chercheur.euse.s. Le critère précédent décrit des capacités réelles, alors que celui-ci traite de la perception. Plus un.e chercheur.euse perçoit que des outils techniques sont difficiles d'accès, moins il ou elle est susceptible de les utiliser. 
\end{itemize}

Pourquoi, alors, développer une \api{}? Au vu du volume du corpus, il peut être intéressant d'y avoir accès de façon automatisée. Avant le développement de cette \api{}, la seule manière d'accéder à des données brutes était de les télécharger sur les dépôts GitHub du projet. Dans ce cas, il est uniquement possible de récupérer un fichier complet, c'est-à-dire un catalogue entier ou un jeu de données portant sur l'ensemble du corpus. La seule manière d'accéder à des données sélectionnées et filtrer en fonction de ses besoins est de passer par l'application Web \enquote{pour huamin.e.s}, mais celle-ci ne permet pas de télécharger les données brutes. Au sein du panorama d'outils développés pour le projet, les méthodes de diffusion de données manquaient. C'est pourquoi une \api{} a été développée. Plus largement, les \api{} peuvent être particulièrement utiles pour un projet de recherche et pour l'application des principes \gls{fair} en humanités numériques. Une \api{} diminue, sur le long terme, le travail nécessaire pour diffuser des données. Dans le cas d'une \api{} \enquote{réactive}, qui construit des documents sur mesure, elle permet également d'explorer des sous-catégories, ou des sections du corpus. Une telle \api{} peut permettre la création de nouveaux jeux de données à la demande, ce qui est d'un intérêt certain.

L'étude d'Edmond et Garnett ne doit pas être prise avec pessimisme, indiquant que l'outil que l'on développe ne sera jamais utilisé. Au contraire, les critères sociaux-techniques qu'elles mettent en avant derrière l'utilisation d'une \api{} permettent de mieux adapter l'outil développé aux besoins. Il est nécessaire, lorsque cela est possible, de développer un outil qui diminue la distance perçue par les chercheur.euse.s. Pour cela il faut documenter l'application, de façon claire et, lorsque cela est possible, concise. Ensuite, il faut chercher à montrer que l'utilisation d'une \api{} n'est pas très compliquée: il peut être intéressant de concevoir des tutoriels, ou comme cela a été fait pour \textit{KatAPI}, des méthodes pour tester l'\api{} en temps réel. Depuis la page de documentation, il est possible de composer un \gls{dictionnaire} contenant les paramètres pour lancer une requête. Une fois la réponse reçue, le résultat s'affiche sur la page. De cette étude, il faut également retenir que une \api{} ne sera utilisée que si elle offre l'accès à des données de qualité. Cela va dans le sens des principes \gls{fair}: pour partager des données, celles-ci doivent être documentées et éditorialisées pour qu'un.e chercheur.euse sache quelles données seront reçues et envisage des manières de les utiliser.

Une autre étude\footcite{corral_towards_2014}, menée sur des \api{} généralistes, permet également de mieux comprendre le terrain pour de tels outils. Cette étude est basée sur l'analyse statistique des réponses obtenues obtenues pour 10955 \textit{Buisness APIs}, terme qui recoupe des applications développées par des entreprises (comme l'API de \textit{Twitter}), à but commercial (comme l'API de \textit{PayPal}), mais aussi des \api{} créées à but non-lucratifs (comme celle de \textit{Wikipedia}). L'étude date d'il y a quelques années, et il est donc possible que les tendances de design d'\api{} aient évoluées depuis. Les statistiques coincident cependant avec mon expérience de ces outils. Les résultats obtenus permettent de mieux comprendre quelles sont les tendances actuelles en terme de design d'\api{}. Les deux formats de réponse dominants sont le \json{} et le \xml{}: 81,08\% des applications proposent l'un ou l'autre format. Seules 21,37\% utilisent les deux formats, ce qui est le cas de \textit{KatAPI}. Un autre fait intéressant est que une immense majorité d'\api{} sont \textit{RESTlike}\footcite[p. 3]{corral_towards_2014}. Contrairement aux API \textit{RESTful}, les API \textit{RESTlike} sont inspirées par les principes \gls{rest} sans nécessairement les appliquer totalement. Ce terme s'est développé du fait de l'implémentation très inégale du standard. Le problème est que le terme \textit{RESTlike} est nécessairement imprécis; il est donc difficile de tirer une conclusion de cette statistique: dans une large mesure, les principes \gls{rest} ont servi au développement de \textit{KatAPI}. Quoi qu'il en soit, \textit{KatAPI} semble s'inscrire, par les formats utilisés et les principes architecturaux suivis, dans le paysage actuel des \api{}.

Les standards et études présentés ici permettent de mieux cerner le statut des \api{} centrées sur le texte en humanités numériques; elles permettent également d'identifier des tendances dans le desgin d'\api{} ainsi que les besoins des utilisateur.ice.s. En ayant cette compréhension du paysage technique pour ces applications, il est possible de définir clairement le périmètre de l'\api{} et la manière dont l'interaction client-serveur doit s'organiser, dans la sémantique des requêtes autant que dans les réponses obtenues.

\chapter{Définir un périmètre: que partager, et comment partager?}
\chaptermark{Définir un périmètre}
Après avoir présenté le paysage des \api{} en général et le statut de ces outils dans les humanités numériques en particulier, ce chapitre décrit \textit{KatAPI} du point de vue de l'utilisateur.ice: quelles données peuvent être obtenues via l'\api{}, quels paramètres de recherche sont autorisés et quels sont les formats de données retournés par l'application. C'est donc les principes de la communication client-serveur de \textit{KatAPI} qui sont ici présentés.

\section{Grands principes pour l'architecture de l'\api{}}
Pour plus de clarté, ici sont présentés de façon concise l'ensemble des principes auxquels l'application doit se conformer; ceux-ci forment une sorte de cahier des charges pour son implémentation technique.

\begin{itemize}
	\item L'application supporte uniquement la méthode \gls{http} \texttt{GET}: il est uniquement possible de demander des données à l'application, et non d'ajouter des données à une base de données, par exemple.
	\item L'application supporte deux formats de réponse: \json{} et \xmltei{}. Le format par défaut est le \json{}, pour sa légèreté et sa facilité de manipulation. Dans les deux cas, la structure des réponses est la même: un en-tête qui décrive le contexte de la réponse (à ne pas confondre avec les en-têtes \gls{http}) et un corps, qui contient les données récupérées.
	\item Trois niveaux d'accès aux données sont possibles. Il est possible de faire une requête pour un catalogue entier; des statistiques sur un ou plusieurs catalogues; une ou plusieurs entrées de catalogues.
	\item L'application suit le principe de séparation des préoccupations. L'interaction avec le client, le traitement des requêtes et la base de données sont des parties distinctes qui ne communiquent que lorsque cela est nécessaire.
	\item L'\api{} suit les principes \gls{rest} lorsque cela est possible. Elle est sans état et présente une interface uniforme. Cela veut dire que, pour les trois niveaux d'accès aux données, trois modèles de données seulement existent et sont adaptés en \json{} et \xmltei{}.
	\item L'application a un traitement strict des requêtes. Une requête n'est pas traitée si elle contient des paramètres non-autorisés (qui ne font pas partie de la sémantique définie pour l'interaction client-serveur), ou des valeurs associées à ces paramètres qui ne sont pas autorisées.
	\item L'application envoie des réponses précises et auto-descriptives, même en cas d'erreur. Plusieurs statuts \gls{http} sont définis pour différents cas de figures; si erreur il y a, un message d'erreur complet et décrivant le contexte et les raisons de l'erreur est renvoyé par l'\api{}. Cette erreur constitue un document \json{} ou \xmltei{} valide.
\end{itemize}

\section{Quelles données partager?}
À différentes étapes, une grande variété de données ont été produites; de plus, différentes manières d'accéder aux données ont été constituées par le projet. Par exemple, un système de réconciliation des différentes entrées de catalogue permet d'identifier lorsqu'un manuscrit est vendu plusieurs fois, et donc présent dans différents catalogues. Cela permet de regrouper ensemble différentes occurrences d'un même manuscrit. Ce type de données pourrait être partagé, de même que les données extraites de \sparql{} et présentées dans la partie précédente. Cependant, la mise à disposition de différents types de données est difficile tout en se conformant au principe d'uniformité de l'interface du \gls{rest}. En effet, chaque source de données a sa propre structure. Il donc est nécessaire, pour chaque source de données, de définir une représentation en \json{} et en \tei{}. Pour se conformer à l'objectif originel du projet \mssktb{} (étudier des catalogues en vente), il a été choisi de ne diffuser que des données issues des catalogues à travers l'\api{}. Cela élimine donc les données issues de \sparql{}. Pour ne se conserver qu'une seule représentation par type de données, il a été choisi de ne pas diffuser non plus de données sur les manuscrits \enquote{réconciliés}, puisque cela amènerait à avoir deux modèles de données pour les manuscrits, selon qu'ils aient été réconciliés ou non. De plus, ce processus de réconciliation prend quelques secondes à s'exécuter, ce augmente le temps de réponse de l'\api{} et peut devenir problématique si de nombreuses requêtes sont reçues en même temps pas l'application.

Au final, trois niveaux d'accès aux corpus ont été définis. Ceux-ci correspondent à différents degrés de granularité dans le corpus. Chacun de ces formats, enfin, a un modèle de données qui lui est propre. Celui-ci est transposé à la fois en \xmltei{} et en \json{}. 

\begin{itemize}
	\item Premier niveau: catalogue complet (\texttt{cat\_full}): l'intégralité des données contenues dans un catalogue peut être requêtée. Dans ce cas, il n'est possible que de requêter un catalogue à la fois. Celui-ci doit être clairement identifié à l'aide de son identifiant unique (l'\texttt{@xml:id}). Il est renvoyé dans son intégralité au format \xml{} uniquement: la traduction d'un fichier \xmltei{} complet en \json{} est complexe; de plus, si un.e utilisateur.ice demande un catalogue de façon aussi ciblée, alors il ou elle souhaitera probablement un format plus complexe que le \json{} et pourra tirer parti du balisage sémantique permise par la \tei{}.
	\item Deuxième niveau: statistiques sur une collection de catalogues (\texttt{cat\_stat}): des données statistiques sont retournées pour un ou plusieurs catalogues (prix moyen et médian des items, variance des prix au sein du catalogue, nombre d'items en vente...). En utilisant d'autres paramètres de recherche, il est possible de cibler précisément un sous-ensemble de catalogues, comme ceux issus de la \textit{Revue des autographes}, ou ceux publiés dans une certaine tranche de dates. Ce degré de granularité permet donc de produire des sous-ensemble pour des études statistiques et thématiques ciblées.
	\item Troisième niveau: au niveau de l'entrée (\texttt{item}). Ce degré permet d'accéder à une ou plusieurs entrées de catalogues, et donc de récupérer l'ensemble des informations contenues dans les catalogues pour ces entrées. Il est possible de cibler des entrées par nom auteur.ice, date d'écriture, date de vente ou par identifiant \texttt{@xml:id}, ce qui permet de ne retourner qu'un identifiant. Ce degré de granularité permet donc de constituer des jeux de données restreints, avec par exemple tous les manuscrits écrits par un.e auteur.ice à une certaine période.
\end{itemize}

Chacun de ces degrés d'accès aux données correspond à une source de données différente. Le premier niveau (\texttt{cat\_full}) correspond à un document \tei{} représentant un catalogue dans son intégralité. Ce format permet donc l'accès aux sources directes du projet. Le deuxième niveau (\texttt{cat\_stat}) donne l'accès à un \json{} produit à partir d'une analyse statistique de tous les catalogues. Les entrées pertinentes de ce \json{} sont traduites en \xmltei{} si c'est le format de requête qui est demandée par l'utilisateur.ice. Enfin, le niveau \texttt{itm} correspond à deux sources de données: la première, c'est les catalogues eux-mêmes (au niveau de l'entrée, et non du catalogue complet); la deuxième, c'est une représentation en \json{} des entrées de catalogues. Pour accélérer le fonctionnement de l'\api{} lorsque la requête est faite au niveau de l'item, les données en \json{} sont d'abord lues avant, si besoin, d'utiliser la \tei{}. Les trois degrés de granularité des données sont donc centraux à l'architecture de l'\api{}: ils définissent trois bases de données à utiliser; ils déterminent aussi trois représentation de données différentes (c'est-à-dire, trois structures pour les réponses de l'\api{}). Grâce au principe de séparation des préoccupations, il est possible de rendre plus tard d'autres données accessibles et de permettre donc la diffusion de données depuis de nouvelles sources et la construction de nouvelles représentations. Les degrés de granularité déjà définis ne seront pas transformés par l'ajout d'autres degrés de granularité pour l'accès au corpus. Puisque les données et leur représentation sont distinctes, il est également possible de modifier la structure des sources de données (la structure des catalogues, par exemple) sans que le format de sortie ne soit affecté. Il suffit pour ce faire de faire en sorte que la représentation des données soit la même malgré le changement de la source de données.

\section{Codifier l'accès aux données: une sémantique pour les requêtes faites à l'API}
\sectionmark{Codifier l'accès aux données}
Les trois niveaux présentés au dessus sont autant de points d'accès aux données. Ils définissent les degrés de précision possibles pour accéder au données, mais ne définissent pas entièrement comment récupérer les informations voulues. À cette fin, une sémantique complète a été définie pour accéder aux données. Celle-ci s'organise autour des trois points d'accès présentés ci-dessus, puisque certains paramètres peuvent être interdits, ou que ceux-ci acceptent différentes valeurs en fonction du point d'accès aux données. Les paramètres de recherche autorisés sont les suivantes:

\begin{itemize}
	\item \texttt{level}: il s'agit du niveau auquel faire une requête. C'est ce paramètre qui définit le point d'accès aux données, et le degré de précision autorisé pour les recherches. 
	\item \texttt{format}: le format de la réponse renvoyée par le serveur au client.
	\item \texttt{id}: rechercher un catalogue ou une entrée de catalogue par son identifiant.
	\item \texttt{name}: rechercher un catalogue par type (\textit{Revue des autographes}, vente aux enchères...) ou une entrée de catalogue par nom d'auteur.ice.
	\item \texttt{sell\_date}: la date de vente à laquelle correspond un catalogue, ou la date de vente d'un manuscrit.
	\item \texttt{orig\_date}: la date d'écriture d'un manuscrit.
\end{itemize}

Ces cinq paramètres offrent un vocabulaire commun pour accéder à toutes les données issues des catalogues. Pour une \api{}, avoir une sémantique claire et facile d'accès est important, et c'est pourquoi les paramètres de recherche sont limités à ces cinq mots clés. Le problème est que ces cinq mots clés permettent d'accéder à différents types de données, en fonction du point d'accès choisi avec le paramètre \texttt{level}. Deux grands types peuvent être identifiés: les données portant sur un catalogue et celles portant sur un manuscrit. Ces deux catégories portent cependant sur des objets très différents: bien que la sémantique soit la même pour toute l'\api{}, il n'est pas possible de rechercher un catalogue et un manuscrit dans les bases de données disponibles. Cette sémantique doit donc être définie et adaptée aux différents points d'entrée aux données.

Comme cela a été dit, l'\api{} réalise un contrôle strict des requêtes: une requête n'est faite que si elle correspond à la sémantique des requêtes; si elle contient des paramètres interdits, alors la requête n'est pas lancée et un message d'erreur est renvoyé à l'utilisateur.ice. Cela permet d'économiser les ressources du serveur: chaque requête a un certain prix. Celui ci peut s'exprimer en terme de temps (le traitement d'une requête n'étant pas instantané) et en termes computationnels (la charge processeur nécessaire à traiter une requête, c'est-à-dire rechercher des informations dans plusieurs bases de données, construire des réponses et les renvoyer à l'utilisateur.ice). Par ailleurs, certaines requêtes pourraient correspondre à la sémantique définie, mais n'avoir aucun sens pour le moteur de recherche: si un identifiant (\texttt{id}) et un nom (\texttt{name}) sont fournis, laquelle de ces deux informations utiliser pour identifier les items pertinents? Un nom et un identifiant peuvent en effet pointer vers deux ressources très différentes. Le parti pris a donc été de diminuer les coûts de traitement et le risque de requêtes contradictoires en contrôlant strictement celles-ci. D'un point de vue de sécurité informatique, le contrôle des requêtes peut également protéger contre les attaques par déni de service, qui consistent à faire énormément de requêtes au même moment pour faire surcharger un serveur et l'empêcher de toutes les traiter.

La sémantique des requêtes ne dépend donc pas seulement des mots clés, mais aussi des valeurs qui y sont associées. Les principales variations dépendent du point d'accès aux données choisi. Cependant, dans tous les cas, une valeur doit être fournie pour le paramètre \texttt{id} ou \texttt{name}, puisque c'est à partir de ceux-ci qu'est faite une recherche. Au niveau du catalogue complet (\texttt{cat\_full}), le contrôle des requêtes est très précis, puisque les deux paramètres autorisés sont \texttt{format} et \texttt{id}.
\begin{itemize}
	\item Le seul format de réponse autorisé (paramètre \texttt{format}) est la \tei{}, pour deux raisons. D'un point de vue scientifique, un catalogue encodé en \tei{} contient des informations qui ne peuvent être facilement représentées sous la forme d'un \json{}. D'un point de vue scientifique, les catalogues en \tei{} sont le fruit d'un travail éditorial particulier; il est considéré qu'un.e utilisateur.ice qui fasse une requête aussi précise souhaiterait disposer d'une représentation aussi précise que la \tei{}. D'un point de vue computationnel, la représentation en \json{} d'un catalogue complet encodé en \tei{} serait très difficile, et aboutirait certainement à une perte d'informations.
	\item À part \texttt{format}, le seul autre paramètre autorisé est \texttt{id}. Une requête au niveau du catalogue complet ne peut renvoyer qu'un seul de ces documents à la fois, et essayer de cibler un catalogue par son nom, ou sa date de publication risquerait de créer des doublons. Là encore, il est supposé qu'un.e utilisateur.ice voulant obtenir un catalogue complet sait précisément celui que il ou elle cherche, et pourrait donc fournir directement son identifiant. Cela dit, il est tout à fait possible de récupérer plusieurs catalogues en lançant une série de requêtes avec différents identifiants. Suivant le principe de contrôle strict des requêtes, seul un identifiant valide sera recherché. Un identifiant valide correspond à l'expression régulière \texttt{CAT\_\textbackslash{}d+}, soit \texttt{CAT\_} suivi d'un nombre entier (par exemple, \texttt{CAT\_000001, CAT\_000499}).
\end{itemize}

Lorsque des données statistiques sur des catalogues sont recherchées (au niveau \texttt{cat\_stat}), l'\api{} offre plus de liberté dans les paramètres fournis.
\begin{itemize}
	\item Le \texttt{format} de réponse accepte deux valeurs possibles: \texttt{tei} ou \texttt{json}.
	\item Un \texttt{id} ne peut être fourni en même temps qu'un \texttt{name}, pour éviter des requêtes impossibles à traiter. 
	\item Un identifiant doit toujours être conforme à l'\gls{expression régulière} \texttt{CAT\_\textbackslash{}d+}, afin de toujours identifier un catalogue.
	\item Le paramètre \texttt{name} n'accepte que certaines valeurs. Celles-ci correspondent aux différents types de catalogues établis par le projet: \texttt{RDA} pour ceux issus de la revue des autographes, \texttt{AUC} pour les ventes aux enchères...
	\item Le paramètre \texttt{orig\_date} n'est pas autorisé: au niveau d'un catalogue complet, il n'y a pas de date de création, mais seulement la date de la vente à laquelle correspond le catalogue.
	\item Le paramètre \texttt{sell\_date} n'accepte que des valeurs au format \texttt{AAAA} ou \texttt{AAAA-AAAA}, ce qui est validé par l'\gls{expression régulière} \texttt{\textbackslash{}d\{4\}(\textbackslash{}d\{4\})+}.
\end{itemize}

C'est au niveau de l'item que la plus grande liberté est admise pour les paramètres de recherche:
\begin{itemize}
	\item Le \texttt{format} de réponse peut être du \xmltei{} ou du \json{}.
	\item Une entrée de catalogue peut être ciblée par son identifiant avec le paramètre \texttt{id}. Cependant, l'identifiant doit correspondre au format de notation défini par \mssktb{} en se conformant à l'expression régulière \texttt{CAT\_\textbackslash{}d+\_e\textbackslash{}d+\_d\textbackslash{}d+}. Des valeurs autorisées sont par exemple: \texttt{CAT\_000069\_e2\_d1, CAT\_000420\_e49\_d1}.
	\item Les paramètres \texttt{sell\_date} et \texttt{orig\_date} sont tous les deux autorisés et peuvent être utilisés en même temps, puisqu'un manuscrit a à la fois une date de création et une date de vente. Le format de date autorisé est le même que pour le niveau \texttt{cat\_stat}. Cela permet par exemple de cibler un manuscrit écrit à une période et vendu une certaine année.
\end{itemize}

À partir de seulement cinq paramètres, c'est un moteur de recherche à filtre qui est défini et qui permet de définir la granularité des données à traiter, leur période et le format obtenu. Il est donc possible, en tant qu'utilisateur.ice de l'\api{}, de choisir entre la facilité de traitement (avec une réponse en \json{}) et un format à la sémantique clairement documentée (la \tei{}). Que les données soient retournées en \tei{} ou en \json{}, la précision des résultats obtenus est la même, puisque les deux formats de réponse sont des représentations des mêmes données, en accord avec les principes \gls{rest}. Une sémantique définie aussi précisément a ses avantages: elle permet de ne faire que des recherches qui ont un sens. Définir une sémantique claire et des incompatibilités entre différents paramètres de recherche garantissent que l'\api{} pourra traiter toutes les requêtes sans risque de contradiction.

 Le contrôle des données envoyées par le client permettent également de ne faire que des recherches qui permettront d'obtenir un résultat, ce qui est également plus intéressant pour les utilisateur.ice.s. Cependant, elles augmentent la difficulté d'utilisation de l'\api{}. Cela risque d'augmenter la niveau de technicité perçu par un.e chercheur.euse, ce qui risque de les décourager d'utiliser l'outil\footcite[p. 292-294]{edmond_apis_2015}. Pour diminuer cette distance perçue, quatre solutions ont été définies:
\begin{itemize}
	\item Des valeurs par défaut ont été établies pour certains paramètres. Par exemple, lorsqu'un \texttt{format} n'est pas spécifié par l'utilisateur.ice, la réponse est en \json{} par défaut (sauf si c'est un catalogue entier qui est recherché). Cela permet d'omettre des paramètres, et donc de faciliter l'utilisation de \textit{KatAPI}. La définition de valeurs par défaut semble aller à l'encontre de l'architecture \enquote{sans-état} voulue par le \gls{rest}, mais de nombreuses autres \api{} suivent ce principe (celle de \wkd{}, par exemple).
	\item La recherche d'un nom est insensible à la casse, aux accents et à la ponctuation. Les résultats obtenus en recherchant le \texttt{name SÉVIGNÉ} seront les mêmes que pour \texttt{sevigne} et \texttt{Sévigné}.
	\item Un système d'essai en temps réel, depuis la version \enquote{pour humain.e.s}, du site a été mis au point. Il est possible d'écrire un \json{} contenant les paramètres voulus dans une barre de recherche pour faire une requête. Celle-ci est traitée par le serveur qui retourne une réponse, et celle-ci s'affiche sur la même page Web. Cela permet d'essayer une \api{} -- qui par définition n'a pas une interface graphique, ce qui est rebutant pour un.e utilisateur.ice non formé.e aux méthodes computationnelles -- depuis une interface graphique.
	\item En cas d'erreur, les réponses identifient précisément l'erreur et permettent de corriger sa requête sans devoir consulter la documentation, comme cela est expliqué dans la section suivante.
\end{itemize}

\section{Quelles représentations pour les données? Principes suivis pour le partage d'informations, formats et structure des réponses de l'API}
\sectionmark{Quelles représentations pour les données?}
Une \api{} n'a de sens que si elle est clairement documentée: c'est la seule manière de garantir que son fonctionnement soit clairement compréhensible par l'utilisateur.ice. La sémantique présentée ci-dessus est donc également documentée sur le site \ktb{}. Mais la sémantique d'une \api{} ne se limite pas dans les paramètres de recherche; elle définit également les formats de réponse de l'application. En effet, si ceux-ci ne sont pas clairement compréhensibles par un.e humain.e, ils risquent d'être inutilisables. La définition de formats de réponse est donc une sorte de travail éditorial, qui doit répondre à trois besoins:

\begin{itemize}
	\item Les réponses doivent être structurées et manipulables par des machines. C'est le cas de la \tei{} comme du \json{}, qui disposent tous les deux d'une structure hiérarchique en arbre permettant de clairement distinguer les différentes parties de la réponse.
	\item Les réponses doivent être des représentations uniformes de données, en accord avec les principes \gls{rest}. Cela veut dire que, pour les différents points d'accès aux données, un seul modèle doit exister et qu'il doit être le même, peu importe le nombre de résultats ait été retourné par l'application. En accord avec ces principes, les réponses doivent également être auto-descriptives.
	\item La réponse doit correspondre aux principes \gls{fair} autant qu'aux attentes des chercheur.euse.s et être compréhensible et utilisable par des personnes humaines. 
\end{itemize}

C'est le troisième point qui est le plus problématique: pour qu'un fichier soit manipulable par une machine, il suffit qu'il présente une structure précise. Pour qu'une réponse ait du sens, qu'elle doit compréhensible par une personne humaine, la tâche est cependant plus compliquée. En effet, une réponse d'une \api{} doit, en général, être aussi légère et concise que possible, puisqu'elle doit être envoyée à un client qui se trouve à distance. Une réponse \enquote{lourde} est également plus difficile à traiter par une machine. Une personne humaine risque également d'être découragée par une réponse trop complexe, qui présente par exemple des structures trop imbriquées et donc des éléments difficiles d'accès. Cependant, il n'est pas possible de demander à l'utilisateur.ice de se référer systématiquement à une documentation externe pour comprendre ce que l'application lui a renvoyé. Cette situation est encore complexifiée lorsque l'on essaye d'adhérer aux principes \gls{fair} et aux besoins de la recherche. En effet, ces principes autant que les chercheur.euse.s mettent l'accent sur l'importance des métadonnées dans le choix d'une source de données plutôt qu'une autre\footcite[p. 290-291 et p. 932-933 respectivement]{edmond_apis_2015, boeckhout_fair_2018}. Il est bien sûr possible de faire figurer toutes les métadonnées nécessaires dans la documentation de l'\api{} qui est accessible en ligne. Cependant, cela demande de devoir régulièrement consulter une source externe; si les résultats d'une requête sont transmis de manière brute à d'autres personnes, il est également nécessaire que celles-ci disposent des métadonnées nécessaires à leur utilisation. Il est donc intéressant d'inclure celles-ci dans la réponse renvoyée par l'\api{}, quitte à ce qu'elles soient ignorées par l'utilisateur.ice. Deux types de métadonnées peuvent être définies: celles qui concernent les données originelles et celles qui définissent le contexte de récupération des données et de production des ressources (c'est-à-dire, la requête faite à l'\api{}). Dans la première catégorie se classent la définition de la licence sous laquelle les données sont diffusées et la définition des termes spécifiques au projet qui pourraient être présents dans les réponses; dans la deuxième catégorie se placent les métadonnées qui permettent de définir le contexte de production de la ressource, c'est-à-dire la date de la requête, son contenu et le statut \gls{http} de la réponse. I va cependant de soit qu'il est impossible de contenir toutes les métadonnées définissant le projet \ktb{}, le contexte de production des données et les choix faits pendant leur traitement. Ces informations sont notamment contenues dans le \texttt{teiHeader} (l'en-tête) des catalogues encodés. Il est donc pertinent de consulter la documentation de l'\api{} et les catalogues encodés pour mieux comprendre les données présentes dans la réponse. Cependant, une réponse doit contient toutes les données nécessaires à sa compréhension minimale, même par une personne autre que celle qui a lancé la requête. Pour faire coïncider ce besoin la nécessité d'une réponse compréhensible par une machine et qui corresponde au principe \gls{rest} d'uniformité de l'interface, c'est donc une véritable éditorialisation des données à renvoyer au client qui est nécessaire.

\subsection{Les réponses, en général}
Les formats de réponse varient en fonction de plusieurs facteurs: le point d'accès aux données, le format de réponse demandé par le client et le fait qu'il y ait eu une erreur. Tous ces facteurs amènent à des structures de données qui sont différentes. Ce sont des représentations. Cependant, à un niveau abstrait et indépendant de sa représentation, une réponse peut toujours être représentée de la même manière (\ref{fig:response})\footnote{
	Des exemples de réponses en différents formats et avec différents paramètres sont visibles en annexes: au niveau \texttt{cat\_stat} en \json{} (\ref{appendix:api_cat_stat_json}) et \tei{} (\ref{appendix:api_cat_stat_json}), au niveau de l'\texttt{item} en \json{} (\ref{appendix:api_item_json}) et \tei{} (\ref{appendix:api_item_xml}); des messages d'erreur sont également présents en annexes, en \json{} (\ref{appendix:api_error_json}), et, là encore, en \tei{} (\ref{appendix:api_error_xml}). Un exemple de réponse complète est également \href{https://github.com/paulhectork/tnah2022_memoire/blob/main/texte_sources/annexes/api_cat_full.xml}{accessible depuis le dépôt en ligne de ce mémoire}, puisque le document est trop long pour être inclus en annexes.
}:

\begin{figure}[h!]
	\tikz[scale=0.75, transform shape]{
		\node[expl, minimum height=1.5cm] (http) at (0,4)%
		{En-tête HTTP}; 
		\node[db] (start) at (0,0)%
		{Réponse};
		\node[base] (header) at (-5,-3)%
		{En-tête de la réponse};
		\node[base] (body) at (5,-3)%
		{Corps de la réponse};
		\node[base] (header1) at (-8.5,-6)%
		{Métadonnées sur la requête};
		\node[base] (header2) at (-2.85,-6)%
		{Métadonnées sur le contenu de la réponse};
		\node[base] (body1) at (2.85,-6)%
		{Premier résultat ou message d'erreur};
		\node[base] (body2) at (8.5,-6)%
		{Second résultat ou message d'erreur};
		
		\draw[arrow] (start) -- (header);
		\draw[arrow] (start) -- (body);
		\draw[arrow] (header) -- (header1);
		\draw[arrow] (header) -- (header2);
		\draw[arrow] (body) -- (body1);
		\draw[arrow] (body) -- (body2);
		\draw[doublearrow, dash pattern=on 3pt off 4pt on \the\pgflinewidth off 4pt] (start) -- (http);
	}
	\caption{Modèle de réponse renvoyé par \textit{KatAPI}}
	\label{fig:response}
\end{figure}

Toutes les réponses revoyées par l'\api{} contiennent un en-tête \gls{http} et la réponse elle-même. L'en-tête \gls{http} sert à caractériser la réponse à l'aide de métadonnées. Ils contiennent de nombreuses informations qui permettent d'interpréter la réponse, dont la plupart sont produits automatiquement: par exemple, des données sont produites sur le serveur ayant renvoyé la réponse, la possibilité de mettre les données reçues par le client en cache ou encore la date de la requête. Parmi toutes ces informations, deux sont définies par l'\api{} à chaque requête: le statut \gls{http} (qui indique comment s'est déroulée l'interaction avec le serveur) et le type MIME (qui identifie le format de la réponse). Ainsi, les en-têtes permettent à un client d'interpréter le message reçu en réponse.

La réponse est elle-même séparée entre un en-tête et un corps. Le premier définit le contexte dans lequel la réponse avec le serveur a été faite. Cet en-tête a plus de précision que celui prévu par le protocole \gls{http}; contrairement à celui-ci, qui n'est plus accessible une fois l'interaction avec le serveur terminée, l'en-tête de la réponse est toujours accessible, puisqu'il fait partie du fichier renvoyé. Le corps de la réponse en lui-même contient les données correspondant à la requête du client, ou, si une erreur a eu lieu, un message d'erreur descriptif. Cette séparation de la réponse en un en-tête et un corps est obligatoire lors de l'utilisation de la \tei{}; son utilisation par le \json{} est également inspirée par la structure des réponses \sparql{}\footcite{beckett_sparql_2013}, bien que celles-ci contiennent beaucoup moins de métadonnées qu'une réponse de \textit{KatAPI}.

\subsection{L'en-tête des réponses, un conteneur pour les métadonnées}
Si l'en-tête n'est pas voué à être conservé par les utilisateur.ice.s ayant réalisé des requêtes, il est néanmoins essentiel. Il permet à une personne qui n'est pas familière avec le projet d'aborder les données reçues et identifie précisément à quels critères elles correspondent. Il est garant du respect des principes \gls{fair}, puisqu'il contient suffisamment de métadonnées pour que quiconque manipule la réponse dispose d'informations suffisantes à leur réutilisation. Décrivant le contexte d'une réponse, il rend la réponse auto-descriptive, ce qui correspond avec l'utilisation des principes \gls{rest}. Les informations relatives à la requête sont les suivantes (\ref{code:api_header_context_json}, \ref{code:api_header_context_tei}):

\begin{itemize}
	\item La requête, représentée sous la forme d'une table associant les paramètres de recherche utilisés (\texttt{level, format...}) aux valeurs que l'utilisateur.ice leur a associées.
	\item La date à laquelle la requête est reçue, au format ISO. Cette information est surtout utile dans le cas où la réponse serait enregistrée par l'utilisateur.ice pour y accéder plus tard. Cela permet de dater les données produites, ce qui est utile puisque de nouveaux catalogues peuvent être ajoutés ultérieurement; dans ce cas, la réponse du serveur ne serait plus à jour.
	\item Le statut \gls{http} de la réponse. Celui-ci est également présent dans l'en-tête \gls{http}, et sa présence ici peut donc sembler superflue. Il a été rajouté à cause du système de gestion des erreurs. Un choix de conception de l'application a en effet été de construire des messages d'erreurs sous la forme de \json{} ou de \tei{} valides. Cela veut dire qu'une erreur retourne une réponse valide qui décrive l'erreur. Dans le cas où les réponses obtenues par le client sont traitées automatiquement, un programme informatique ne détectera donc pas forcément de problème. L'ajout d'un code de statut permet d'adapter facilement un programme à ce cas de figure, en vérifiant à chaque réponse le code \gls{http} dans le corps du document.
\end{itemize}

\begin{listing}
	\begin{minted}[breakanywhere]{json}
{
	"license": "Attribution 2.0 Generic (CC BY 2.0)",
	"query": {
		"format": "json",
		"level": "cat_stat",
		"name": "RDA",
		"sell_date": "1800-1900"
	},
	"query_date": "2022-08-24T16:41:42.604421",
	"status_code": 200
	# reste de l'en-tête
}
	\end{minted}
	\caption{Extrait d'en-tête de réponse en \json{} décrivant le contexte d'une requête}
	\label{code:api_header_context_json}
\end{listing}

Les informations relatives aux données contenues dans le corps de la réponse, elles, permettent de mieux comprendre les données. Ces métadonnées sont différentes selon si le format de réponse est le \json{} ou le \tei{}. Dans les deux cas, une réponse contient une licence, qui définit de quelle manière les données peuvent être utilisées. La licence Creative Commons Attribution 2.0 Generic (CC BY 2.0) est utilisée par le projet. Étant une licence libre, elle permet aux utilisateur.ice.s de réutiliser les données en les citant. Toutes les réponses partagent également une ou plusieurs \enquote{taxonomies} (l'usage de ce terme est issu de la \tei{}). Celles-ci servent à définir les termes spécifiques au projet, qui ne seraient pas nécessairement compréhensibles par tou.te.s les utilisateur.ice.s. Les taxonomies associent à des termes présents dans le corps de la réponse une définition. L'explication du terme \texttt{variance\_price\_c} dans une taxonomie en \tei{} est visible dans l'exemple \ref{code:taxonomy}. Ces taxonomies améliorent la compréhension de la réponse par une personne humaine; mais elles offrent aussi des possibilités de traitement par une machine, puisqu'il est par exemple possible de remplacer un terme spécifique au projet par une définition. Les taxonomies présentes dans une réponse changent selon le point d'accès aux données choisi, puisque ce sont des termes différents qui auront besoin d'être expliqués à chaque fois.

\begin{listing}[h]
	\begin{minted}{xml}
<category xml:id="cat_stat_keys_variance_price_c">
	<catDesc>The variance of the prices inside the catalogue.</catDesc>
</category>
	\end{minted}
	\caption{Un élément d'une taxonomie en \tei{}}
	\label{code:taxonomy}
\end{listing}

Si une réponse est encodée en \tei{}, alors d'autres informations sont présentes. Deux raisons sont derrière ce choix, qui implique que les réponses en \json{} et en \tei{} diffèrent. D'abord, la \tei{} définit toute une sémantique qui permet de caractériser très efficacement le contexte de production des données. Elle requiert qu'un document contienne un minimum d'informations dans son en-tête, ce qui a encouragé à étoffer l'en-tête. Ensuite, il a été considéré que la \tei{} est plus susceptible que le \json{} d'être un format définitif, dans lequel la richesse d'informations privilégiée. Un \json{}, au contraire, est utilisé parce qu'il est pratique, et il est susceptible d'être retraité par un.e utilisateur.ice de l'\api{} afin qu'il s'adapte à ses besoins. Par ailleurs, la présence ou l'absence de ces données ne change pas la structure globale de la réponse, mais seulement l'en-tête. Les informations supplémentaires contenues dans le \tei{} sont notamment un titre (\textit{KatAPI query results}, soit \enquote{Résultats de requête KatAPI}) et la mention des différents projets qui ont produit les données (\textit{e-Ditiones, Katabase et Manuscript SaleS Catalogues}) (\ref{appendix:api_cat_stat_xml}).

Les métadonnées relatives à la requête doivent être encodées de façon légèrement différente lorsqu'un catalogue entier est requêté. Dans ce cas, la réponse n'est pas créée \textit{ex nihilo}, elle est construite en récupérant un document entier dans la base de données de catalogues. Cela pose une question à propos de la nature du document: faut-il modifier le catalogue encodé, en sachant que celui-ci est déjà un objet édité et pensé de façon cohérente? Le document transmis au client lors d'une requête est-il différent de celui qui est présent dans le serveur? En plus de ces questions pratiques, le problème est technique: les métadonnées relatives à la requête sont normalement encodées en \tei{} dans un élément \texttt{tei:publicationStmt}, qui décrit le contexte de publication d'un document électronique. Dans un catalogue complet, cet élément est déjà utilisé. Le fait que cet élément soit déjà utilisé, mais qu'il doive être réutilisé lors d'une requête résume bien la question posée ci-dessus. La réponse à ce problème est pragmatique. Il est toujours possible que, à cause d'un problème interne à l'\api{} ou dû au transfert de la réponse au client, que le catalogue soit corrompu ou contienne des erreurs. Dans ce cas, le catalogue transmis n'est pas différent de celui présent dans le serveur, mais il peut être considéré comme une édition de celui-ci. De ce fait, il est toujours nécessaire d'encoder le contexte dans lequel le catalogue a été transmis au client. La solution trouvée consiste à intégrer le contexte de la requête à l'intérieur d'un élément \texttt{tei:availability} -- qui définit les conditions d'accès à un document -- dans le \texttt{tei:publicationStmt} (\ref{code:api_header_context_tei}). Cela permet de ne pas perdre d'informations de l'original, tout en intégrant à la réponse les métadonnées relatives à la requête.

\begin{listing}[p]
	\begin{minted}[breakanywhere]{xml}
<publicationStmt>
	<publisher>Projet e-Ditiones, Université de Neuchâtel</publisher>
	<availability status="restricted">
		<licence target="https://creativecommons.org/licenses/by/2.0">Attribution 2.0 Generic (CC BY 2.0)</licence>
		<p>KatAPI query results. File created automatically by KatAPI, an API developped as part of the<ref target="https://katabase.huma-num.fr/">Manuscript SaleS Catalogues project</ref></p>
		<p>Query run on<date when-iso="2022-08-24T16:41:52.101590">2022-08-24T16:41:52.101590</date></p>
		<p>Query ran with HTTP status code:<ref target="https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/200"/></p>
		<p>The current file has been retrieved and updated as a response to the query:
			<table>
				<head>Query parameters</head>
				<row>
					<cell role="key" xml:id="id">id</cell>
					<cell role="key" xml:id="output_format">format</cell>
					<cell role="key" xml:id="level">level</cell>
				</row>
				<row>
					<cell role="value" corresp="id">CAT_000300</cell>
					<cell role="value" corresp="format">tei</cell>
					<cell role="value" corresp="level">cat_full</cell>
				</row>
			</table>
		</p>
	</availability>
</publicationStmt>
	\end{minted}
	\caption{Exemple de \texttt{tei:publicationStmt} décrivant le contexte de la requête}
	\label{code:api_header_context_tei}
\end{listing}

L'en-tête sert à contextualiser les données contenues dans le corps de la réponse, afin qu'elles aient du sens au moment où elles sont reçues, mais aussi sur le long terme. En décrivant le contexte de la requête et de la production des docuemnt, et en indiquant la licence sous laquelle les documents sont diffusés, l'en-tête cherche à s'adapter aux principes \gls{fair}. L'éditorialisation de l'en-tête cherche également à construire une structure commune pour les différents points d'entrée, en accord avec les principes \gls{rest}. Son rôle principal est de permettre la compréhension du corps des réponses, qui sont elles mêmes issues d'un travail d'éditorialisation.

\subsection{Le corps d'une réponse au format \texttt{cat\_full}}
Ce cas particulier implique un fonctionnement particulier de l'\api{}: plutôt que de construire un jeu de données sur mesure à transmettre au client, il s'agit de vérifier si le fichier demandé existe. Cela implique, comme on l'a vu, un en-tête de réponse est particulier; le corps l'est aussi. Dans le cas où une catalogue est trouvé, c'est le corps de ce catalogue qui est retourné au client. Cependant, si aucun catalogue correspondant à l'identifiant fourni par le client n'est trouvé, le corps comme l'en-tête sont différents. Il n'est pas possible de reprendre un en-tête existant, et un en-tête sur mesure est donc constitué, comme pour les points d'entrée \texttt{cat\_stat} et \texttt{item}. Le corps est vide, puisqu'aucun résultat n'a été trouvé (\ref{code:api_cat_full_empty}):

\begin{listing}[h!]
	\begin{minted}{xml}
<TEI>
	<teiHeader>
		<!-- ... -->
	</teiHeader>
	<front>
		<body>
			<div type="search-results"/>
		</body>
	</front>
</TEI>
	\end{minted}
	\caption{Extrait de réponse au niveau \texttt{cat\_full} lorsqu'aucun catalogue n'est trouvé}
	\label{code:api_cat_full_empty}
\end{listing}

\subsection{Le corps d'une réponse au format \texttt{cat\_stat}}

\subsection{Le corps d'une réponse au format \texttt{item}}

\chapter{Implémentation et fonctionnement technique de \textit{KatAPI}}
\chaptermark{Implémentation et fonctionnement technique}
Ce chapitre décrit le fonctionnement de l'\api{} côté serveur: comment les données sont reçues, la manière dont elles sont traitées et comment les réponses sont construites (notamment la création automatisée de documents \xmltei{}). Le système de gestion des erreurs est également présenté.

\section{Présentation générale}
Ici est présenté, schéma à l'appui, le fonctionnement technique de l'\api{} et la chaîne de traitement depuis la réception des requêtes jusqu'à l'envoi d'une réponse.

\section{Gestion des erreurs}
L'\api{} étant une application devant interagir avec des utilisateur.ice.s et gérer leurs requêtes, il n'est pas pensable qu'elle \enquote{plante} ou ne renvoie pas d'erreur. Tout un système de gestion des erreurs a donc été défini. Ces erreurs peuvent être classées en deux catégoriés: côté client (dues à des entrées invalides des utilisateur.ice.s)  et côté serveur (erreurs inattendues qui empêchent l'exécution d'une requête). Si ces erreurs sont rencontrées, des réponses sont construites en \json{} ou \xmltei{} (selon le format demandé par l'utilisateur.ice.s). Celles-ci décrivent l'erreur et permettent donc aux utilisateur.ice.s de corriger les erreurs qui ont pu avoir lieu côté client.

\section{Garantir le bon fonctionnement de l'application}
De la même manière que les systèmes de gestion des erreurs garantissent que l'application continue à fonctionner même en cas d'erreur, les tests garantissent que l'\api{} soit fonctionnelle, même dans \enquote{des conditions extrêmes}. Les réponses, formats et données retournées sont donc testés. C'est ce protocole de test qui est présenté ici.